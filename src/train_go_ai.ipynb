{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqnIOf1oB2r9"
      },
      "source": [
        "# Entraînement d'un réseau de neurones pour jouer au Go\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/auduvignac/deep_learning_go/blob/main/src/train_go_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGW-Bl5SB2r_"
      },
      "source": [
        "## Description\n",
        "\n",
        "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
        "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
        "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
        "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
        "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
        "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
        "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
        "  - Couleur au trait  \n",
        "  - Échelles  \n",
        "  - État actuel sur deux plans  \n",
        "  - Deux états précédents sur plusieurs plans  \n",
        "- Les cibles de sortie sont :  \n",
        "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
        "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
        "\n",
        "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
        "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
        "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
        "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
        "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
        "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
        "\n",
        "## Tournois\n",
        "\n",
        "- Toutes les deux semaines environ, j'organiserai un tournoi entre les réseaux que vous téléchargez.  \n",
        "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
        "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
        "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
        "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
        "\n",
        "## Exemple de réseau\n",
        "\n",
        "```python\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 20\n",
        "batch = 128\n",
        "filters = 32\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input)\n",
        "for i in range (5):\n",
        "  x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "for i in range (1, epochs + 1):\n",
        "  print ('epoch ' + str (i))\n",
        "  golois.getBatch (input_data, policy, value, end, groups, i * N)\n",
        "  history = model.fit(input_data,\n",
        "  {'policy': policy, 'value': value},\n",
        "  epochs=1, batch_size=batch)\n",
        "  if (i % 5 == 0):\n",
        "  gc.collect ()\n",
        "  if (i % 20 == 0):\n",
        "  golois.getValidation (input_data, policy, value, end)\n",
        "  val = model.evaluate (input_data,\n",
        "  [policy, value], verbose = 0, batch_size=batch)\n",
        "  print (\"val =\", val)\n",
        "  model.save ('test.h5')\n",
        "```\n",
        "\n",
        "## Instructions :  \n",
        "- Entraînez un réseau pour jouer au Go.  \n",
        "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
        "- Tournoi des réseaux **chaque dimanche**.  \n",
        "- Téléchargez un réseau **avant la fin de la session**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VvTcnNjdcrGe",
        "outputId": "0e070fed-c4a7-485b-f070-1b115eb7235a"
      },
      "outputs": [],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
        "!unzip project2025.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LXj_yFKDbhiI",
        "outputId": "893b147b-b1b6-4faa-9a3e-355038727a76"
      },
      "outputs": [],
      "source": [
        "!pip install tensorrt-bindings==8.6.1\n",
        "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
        "!pip install tensorflow[and-cuda]==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4CT2R1qaB1"
      },
      "source": [
        "## Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAcwAJJ9qZF7"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import regularizers\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import golois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtixgy9JqeA7"
      },
      "source": [
        "## Création de la classe abstraite `GONet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_6C3MiaVelc"
      },
      "outputs": [],
      "source": [
        "class GONet(ABC):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        self.batch = batch\n",
        "        self.epochs = epochs\n",
        "        self.filters = filters\n",
        "        self.moves = moves\n",
        "        self.N = N\n",
        "        self.planes = planes\n",
        "        self.set_input_data(N, planes)\n",
        "        self.set_policy(N, moves)\n",
        "        self.set_value(N)\n",
        "        self.set_end(N)\n",
        "        self.set_groups(N)\n",
        "        print(\"Tensorflow version\", tf.__version__)\n",
        "        print(\"getValidation\", flush=True)\n",
        "        golois.getValidation(\n",
        "            self.input_data, self.policy, self.value, self.end\n",
        "        )\n",
        "        self.loss_total = []\n",
        "        self.policy_loss  = []\n",
        "        self.value_loss  = []\n",
        "        self.policy_acc = []\n",
        "        self.value_mse = []\n",
        "\n",
        "    def set_input_data(self, N, planes):\n",
        "        input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "        self.input_data = input_data.astype(\"float32\")\n",
        "\n",
        "    def get_input_data(self):\n",
        "        return self.input_data\n",
        "\n",
        "    def set_policy(self, N, moves):\n",
        "        policy = np.random.randint(moves, size=(N,))\n",
        "        self.policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "    def get_policy(self):\n",
        "        return self.policy\n",
        "\n",
        "    def set_value(self, N):\n",
        "        value = np.random.randint(2, size=(N,))\n",
        "        self.value = value.astype(\"float32\")\n",
        "\n",
        "    def get_value(self):\n",
        "        return self.value\n",
        "\n",
        "    def set_end(self, N):\n",
        "        end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "        self.end = end.astype(\"float32\")\n",
        "\n",
        "    def get_end(self):\n",
        "        return self.end\n",
        "\n",
        "    def set_groups(self, N):\n",
        "        groups = np.zeros((N, 19, 19, 1))\n",
        "        self.groups = groups.astype(\"float32\")\n",
        "\n",
        "    def get_groups(self):\n",
        "        return self.groups\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_model(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_policy_value_heads(self):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def train_model(self, epochs):\n",
        "        for i in range(1, epochs + 1):\n",
        "            print(f\"epoch {str(i)}\")\n",
        "            golois.getBatch(\n",
        "                self.input_data,\n",
        "                self.policy,\n",
        "                self.value,\n",
        "                self.end,\n",
        "                self.groups,\n",
        "                i * self.N,\n",
        "            )\n",
        "            history = self.model.fit(\n",
        "                self.input_data,\n",
        "                {\"policy\": self.policy, \"value\": self.value},\n",
        "                epochs=1,\n",
        "                batch_size=self.batch,\n",
        "            )\n",
        "            # Extraction des valeurs depuis history.history\n",
        "            self.loss_total.append(history.history[\"loss\"][0])  # Loss globale\n",
        "            self.policy_loss.append(history.history[\"policy_loss\"][0])  # Policy loss\n",
        "            self.value_loss.append(history.history[\"value_loss\"][0])  # Value loss\n",
        "            self.policy_acc.append(history.history[\"policy_categorical_accuracy\"][0])  # Policy accuracy\n",
        "            self.value_mse.append(history.history[\"value_mse\"][0])  # Value MSE\n",
        "            if i % 5 == 0:\n",
        "                gc.collect()\n",
        "            if i % 20 == 0:\n",
        "                golois.getValidation(\n",
        "                    self.input_data, self.policy, self.value, self.end\n",
        "                )\n",
        "                val = self.model.evaluate(\n",
        "                    self.input_data,\n",
        "                    [self.policy, self.value],\n",
        "                    verbose=0,\n",
        "                    batch_size=self.batch,\n",
        "                )\n",
        "                print(f\"{val=}\")\n",
        "\n",
        "    def save_model(self, name):\n",
        "        self.model.save(name)\n",
        "        files.download(name)\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Trace les courbes des pertes et métriques en fonction des époques.\"\"\"\n",
        "        epochs = range(1, len(self.loss_total) + 1)  # Liste des époques\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Graphique des pertes\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.loss_total, label=\"Loss totale\", marker=\"o\")\n",
        "        plt.plot(epochs, self.policy_loss, label=\"Policy Loss\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_loss, label=\"Value Loss\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur de la perte\")\n",
        "        plt.title(\"Évolution des pertes\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Graphique des métriques\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.policy_acc, label=\"Policy Accuracy\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_mse, label=\"Value MSE\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur des métriques\")\n",
        "        plt.title(\"Évolution des métriques\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Affichage\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def log_accuracy(self, results_dict={}):\n",
        "        \"\"\"Logs the model’s last accuracy into the given dictionary.\"\"\"\n",
        "        results_dict[self.__class__.__name__] = {\n",
        "          \"instance\": self,\n",
        "          \"accuracy\": self.policy_acc[-1]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXuo5huH7cIy"
      },
      "outputs": [],
      "source": [
        "def save_best_model(results_dict, model_name=\"test.h5\"):\n",
        "    \"\"\"\n",
        "    Returns the class instance with the highest accuracy from the dictionary.\n",
        "    \"\"\"\n",
        "    if not results_dict:\n",
        "        return None  # Handle empty dictionary case\n",
        "\n",
        "    # Find the key with the max accuracy\n",
        "    best_model_key = max(results_dict, key=lambda k: results_dict[k][\"accuracy\"])\n",
        "\n",
        "    # Retrieve the best accuracy\n",
        "    best_accuracy = results_dict[best_model_key][\"accuracy\"]\n",
        "\n",
        "    # Retrieve the best instance\n",
        "    best_instance = results_dict[best_model_key][\"instance\"]\n",
        "\n",
        "    print(f\"Le réseau {best_model_key} est celui qui a enregistré la meilleur accuracy : {best_accuracy}\")\n",
        "\n",
        "    best_instance.save_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons définir un dictionnaire intitulé `log_accuracy_dict` qui contiendra les *accuracies* successives pour chaque réseau. Ce dernier constituera un historique des performances des réseaux entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-uT2eey8Ph0"
      },
      "outputs": [],
      "source": [
        "log_accuracy_dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNWs9l8L0bWx"
      },
      "source": [
        "Création de la classe `GONetDemo`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfuVC90KRFDQ"
      },
      "outputs": [],
      "source": [
        "class GONetDemo(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation(\"softmax\", name=\"policy\")(policy_head)\n",
        "        value_head = layers.Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = layers.Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "\n",
        "        model = keras.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "            loss={\n",
        "                \"policy\": \"categorical_crossentropy\",\n",
        "                \"value\": \"binary_crossentropy\",\n",
        "            },\n",
        "            loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "            metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def set_model(self):\n",
        "        input_layer = keras.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        x = layers.Conv2D(self.filters, 1, activation=\"relu\", padding=\"same\")(\n",
        "            input_layer\n",
        "        )\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(\n",
        "                self.filters, 3, activation=\"relu\", padding=\"same\"\n",
        "            )(x)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVZ_rb1QVelh",
        "outputId": "91a71821-394d-4f8d-93b5-be8deffe2578"
      },
      "outputs": [],
      "source": [
        "GONetDemo_instance = GONetDemo()\n",
        "GONetDemo_instance.set_model()\n",
        "GONetDemo_instance.train_model(20)\n",
        "GONetDemo_instance.plot_training_history()\n",
        "GONetDemo_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEV7ZUUU0g-3"
      },
      "source": [
        "Création de la classe `GONetRes_cnn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSmJCGWqpZ8F"
      },
      "outputs": [],
      "source": [
        "class GONetRes_cnn(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def set_model(self, filters=32, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y720WYUsq7--",
        "outputId": "e44cd560-bfe4-4226-c039-8184a259149d"
      },
      "outputs": [],
      "source": [
        "GONetRes_cnn_instance = GONetRes_cnn()\n",
        "GONetRes_cnn_instance.set_model()\n",
        "GONetRes_cnn_instance.train_model(20)\n",
        "GONetRes_cnn_instance.plot_training_history()\n",
        "GONetRes_cnn_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t71Qs2Rg0lS6"
      },
      "source": [
        "## Création de la classe `GONetRes_resnet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iofDxz7OsGh_"
      },
      "outputs": [],
      "source": [
        "class GONetRes_resnet(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def residual_block(self, x, filters):\n",
        "        shortcut = x\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def set_model(self, filters=64, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = self.residual_block(x, filters)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bwkWX5hfs2s6",
        "outputId": "80a31476-61a3-4176-b067-53154d14c857"
      },
      "outputs": [],
      "source": [
        "GONetRes_resnet_instance = GONetRes_resnet()\n",
        "GONetRes_resnet_instance.set_model()\n",
        "GONetRes_resnet_instance.train_model(20)\n",
        "GONetRes_resnet_instance.plot_training_history()\n",
        "GONetRes_resnet_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "1zImqELY55Zh",
        "outputId": "ed575033-8004-40a1-fd13-32b470a1ea55"
      },
      "outputs": [],
      "source": [
        "save_best_model(log_accuracy_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
