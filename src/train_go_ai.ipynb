{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqnIOf1oB2r9"
      },
      "source": [
        "# Entraînement d'un réseau de neurones pour jouer au Go\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/auduvignac/deep_learning_go/blob/main/src/train_go_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGW-Bl5SB2r_"
      },
      "source": [
        "## Description\n",
        "\n",
        "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
        "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
        "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
        "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
        "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
        "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
        "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
        "  - Couleur au trait  \n",
        "  - Échelles  \n",
        "  - État actuel sur deux plans  \n",
        "  - Deux états précédents sur plusieurs plans  \n",
        "- Les cibles de sortie sont :  \n",
        "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
        "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
        "\n",
        "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
        "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
        "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
        "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
        "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
        "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
        "\n",
        "## Tournois\n",
        "\n",
        "- Toutes les deux semaines environ, j'organiserai un tournoi entre les réseaux que vous téléchargez.  \n",
        "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
        "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
        "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
        "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
        "\n",
        "## Exemple de réseau\n",
        "\n",
        "```python\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 20\n",
        "batch = 128\n",
        "filters = 32\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input)\n",
        "for i in range (5):\n",
        "  x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "for i in range (1, epochs + 1):\n",
        "  print ('epoch ' + str (i))\n",
        "  golois.getBatch (input_data, policy, value, end, groups, i * N)\n",
        "  history = model.fit(input_data,\n",
        "  {'policy': policy, 'value': value},\n",
        "  epochs=1, batch_size=batch)\n",
        "  if (i % 5 == 0):\n",
        "  gc.collect ()\n",
        "  if (i % 20 == 0):\n",
        "  golois.getValidation (input_data, policy, value, end)\n",
        "  val = model.evaluate (input_data,\n",
        "  [policy, value], verbose = 0, batch_size=batch)\n",
        "  print (\"val =\", val)\n",
        "  model.save ('test.h5')\n",
        "```\n",
        "\n",
        "## Instructions :  \n",
        "- Entraînez un réseau pour jouer au Go.  \n",
        "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
        "- Tournoi des réseaux **chaque dimanche**.  \n",
        "- Téléchargez un réseau **avant la fin de la session**.\n",
        "\n",
        "## Mise en place de l'environnement de travail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons tout d'abord installer l'archive de l'API de Go et la bibliothèque Golois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VvTcnNjdcrGe",
        "outputId": "0e070fed-c4a7-485b-f070-1b115eb7235a"
      },
      "outputs": [],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
        "!unzip project2025.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensuite, nous allons installer les dépendances nécessaires à l'entraînement du réseau de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LXj_yFKDbhiI",
        "outputId": "893b147b-b1b6-4faa-9a3e-355038727a76"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorrt-bindings==8.6.1\n",
        "!pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
        "!pip install tensorflow[and-cuda]==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remarque importante :** Cette étape réalisée, il est nécessaire de redémmarer la session par l'intermédiaire de l'onglet « Exécution » et « Redémarrer le session »."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rappels Apprentissage par renforcement\n",
        "\n",
        "### Optimisation des récompenses et recherche de politique (agent et politique)\n",
        "\n",
        "« L'apprentissage par renforcement (en anglais, *reinforcement learning*, ou RL) est la branche de l'apprentissage automatique qui consiste à apprendre comment un agent doit se comporter dans un environnement de manière à maximiser une récompense. Naturellement, l’apprentissage par renforcement profond restreint la méthode d'apprentissage à l'apprentissage profond » ([Charniak, E. (2019). *Introduction au Deep Learning*. Dunod. p. 105](https://www.dunod.com/sciences-techniques/introduction-au-deep-learning)).\n",
        "\n",
        "« Dans l'apprentissage par renforcement, un agent logiciel procède à des observations et réalise des actions au sein d'un environnement. En retour, il reçoit des récompenses. Son objectif est d'apprendre à agir de façon à maximiser les récompenses espérées sur le long terme » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 440](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
        "\n",
        "« L'algorithme que l'agent logiciel utilise pour déterminer ses actions est appelé stratégie ou politique (*policy*). Cette politique peut être un réseau de neurones qui prend en entrée des observations et produit en sortie l'action à réaliser » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 441](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
        "\n",
        "\n",
        "Dans le cas du jeu de go: \n",
        "- L'agent est le programme qui joue au jeu ;\n",
        "- L'environnement est le plateau de jeu ;\n",
        "- Les récompenses sont les points gagnés ou perdus lors d'une partie ;\n",
        "- La politique définit la manière dont l'agent choisit ses coups en fonction de l'état du plateau, dans le but de maximiser ses gains à long terme.\n",
        "\n",
        "\n",
        "L'objectif de ce projet est de concevoir un réseau de neurones permettant de jouer au jeu de go. La figure ci-dessous (cf. [Pumperla, M., & Ferguson, K. (2019). *Deep Learning and the Game of Go*. Manning Publications. p.117](https://www.amazon.fr/Deep-Learning-Game-Max-Pumperla/dp/1617295329)) illustre comment les sorties du réseau, représentant les probabilités associées aux coups possibles, sont utilisées pour déterminer l'action optimale à effectuer.\n",
        "\n",
        "![Neural network go](https://raw.githubusercontent.com/auduvignac/deep_learning_go/refs/heads/main/figures/go_explanation_deep_annotated.png?token=GHSAT0AAAAAADA7LSSO5U4CC4HBJZQI5X2YZ7AGJBQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4CT2R1qaB1"
      },
      "source": [
        "## Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAcwAJJ9qZF7"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import gc # garbage collector\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import golois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtixgy9JqeA7"
      },
      "source": [
        "## Création de la classe abstraite `GONet`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La classe abstraite `GONet` permet de définir les méthodes communes à tous les réseaux de neurones qui joueront au jeu de Go. Elle contient des méthodes pour la création du modèle, l'entraînement, l'évaluation et la sauvegarde du modèle. Cette classe est conçue pour être étendue par d'autres classes qui implémenteront des architectures spécifiques de réseaux de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_6C3MiaVelc"
      },
      "outputs": [],
      "source": [
        "class GONet(ABC):\n",
        "    \"\"\"\n",
        "    Classe abstraite pour la construction d'un réseau de neurones pour le jeu de Go.\n",
        "\n",
        "    Cette classe initialise des données simulées, définit les entrées et sorties du modèle,\n",
        "    permet la construction de têtes de prédiction (politique et valeur), et gère l'entraînement\n",
        "    et l'évaluation.\n",
        "\n",
        "    Les sous-classes doivent obligatoirement implémenter `set_backbone()`, qui définit l'architecture du corps principal du réseau.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialise les paramètres et génère les données d'entraînement aléatoires.\n",
        "\n",
        "        Args:\n",
        "            moves (int): Nombre total de coups possibles (361 pour un plateau 19x19).\n",
        "            N (int): Nombre d'exemples dans le jeu de données.\n",
        "            planes (int): Nombre de plans utilisés en entrée pour représenter le plateau.\n",
        "        \"\"\"\n",
        "        self.moves = moves\n",
        "        self.N = N\n",
        "        self.planes = planes\n",
        "        self.set_input_data()\n",
        "        self.set_policy()\n",
        "        self.set_value()\n",
        "        self.set_end()\n",
        "        self.set_groups()\n",
        "        self.set_input_layer()\n",
        "        golois.getValidation(\n",
        "            self.input_data, self.policy, self.value, self.end\n",
        "        )\n",
        "        self.loss_total = []\n",
        "        self.policy_loss = []\n",
        "        self.value_loss = []\n",
        "        self.policy_acc = []\n",
        "        self.value_mse = []\n",
        "\n",
        "    def set_input_data(self):\n",
        "        \"\"\"\n",
        "        Génère les données d'entrée du réseau sous forme de tenseurs aléatoires.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.input_data (forme: [N, 19, 19, planes])\n",
        "        \"\"\"\n",
        "        input_data = np.random.randint(2, size=(self.N, 19, 19, self.planes))\n",
        "        self.input_data = input_data.astype(\"float32\")\n",
        "\n",
        "    def set_policy(self):\n",
        "        \"\"\"\n",
        "        Génère des cibles de politique sous forme one-hot encodées.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.policy (forme: [N, moves])\n",
        "        \"\"\"\n",
        "        policy = np.random.randint(self.moves, size=(self.N,))\n",
        "        self.policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "    def set_value(self):\n",
        "        \"\"\"\n",
        "        Génère des valeurs de victoire (0 ou 1) aléatoires.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.value (forme: [N])\n",
        "        \"\"\"\n",
        "        value = np.random.randint(2, size=(self.N,))\n",
        "        self.value = value.astype(\"float32\")\n",
        "\n",
        "    def set_end(self):\n",
        "        \"\"\"\n",
        "        Génère des représentations aléatoires de fin de partie.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.end (forme: [N, 19, 19, 2])\n",
        "        \"\"\"\n",
        "        end = np.random.randint(2, size=(self.N, 19, 19, 2))\n",
        "        self.end = end.astype(\"float32\")\n",
        "\n",
        "    def set_groups(self):\n",
        "        \"\"\"\n",
        "        Initialise des groupes de pierres à zéro (ex: pour analyse de connexité).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.groups (forme: [N, 19, 19, 1])\n",
        "        \"\"\"\n",
        "        groups = np.zeros((self.N, 19, 19, 1))\n",
        "        self.groups = groups.astype(\"float32\")\n",
        "\n",
        "    def set_input_layer(self):\n",
        "        \"\"\"\n",
        "        Définit la couche d'entrée du modèle.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.input_layer (couche d'entrée)\n",
        "        \"\"\"\n",
        "        # Couche d'entrée : plateau de Go 19x19 avec P plans de caractéristiques\n",
        "        self.input_layer = keras.Input(\n",
        "            shape=(19, 19, self.planes), name=\"board\"\n",
        "        )\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Méthode abstraite pour définir le tronc du modèle (blocs convolutifs, etc.).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Doit être implémentée dans une sous-classe.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\n",
        "            \"set_backbone() must be implemented in subclasses\"\n",
        "        )\n",
        "\n",
        "    def create_policy_value_heads(self):\n",
        "        \"\"\"\n",
        "        Crée les en-têtes de sortie du modèle : politique (softmax) et valeur (sigmoïde).\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Sortie du tronc du modèle.\n",
        "            input_layer (Tensor): Couche d'entrée du modèle.\n",
        "\n",
        "        Returns:\n",
        "            keras.Model: Modèle compilé avec têtes de sortie et métriques définies.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # En-tête de politique\n",
        "            policy_head = layers.Conv2D(\n",
        "                1,\n",
        "                1,\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(self.x)\n",
        "            policy_head = layers.Flatten()(policy_head)\n",
        "            policy_head = layers.Activation(\"softmax\", name=\"policy\")(\n",
        "                policy_head\n",
        "            )\n",
        "            # En-tête de valeur\n",
        "            value_head = layers.Conv2D(\n",
        "                1,\n",
        "                1,\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(self.x)\n",
        "            value_head = layers.Flatten()(value_head)\n",
        "            value_head = layers.Dense(\n",
        "                50,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(value_head)\n",
        "            value_head = layers.Dense(\n",
        "                1,\n",
        "                activation=\"sigmoid\",\n",
        "                name=\"value\",\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(value_head)\n",
        "\n",
        "            model = keras.Model(\n",
        "                inputs=self.input_layer, outputs=[policy_head, value_head]\n",
        "            )\n",
        "\n",
        "            model.summary()\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=keras.optimizers.SGD(\n",
        "                    learning_rate=0.0005, momentum=0.9\n",
        "                ),\n",
        "                loss={\n",
        "                    \"policy\": \"categorical_crossentropy\",\n",
        "                    \"value\": \"binary_crossentropy\",\n",
        "                },\n",
        "                loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "                metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "            )\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return\n",
        "\n",
        "    def set_model(self):\n",
        "        self.model = self.create_policy_value_heads()\n",
        "\n",
        "    def train_model(self, batch=128, epochs=20):\n",
        "        \"\"\"\n",
        "        Entraîne le modèle en plusieurs époques avec suivi des métriques.\n",
        "\n",
        "        Args:\n",
        "            batch (int): Taille du batch d'entraînement.\n",
        "            epochs (int): Nombre total d'époques.\n",
        "\n",
        "        Returns:\n",
        "            None: Met à jour l'historique d'entraînement.\n",
        "        \"\"\"\n",
        "        for i in range(1, epochs + 1):\n",
        "            print(f\"epoch {str(i)}\")\n",
        "            golois.getBatch(\n",
        "                self.input_data,\n",
        "                self.policy,\n",
        "                self.value,\n",
        "                self.end,\n",
        "                self.groups,\n",
        "                i * self.N,\n",
        "            )\n",
        "            history = self.model.fit(\n",
        "                self.input_data,\n",
        "                {\"policy\": self.policy, \"value\": self.value},\n",
        "                epochs=1,\n",
        "                batch_size=batch,\n",
        "            )\n",
        "            # Extraction des valeurs depuis history.history\n",
        "            self.loss_total.append(history.history[\"loss\"][0])  # Loss globale\n",
        "            self.policy_loss.append(\n",
        "                history.history[\"policy_loss\"][0]\n",
        "            )  # Policy loss\n",
        "            self.value_loss.append(\n",
        "                history.history[\"value_loss\"][0]\n",
        "            )  # Value loss\n",
        "            self.policy_acc.append(\n",
        "                history.history[\"policy_categorical_accuracy\"][0]\n",
        "            )  # Policy accuracy\n",
        "            self.value_mse.append(history.history[\"value_mse\"][0])  # Value MSE\n",
        "            if i % 5 == 0:\n",
        "                gc.collect()\n",
        "            if i % 20 == 0:\n",
        "                golois.getValidation(\n",
        "                    self.input_data, self.policy, self.value, self.end\n",
        "                )\n",
        "                val = self.model.evaluate(\n",
        "                    self.input_data,\n",
        "                    [self.policy, self.value],\n",
        "                    verbose=0,\n",
        "                    batch_size=batch,\n",
        "                )\n",
        "                print(f\"{val=}\")\n",
        "\n",
        "    def save_model(self, name):\n",
        "        \"\"\"\n",
        "        Sauvegarde le modèle et déclenche le téléchargement dans le fichier dédié.\n",
        "\n",
        "        Args:\n",
        "            name (str): Nom de fichier pour enregistrer le modèle (.h5, etc.)\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.model.save(name)\n",
        "        files.download(name)\n",
        "\n",
        "    def plot_model(self):\n",
        "        plot_model(self.model, show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"\n",
        "        Affiche les courbes d'apprentissage pour les pertes et métriques (par époque).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affiche un graphique matplotlib.\n",
        "        \"\"\"\n",
        "        epochs = range(1, len(self.loss_total) + 1)  # Liste des époques\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Graphique des pertes\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.loss_total, label=\"Loss totale\", marker=\"o\")\n",
        "        plt.plot(epochs, self.policy_loss, label=\"Policy Loss\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_loss, label=\"Value Loss\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur de la perte\")\n",
        "        plt.title(\"Évolution des pertes\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Graphique des métriques\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.policy_acc, label=\"Policy Accuracy\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_mse, label=\"Value MSE\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur des métriques\")\n",
        "        plt.title(\"Évolution des métriques\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Affichage\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def log_accuracy(self, results_dict={}):\n",
        "        \"\"\"\n",
        "        Enregistre la dernière précision de la tête \"policy\" dans un dictionnaire.\n",
        "\n",
        "        Args:\n",
        "            results_dict (dict): Dictionnaire auquel ajouter les résultats.\n",
        "\n",
        "        Returns:\n",
        "            None: Met à jour results_dict avec l'accuracy du modèle.\n",
        "        \"\"\"\n",
        "        results_dict[self.__class__.__name__] = {\n",
        "            \"instance\": self,\n",
        "            \"accuracy\": self.policy_acc[-1],\n",
        "        }\n",
        "\n",
        "    def workflow(\n",
        "        self, epochs=20, batch=128, name=\"model.h5\", log_accuracy_dict={}\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Exécute le flux de travail complet : construction, entraînement et évaluation du modèle.\n",
        "\n",
        "        Args:\n",
        "            epochs (int): Nombre d'époques pour l'entraînement.\n",
        "            batch (int): Taille du batch pour l'entraînement.\n",
        "            name (str): Nom du fichier pour enregistrer le modèle.\n",
        "            log_accuracy_dict (dict): Dictionnaire pour enregistrer les résultats d'accuracy.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.set_backbone()\n",
        "        self.set_model()\n",
        "        self.train_model(epochs=epochs, batch=batch)\n",
        "        self.save_model(name=name)\n",
        "        self.plot_training_history()\n",
        "        self.log_accuracy(results_dict=log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXuo5huH7cIy"
      },
      "outputs": [],
      "source": [
        "def save_best_model(results_dict, model_name=\"test.h5\"):\n",
        "    \"\"\"\n",
        "    Sauvegarde le modèle ayant obtenu la meilleure précision (accuracy) à partir d'un dictionnaire de résultats.\n",
        "\n",
        "    Le dictionnaire 'results_dict' doit contenir, pour chaque clé (nom du modèle), une structure :\n",
        "        {\n",
        "            \"instance\": instance_du_modèle,\n",
        "            \"accuracy\": précision_obtenue (float)\n",
        "        }\n",
        "\n",
        "    La fonction identifie l'entrée avec la précision maximale, affiche un résumé,\n",
        "    et sauvegarde l'instance correspondante au format Keras (.h5) sous le nom spécifié.\n",
        "\n",
        "    Paramètres\n",
        "    ----------\n",
        "    results_dict : dict\n",
        "        Dictionnaire contenant les modèles et leurs précisions associées.\n",
        "\n",
        "    model_name : str\n",
        "        Nom du fichier dans lequel sauvegarder le meilleur modèle (format .h5).\n",
        "\n",
        "    Retourne\n",
        "    --------\n",
        "    None\n",
        "    \"\"\"\n",
        "    if not results_dict:\n",
        "        return None  # Handle empty dictionary case\n",
        "\n",
        "    # Recherche le modèle avec la meilleure précision\n",
        "    best_model_key = max(\n",
        "        results_dict, key=lambda k: results_dict[k][\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # garder en mémoire la meilleure précision\n",
        "    best_accuracy = results_dict[best_model_key][\"accuracy\"]\n",
        "\n",
        "    # et l'instance du modèle\n",
        "    best_instance = results_dict[best_model_key][\"instance\"]\n",
        "\n",
        "    print(\n",
        "        f\"Le réseau {best_model_key} est celui qui a enregistré la meilleur accuracy : {best_accuracy}\"\n",
        "    )\n",
        "\n",
        "    best_instance.save_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons définir un dictionnaire intitulé `log_accuracy_dict` qui contiendra les *accuracies* successives pour chaque réseau. Ce dernier constituera un historique des performances des réseaux entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-uT2eey8Ph0"
      },
      "outputs": [],
      "source": [
        "log_accuracy_dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNWs9l8L0bWx"
      },
      "source": [
        "Création de la classe `GONetDemo`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfuVC90KRFDQ"
      },
      "outputs": [],
      "source": [
        "class GONetDemo(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Définit l'architecture du tronc du réseau de neurones.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.x (sortie du tronc)\n",
        "        \"\"\"\n",
        "        filters = 32\n",
        "        x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(\n",
        "            self.input_layer\n",
        "        )\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVZ_rb1QVelh",
        "outputId": "91a71821-394d-4f8d-93b5-be8deffe2578"
      },
      "outputs": [],
      "source": [
        "GONetDemo_instance = GONetDemo()\n",
        "GONetDemo_instance.workflow(\n",
        "    epochs=2,\n",
        "    batch=128,\n",
        "    name=\"gonetdemo.h5\",\n",
        "    log_accuracy_dict=log_accuracy_dict,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Réseaux de neurones résiduels\n",
        "\n",
        "La couche standard utilisée dans les programmes de Go computationnel tels que AlphaGo \\cite{AlphaGo} et DarkForest \\cite{DarkForest} est généralement constituée d’une couche convolutionnelle suivie d’une activation ReLU, comme illustré en Figure~1.\n",
        "\n",
        "La couche résiduelle, souvent utilisée pour des tâches de classification d’images, consiste à additionner l’entrée de la couche avec sa sortie. Elle est composée de deux couches convolutionnelles consécutives, entre lesquelles des activations ReLU sont appliquées après la première convolution et après l’opération d’addition. Cette structure est représentée en Figure~2. Nous envisageons d’exploiter ce type de couches résiduelles dans le cadre de nos réseaux dédiés au jeu de Go.\n",
        "\n",
        "La couche d’entrée de nos réseaux pour le Go adopte elle aussi une structure résiduelle. Elle repose sur une combinaison parallèle de deux couches convolutionnelles : l’une de taille $5 \\times 5$ et l’autre de taille $1 \\times 1$. Leurs sorties respectives sont additionnées, puis une activation ReLU est appliquée. Cette architecture est illustrée en Figure~3.\n",
        "\n",
        "La couche de sortie du réseau est constituée d’une couche convolutionnelle de taille $3 \\times 3$, produisant un unique plan de sortie, suivie d’une fonction d’activation SoftMax. L’ensemble des couches cachées du réseau utilise des filtres de taille $3 \\times 3$ avec 256 plans de caractéristiques.\n",
        "\n",
        "Dans le cadre de cet article, nous définissons la profondeur d’un réseau comme étant le nombre total de couches convolutionnelles. Ainsi, un réseau à 28 couches comprend 28 couches convolutionnelles, correspondant à 14 blocs résiduels tels que décrits en Figure~2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetRes_residual(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def residual_block(self, x, filters, name_prefix):\n",
        "        skip = x\n",
        "        x = layers.Conv2D(\n",
        "            filters,\n",
        "            3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            name=f\"{name_prefix}_conv1\",\n",
        "        )(x)\n",
        "        x = layers.Conv2D(\n",
        "            filters, 3, padding=\"same\", name=f\"{name_prefix}_conv2\"\n",
        "        )(x)\n",
        "        x = layers.Add(name=f\"{name_prefix}_add\")([x, skip])\n",
        "        x = layers.Activation(\"relu\", name=f\"{name_prefix}_relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def go_residual_input(self, x, filters):\n",
        "        conv_5x5 = layers.Conv2D(\n",
        "            filters, 5, padding=\"same\", name=\"input_conv5x5\"\n",
        "        )(x)\n",
        "        conv_1x1 = layers.Conv2D(\n",
        "            filters, 1, padding=\"same\", name=\"input_conv1x1\"\n",
        "        )(x)\n",
        "        x = layers.Add(name=\"input_add\")([conv_5x5, conv_1x1])\n",
        "        x = layers.Activation(\"relu\", name=\"input_relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def set_backbone(self, filters=256, n_blocks=14):\n",
        "        x = self.go_residual_input(self.input_layer, filters)\n",
        "        for i in range(n_blocks):\n",
        "            x = self.residual_block(x, filters, name_prefix=f\"res{i+1}\")\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetRes_residual_instance = GONetRes_residual()\n",
        "GONetRes_residual_instance.set_backbone()\n",
        "GONetRes_residual_instance.train_model(epochs=2)\n",
        "GONetRes_residual_instance.plot_training_history()\n",
        "GONetRes_residual_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEV7ZUUU0g-3"
      },
      "source": [
        "Création de la classe `GONetRes_cnn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSmJCGWqpZ8F"
      },
      "outputs": [],
      "source": [
        "class GONetRes_cnn(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def set_model(self, filters=32, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y720WYUsq7--",
        "outputId": "e44cd560-bfe4-4226-c039-8184a259149d"
      },
      "outputs": [],
      "source": [
        "GONetRes_cnn_instance = GONetRes_cnn()\n",
        "GONetRes_cnn_instance.set_model()\n",
        "GONetRes_cnn_instance.train_model(20)\n",
        "GONetRes_cnn_instance.plot_training_history()\n",
        "GONetRes_cnn_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t71Qs2Rg0lS6"
      },
      "source": [
        "## Création de la classe `GONetRes_resnet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iofDxz7OsGh_"
      },
      "outputs": [],
      "source": [
        "class GONetRes_resnet(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def residual_block(self, x, filters):\n",
        "        shortcut = x\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def set_model(self, filters=64, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = self.residual_block(x, filters)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bwkWX5hfs2s6",
        "outputId": "80a31476-61a3-4176-b067-53154d14c857"
      },
      "outputs": [],
      "source": [
        "GONetRes_resnet_instance = GONetRes_resnet()\n",
        "GONetRes_resnet_instance.set_model()\n",
        "GONetRes_resnet_instance.train_model(20)\n",
        "GONetRes_resnet_instance.plot_training_history()\n",
        "GONetRes_resnet_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "1zImqELY55Zh",
        "outputId": "ed575033-8004-40a1-fd13-32b470a1ea55"
      },
      "outputs": [],
      "source": [
        "save_best_model(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Compare Resnets, Mobilenets and Convnexts, Shufflenet by training on the game of go**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *Shufflenet*\n",
        "\n",
        "*ShuffleNet* est une architecture de réseau neuronal conçue pour être rapide et efficace. Elle repose sur le concept de permutation des canaux du tenseur d’entrée, ce qui améliore l’efficacité en termes de calcul et d’utilisation de la mémoire.\n",
        "\n",
        "Le réseau se compose de deux principales parties :\n",
        "\n",
        "1.  Couche de convolution : Cette couche a pour rôle d’extraire les caractéristiques du tenseur d’entrée.\n",
        "\n",
        "2.  Couche de permutation (*shuffling*) : Cette couche permutent les canaux du tenseur d’entrée. Elle est conçue pour être légère et efficace, ce qui contribue fortement à la performance globale et à l’efficacité du réseau\n",
        "\n",
        "*Shufflenet* est un mobilenet avec moins de paramètres puisqu'il y a des plans séparés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    DepthwiseConv2D,\n",
        "    Dense,\n",
        "    Concatenate,\n",
        "    Add,\n",
        "    ReLU,\n",
        "    BatchNormalization,\n",
        "    AvgPool2D,\n",
        "    MaxPool2D,\n",
        "    GlobalAveragePooling2D,\n",
        "    Reshape,\n",
        "    Permute,\n",
        "    Lambda,\n",
        "    Flatten,\n",
        "    Activation,\n",
        ")\n",
        "\n",
        "\n",
        "class GONetRes_shufflenet(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch=128,\n",
        "        epochs=20,\n",
        "        filters=32,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "        trunk=32,  # trunk (hyperparamètre) : nombre de filtres dans le tronc (32, 64, etc.). Dans le modèle de go il est de l'ordre de 32.\n",
        "        blocks=5,  # blocks : nombre de blocs résiduels\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "        self.trunk = trunk\n",
        "        self.blocks = blocks\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        input = keras.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        x = Conv2D(\n",
        "            self.trunk,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        for i in range(self.blocks):\n",
        "            x = self.bottleneck_block(x, self.filters, self.trunk)\n",
        "        policy_head = Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = Flatten()(policy_head)\n",
        "        policy_head = Activation(\"softmax\", name=\"policy\")(policy_head)\n",
        "        value_head = GlobalAveragePooling2D()(x)\n",
        "        value_head = Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "        model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "        return model\n",
        "\n",
        "    def bottleneck_block(self, tensor, expand=96, squeeze=16):\n",
        "        x = self.gconv(tensor, channels=expand, groups=4)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = self.channel_shuffle(x, groups=4)\n",
        "        # Depthwise (comme dans les mobilenets)\n",
        "        x = DepthwiseConv2D(kernel_size=3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = self.gconv(x, channels=squeeze, groups=4)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Add()([tensor, x])\n",
        "        # Les connexions résiduelles ajoutent de la souplesse et permettre de\n",
        "        # rendre les réseaux plus entraînables\n",
        "        output = ReLU()(x)\n",
        "        return output\n",
        "\n",
        "    def gconv(tensor, channels, groups):\n",
        "        \"\"\"\n",
        "        gconv permet de faire un groupe de convolution sur l'entrée du tenseur\n",
        "\n",
        "        Args:\n",
        "            tensor (_type_): _description_\n",
        "            channels (_type_): _description_\n",
        "            groups (_type_): _description_\n",
        "\n",
        "        Returns:\n",
        "            _type_: _description_\n",
        "        \"\"\"\n",
        "        input_ch = tensor.get_shape().as_list()[-1]\n",
        "        group_ch = input_ch // groups\n",
        "        output_ch = channels // groups\n",
        "        groups_list = []\n",
        "        for i in range(groups):\n",
        "            group_tensor = tensor[:, :, :, i * group_ch : (i + 1) * group_ch]\n",
        "            group_tensor = Conv2D(output_ch, 1)(group_tensor)\n",
        "            groups_list.append(group_tensor)\n",
        "        output = Concatenate()(groups_list)\n",
        "        return output\n",
        "\n",
        "    def channel_shuffle(self, x, groups):\n",
        "        _, width, height, channels = x.get_shape().as_list()\n",
        "        group_ch = channels // groups\n",
        "        x = Reshape([width, height, group_ch, groups])(x)\n",
        "        x = Permute([1, 2, 4, 3])(x)\n",
        "        x = Reshape([width, height, channels])(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glossaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Réseau de neurones *feed forward* :\n",
        "\n",
        "« Un réseau de neurones à propagation avant, en anglais *feed forward neural network*, est un réseau de neurones artificiels acyclique, se distinguant ainsi des réseaux de neurones récurrents. Le plus connu est le perceptron multicouche qui est une extension du premier réseau de neurones artificiel. Le perceptron a été inventé en 1957 par Frank Rosenblatt.\n",
        "\n",
        "Le réseau de neurones à propagation avant a été le premier et le plus simple type de réseau neuronal artificiel conçu. Typiquement, il ne comportait qu'une seule couche cachée et s'appelait perceptron. Dans ce réseau, l'information ne se déplace que dans une seule direction, vers l'avant, à partir des nœuds d'entrée, en passant par les couches cachées (le cas échéant) et vers les nœuds de sortie. Il n'y a pas de cycles ou de boucles dans ce réseau. C'est pourquoi on le désigne parfois par réseau de neurones sans boucle.\n",
        "\n",
        "Quand le réseau de neurones à propagation avant comporte plusieurs couches cachées, on parle habituellement d'un perceptron multicouche. » (cf. [Réseau de neurones *feed forward*](https://datafranca.org/wiki/R%C3%A9seau_de_neurones_%C3%A0_propagation_avant))\n",
        "\n",
        "\n",
        "\n",
        "![Réseau de neurones *feed forward*](https://upload.wikimedia.org/wikipedia/commons/8/82/FeedForwardNN.png)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
