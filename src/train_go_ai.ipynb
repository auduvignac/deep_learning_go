{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqnIOf1oB2r9"
      },
      "source": [
        "# Entraînement d'un réseau de neurones pour jouer au Go\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/auduvignac/deep_learning_go/blob/main/src/train_go_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGW-Bl5SB2r_"
      },
      "source": [
        "## Description\n",
        "\n",
        "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
        "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
        "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
        "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
        "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
        "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
        "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
        "  - Couleur au trait  \n",
        "  - Échelles  \n",
        "  - État actuel sur deux plans  \n",
        "  - Deux états précédents sur plusieurs plans  \n",
        "- Les cibles de sortie sont :  \n",
        "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
        "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
        "\n",
        "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
        "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
        "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
        "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
        "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
        "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
        "\n",
        "## Tournois\n",
        "\n",
        "- Toutes les deux semaines environ, j'organiserai un tournoi entre les réseaux que vous téléchargez.  \n",
        "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
        "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
        "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
        "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
        "\n",
        "## Exemple de réseau\n",
        "\n",
        "```python\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import gc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import golois\n",
        "\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 20\n",
        "batch = 128\n",
        "filters = 32\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype(\"float32\")\n",
        "\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype(\"float32\")\n",
        "\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype(\"float32\")\n",
        "\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype(\"float32\")\n",
        "\n",
        "print(\"Tensorflow version\", tf.__version__)\n",
        "print(\"getValidation\", flush=True)\n",
        "golois.getValidation(input_data, policy, value, end)\n",
        "\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name=\"board\")\n",
        "x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(input)\n",
        "for i in range(5):\n",
        "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "policy_head = layers.Conv2D(\n",
        "    1,\n",
        "    1,\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "    kernel_regularizer=regularizers.l2(0.0001),\n",
        ")(x)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Activation(\"softmax\", name=\"policy\")(policy_head)\n",
        "value_head = layers.Conv2D(\n",
        "    1,\n",
        "    1,\n",
        "    activation=\"relu\",\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "    kernel_regularizer=regularizers.l2(0.0001),\n",
        ")(x)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(\n",
        "    50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        ")(value_head)\n",
        "value_head = layers.Dense(\n",
        "    1,\n",
        "    activation=\"sigmoid\",\n",
        "    name=\"value\",\n",
        "    kernel_regularizer=regularizers.l2(0.0001),\n",
        ")(value_head)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
        "    loss={\n",
        "        \"policy\": \"categorical_crossentropy\",\n",
        "        \"value\": \"binary_crossentropy\",\n",
        "    },\n",
        "    loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "    metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        ")\n",
        "\n",
        "for i in range(1, epochs + 1):\n",
        "    print(\"epoch \" + str(i))\n",
        "    golois.getBatch(input_data, policy, value, end, groups, i * N)\n",
        "    history = model.fit(\n",
        "        input_data,\n",
        "        {\"policy\": policy, \"value\": value},\n",
        "        epochs=1,\n",
        "        batch_size=batch,\n",
        "    )\n",
        "    if i % 5 == 0:\n",
        "        gc.collect()\n",
        "    if i % 20 == 0:\n",
        "        golois.getValidation(input_data, policy, value, end)\n",
        "        val = model.evaluate(\n",
        "            input_data, [policy, value], verbose=0, batch_size=batch\n",
        "        )\n",
        "        print(\"val =\", val)\n",
        "        model.save(\"test.h5\")\n",
        "```\n",
        "\n",
        "## Instructions :  \n",
        "- Entraînez un réseau pour jouer au Go.  \n",
        "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
        "- Tournoi des réseaux **chaque dimanche**.  \n",
        "- Téléchargez un réseau **avant la fin de la session**.\n",
        "\n",
        "## Objectif du projet\n",
        "\n",
        "Ce projet a pour objectif d’implémenter et d’évaluer plusieurs architectures de réseaux de neurones convolutionnels appliquées à la modélisation du jeu de Go. Les architectures ciblées sont les suivantes :\n",
        "\n",
        "- **ResNet** : réseaux résiduels profonds facilitant l’apprentissage de modèles très profonds grâce aux connexions de saut (skip connections).\n",
        "\n",
        "- **MobileNet** : architectures légères conçues pour les environnements contraints, utilisant des convolutions séparables en profondeur (depthwise separable convolutions) pour réduire le nombre de paramètres.\n",
        "\n",
        "- **ConvNeXt** : réseaux convolutionnels modernes inspirés des Transformers, conçus comme une évolution des CNN classiques avec des performances compétitives sur ImageNet.\n",
        "\n",
        "- **ShuffleNet** : modèles optimisés pour l'efficacité computationnelle, combinant group convolutions et opérations de réorganisation (channel shuffle) pour limiter le coût en calcul tout en maintenant de bonnes performances.\n",
        "\n",
        "Ces modèles seront adaptés, entraînés et comparés dans le cadre d’un apprentissage supervisé pour prédire les coups dans des parties de Go.\n",
        "\n",
        "## Mise en place de l'environnement de travail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons tout d'abord installer l'archive de l'API de Go et la bibliothèque Golois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VvTcnNjdcrGe",
        "outputId": "0e070fed-c4a7-485b-f070-1b115eb7235a"
      },
      "outputs": [],
      "source": [
        "#!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
        "#!unzip project2025.zip\n",
        "#!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ensuite, nous allons installer les dépendances nécessaires à l'entraînement du réseau de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LXj_yFKDbhiI",
        "outputId": "893b147b-b1b6-4faa-9a3e-355038727a76"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y tensorflow\n",
        "#!pip install tensorrt-bindings==8.6.1\n",
        "#!pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
        "#!pip install tensorflow[and-cuda]==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Remarque importante :** Cette étape réalisée, il est nécessaire de redémmarer la session par l'intermédiaire de l'onglet « Exécution » et « Redémarrer le session »."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rappels Apprentissage par renforcement\n",
        "\n",
        "### Optimisation des récompenses et recherche de politique (agent et politique)\n",
        "\n",
        "« L'apprentissage par renforcement (en anglais, *reinforcement learning*, ou RL) est la branche de l'apprentissage automatique qui consiste à apprendre comment un agent doit se comporter dans un environnement de manière à maximiser une récompense. Naturellement, l’apprentissage par renforcement profond restreint la méthode d'apprentissage à l'apprentissage profond » ([Charniak, E. (2019). *Introduction au Deep Learning*. Dunod. p. 105](https://www.dunod.com/sciences-techniques/introduction-au-deep-learning)).\n",
        "\n",
        "« Dans l'apprentissage par renforcement, un agent logiciel procède à des observations et réalise des actions au sein d'un environnement. En retour, il reçoit des récompenses. Son objectif est d'apprendre à agir de façon à maximiser les récompenses espérées sur le long terme » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 440](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
        "\n",
        "« L'algorithme que l'agent logiciel utilise pour déterminer ses actions est appelé stratégie ou politique (*policy*). Cette politique peut être un réseau de neurones qui prend en entrée des observations et produit en sortie l'action à réaliser » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 441](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
        "\n",
        "\n",
        "Dans le cas du jeu de go: \n",
        "- L'agent est le programme qui joue au jeu ;\n",
        "- L'environnement est le plateau de jeu ;\n",
        "- Les récompenses sont les points gagnés ou perdus lors d'une partie ;\n",
        "- La politique définit la manière dont l'agent choisit ses coups en fonction de l'état du plateau, dans le but de maximiser ses gains à long terme.\n",
        "\n",
        "\n",
        "L'objectif de ce projet est de concevoir un réseau de neurones permettant de jouer au jeu de go. La figure ci-dessous (cf. [Pumperla, M., & Ferguson, K. (2019). *Deep Learning and the Game of Go*. Manning Publications. p.117](https://www.amazon.fr/Deep-Learning-Game-Max-Pumperla/dp/1617295329)) illustre comment les sorties du réseau, représentant les probabilités associées aux coups possibles, sont utilisées pour déterminer l'action optimale à effectuer.\n",
        "\n",
        "![Neural network go](https://raw.githubusercontent.com/auduvignac/deep_learning_go/refs/heads/main/figures/go_explanation_deep_annotated.png?token=GHSAT0AAAAAADA7LSSO5U4CC4HBJZQI5X2YZ7AGJBQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4CT2R1qaB1"
      },
      "source": [
        "## Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RAcwAJJ9qZF7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-01 13:51:17.701922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-05-01 13:51:17.702225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-05-01 13:51:17.796407: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-01 13:51:17.990834: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-01 13:51:19.821685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "# A décommenter avec Google Colab\n",
        "#from google.colab import files\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import gc # garbage collector\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import golois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtixgy9JqeA7"
      },
      "source": [
        "## Création de la classe abstraite `GONet`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La classe abstraite `GONet` permet de définir les méthodes communes à tous les réseaux de neurones qui joueront au jeu de Go. Elle contient des méthodes pour la création du modèle, l'entraînement, l'évaluation et la sauvegarde du modèle. Cette classe est conçue pour être étendue par d'autres classes qui implémenteront des architectures spécifiques de réseaux de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9_6C3MiaVelc"
      },
      "outputs": [],
      "source": [
        "class GONet(ABC):\n",
        "    \"\"\"\n",
        "    Classe abstraite pour la construction d'un réseau de neurones pour le jeu de Go.\n",
        "\n",
        "    Cette classe initialise des données simulées, définit les entrées et sorties du modèle,\n",
        "    permet la construction de têtes de prédiction (politique et valeur), et gère l'entraînement\n",
        "    et l'évaluation.\n",
        "\n",
        "    Les sous-classes doivent obligatoirement implémenter `set_backbone()`,\n",
        "    qui définit l'architecture du corps principal du réseau.\n",
        "    \n",
        "    La méthode `create_policy_value_heads` en charge de créer les en-têtes\n",
        "    de sortie du modèle (politique et valeur) restera inchangée indépendamment\n",
        "    de la structure du réseau de neurones utilisée.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "        max_params = 100000,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialise les paramètres et génère les données d'entraînement aléatoires.\n",
        "\n",
        "        Args:\n",
        "            moves (int): Nombre total de coups possibles (361 pour un plateau 19x19).\n",
        "            N (int): Nombre d'exemples dans le jeu de données.\n",
        "            planes (int): Nombre de plans utilisés en entrée pour représenter le plateau.\n",
        "        \"\"\"\n",
        "        self.moves = moves\n",
        "        self.N = N\n",
        "        self.planes = planes\n",
        "        self.max_params = max_params\n",
        "        self.set_input_data()\n",
        "        self.set_policy()\n",
        "        self.set_value()\n",
        "        self.set_end()\n",
        "        self.set_groups()\n",
        "        self.set_input_layer()\n",
        "        golois.getValidation(\n",
        "            self.input_data, self.policy, self.value, self.end\n",
        "        )\n",
        "        self.loss_total = []\n",
        "        self.policy_loss = []\n",
        "        self.value_loss = []\n",
        "        self.policy_acc = []\n",
        "        self.value_mse = []\n",
        "\n",
        "    def set_input_data(self):\n",
        "        \"\"\"\n",
        "        Génère les données d'entrée du réseau sous forme de tenseurs aléatoires.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.input_data (forme: [N, 19, 19, planes])\n",
        "        \"\"\"\n",
        "        input_data = np.random.randint(2, size=(self.N, 19, 19, self.planes))\n",
        "        self.input_data = input_data.astype(\"float32\")\n",
        "\n",
        "    def set_policy(self):\n",
        "        \"\"\"\n",
        "        Génère des cibles de politique sous forme one-hot encodées.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.policy (forme: [N, moves])\n",
        "        \"\"\"\n",
        "        policy = np.random.randint(self.moves, size=(self.N,))\n",
        "        self.policy = keras.utils.to_categorical(policy)\n",
        "\n",
        "    def set_value(self):\n",
        "        \"\"\"\n",
        "        Génère des valeurs de victoire (0 ou 1) aléatoires.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.value (forme: [N])\n",
        "        \"\"\"\n",
        "        value = np.random.randint(2, size=(self.N,))\n",
        "        self.value = value.astype(\"float32\")\n",
        "\n",
        "    def set_end(self):\n",
        "        \"\"\"\n",
        "        Génère des représentations aléatoires de fin de partie.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.end (forme: [N, 19, 19, 2])\n",
        "        \"\"\"\n",
        "        end = np.random.randint(2, size=(self.N, 19, 19, 2))\n",
        "        self.end = end.astype(\"float32\")\n",
        "\n",
        "    def set_groups(self):\n",
        "        \"\"\"\n",
        "        Initialise des groupes de pierres à zéro (ex: pour analyse de connexité).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.groups (forme: [N, 19, 19, 1])\n",
        "        \"\"\"\n",
        "        groups = np.zeros((self.N, 19, 19, 1))\n",
        "        self.groups = groups.astype(\"float32\")\n",
        "\n",
        "    def set_input_layer(self):\n",
        "        \"\"\"\n",
        "        Définit la couche d'entrée du modèle.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.input_layer (couche d'entrée)\n",
        "        \"\"\"\n",
        "        # Couche d'entrée : plateau de Go 19x19 avec P plans de caractéristiques\n",
        "        self.input_layer = keras.Input(\n",
        "            shape=(19, 19, self.planes), name=\"board\"\n",
        "        )\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Méthode abstraite pour définir le tronc du modèle (blocs convolutifs, etc.).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Doit être implémentée dans une sous-classe.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\n",
        "            \"set_backbone() must be implemented in subclasses\"\n",
        "        )\n",
        "\n",
        "    def create_policy_value_heads(self):\n",
        "        \"\"\"\n",
        "        Crée les en-têtes de sortie du modèle : politique (softmax) et valeur (sigmoïde).\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Sortie du tronc du modèle.\n",
        "            input_layer (Tensor): Couche d'entrée du modèle.\n",
        "\n",
        "        Returns:\n",
        "            keras.Model: Modèle compilé avec têtes de sortie et métriques définies.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            expected_shape = (None, 19, 19, 32)\n",
        "\n",
        "            for i, (a, e) in enumerate(zip(self.x.shape, expected_shape)):\n",
        "                if e is not None and a != e:\n",
        "                    raise ValueError(\n",
        "                        f\"\"\"\n",
        "                        - Forme inattendue pour self.x : {self.x.shape}.\n",
        "                        - La dimension {i} vaut {a} au lieu de {e} ;\n",
        "                        - Forme attendue complète : {expected_shape}\n",
        "                      \"\"\"\n",
        "                    )\n",
        "            # En-tête de politique\n",
        "            policy_head = layers.Conv2D(\n",
        "                1,\n",
        "                1,\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(self.x)\n",
        "            policy_head = layers.Flatten()(policy_head)\n",
        "            policy_head = layers.Activation(\"softmax\", name=\"policy\")(\n",
        "                policy_head\n",
        "            )\n",
        "            # En-tête de valeur\n",
        "            value_head = layers.Conv2D(\n",
        "                1,\n",
        "                1,\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                use_bias=False,\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(self.x)\n",
        "            value_head = layers.Flatten()(value_head)\n",
        "            value_head = layers.Dense(\n",
        "                50,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(value_head)\n",
        "            value_head = layers.Dense(\n",
        "                1,\n",
        "                activation=\"sigmoid\",\n",
        "                name=\"value\",\n",
        "                kernel_regularizer=regularizers.l2(0.0001),\n",
        "            )(value_head)\n",
        "\n",
        "            model = keras.Model(\n",
        "                inputs=self.input_layer, outputs=[policy_head, value_head]\n",
        "            )\n",
        "\n",
        "            model.summary()\n",
        "\n",
        "            # Vérification du nombre total de paramètres\n",
        "            nb_params = model.count_params()\n",
        "            if nb_params > self.max_params:\n",
        "              raise Exception(f\"\"\"\n",
        "                              Le nombre de paramètres doit être inférieur à {self.max_params}\n",
        "                              \"\"\")\n",
        "            else:\n",
        "              print(f\"\"\"\n",
        "                    Le modèle contient {nb_params} paramètres, inférieur au seuil maximal ({self.max_params}). Traitement poursuivi.\n",
        "                    \"\"\")\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=keras.optimizers.SGD(\n",
        "                    learning_rate=0.0005, momentum=0.9\n",
        "                ),\n",
        "                loss={\n",
        "                    \"policy\": \"categorical_crossentropy\",\n",
        "                    \"value\": \"binary_crossentropy\",\n",
        "                },\n",
        "                loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
        "                metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
        "            )\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return\n",
        "\n",
        "    def set_model(self):\n",
        "        self.model = self.create_policy_value_heads()\n",
        "\n",
        "    def train_model(self, batch=128, epochs=20):\n",
        "        \"\"\"\n",
        "        Entraîne le modèle en plusieurs époques avec suivi des métriques.\n",
        "\n",
        "        Args:\n",
        "            batch (int): Taille du batch d'entraînement.\n",
        "            epochs (int): Nombre total d'époques.\n",
        "\n",
        "        Returns:\n",
        "            None: Met à jour l'historique d'entraînement.\n",
        "        \"\"\"\n",
        "        for i in range(1, epochs + 1):\n",
        "            print(f\"epoch {str(i)}\")\n",
        "            golois.getBatch(\n",
        "                self.input_data,\n",
        "                self.policy,\n",
        "                self.value,\n",
        "                self.end,\n",
        "                self.groups,\n",
        "                i * self.N,\n",
        "            )\n",
        "            history = self.model.fit(\n",
        "                self.input_data,\n",
        "                {\"policy\": self.policy, \"value\": self.value},\n",
        "                epochs=1,\n",
        "                batch_size=batch,\n",
        "            )\n",
        "            # Extraction des valeurs depuis history.history\n",
        "            self.loss_total.append(history.history[\"loss\"][0])  # Loss globale\n",
        "            self.policy_loss.append(\n",
        "                history.history[\"policy_loss\"][0]\n",
        "            )  # Policy loss\n",
        "            self.value_loss.append(\n",
        "                history.history[\"value_loss\"][0]\n",
        "            )  # Value loss\n",
        "            self.policy_acc.append(\n",
        "                history.history[\"policy_categorical_accuracy\"][0]\n",
        "            )  # Policy accuracy\n",
        "            self.value_mse.append(history.history[\"value_mse\"][0])  # Value MSE\n",
        "            if i % 5 == 0:\n",
        "                gc.collect()\n",
        "            if i % 20 == 0:\n",
        "                golois.getValidation(\n",
        "                    self.input_data, self.policy, self.value, self.end\n",
        "                )\n",
        "                val = self.model.evaluate(\n",
        "                    self.input_data,\n",
        "                    [self.policy, self.value],\n",
        "                    verbose=0,\n",
        "                    batch_size=batch,\n",
        "                )\n",
        "                print(f\"{val=}\")\n",
        "\n",
        "    def save_model(self, name):\n",
        "        \"\"\"\n",
        "        Sauvegarde le modèle et déclenche le téléchargement dans le fichier dédié.\n",
        "\n",
        "        Args:\n",
        "            name (str): Nom de fichier pour enregistrer le modèle (.h5, etc.)\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.model.save(name)\n",
        "        # A décommenter avec Google Colab\n",
        "        # files.download(name)\n",
        "\n",
        "    def plot_model(self):\n",
        "        plot_model(self.model, show_shapes=True, show_layer_names=True)\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"\n",
        "        Affiche les courbes d'apprentissage pour les pertes et métriques (par époque).\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affiche un graphique matplotlib.\n",
        "        \"\"\"\n",
        "        epochs = range(1, len(self.loss_total) + 1)  # Liste des époques\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Graphique des pertes\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.loss_total, label=\"Loss totale\", marker=\"o\")\n",
        "        plt.plot(epochs, self.policy_loss, label=\"Policy Loss\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_loss, label=\"Value Loss\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur de la perte\")\n",
        "        plt.title(\"Évolution des pertes\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Graphique des métriques\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.policy_acc, label=\"Policy Accuracy\", marker=\"o\")\n",
        "        plt.plot(epochs, self.value_mse, label=\"Value MSE\", marker=\"o\")\n",
        "        plt.xlabel(\"Époques\")\n",
        "        plt.ylabel(\"Valeur des métriques\")\n",
        "        plt.title(\"Évolution des métriques\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Affichage\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def log_accuracy(self, results_dict={}):\n",
        "        \"\"\"\n",
        "        Enregistre la dernière précision de la tête \"policy\" dans un dictionnaire.\n",
        "\n",
        "        Args:\n",
        "            results_dict (dict): Dictionnaire auquel ajouter les résultats.\n",
        "\n",
        "        Returns:\n",
        "            None: Met à jour results_dict avec l'accuracy du modèle.\n",
        "        \"\"\"\n",
        "        results_dict[self.__class__.__name__] = {\n",
        "            \"instance\": self,\n",
        "            \"accuracy\": self.policy_acc[-1],\n",
        "        }\n",
        "\n",
        "    def workflow(\n",
        "        self, epochs=20, batch=128, name=\"model.h5\", log_accuracy_dict={}\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Exécute le flux de travail complet : construction, entraînement et évaluation du modèle.\n",
        "\n",
        "        Args:\n",
        "            epochs (int): Nombre d'époques pour l'entraînement.\n",
        "            batch (int): Taille du batch pour l'entraînement.\n",
        "            name (str): Nom du fichier pour enregistrer le modèle.\n",
        "            log_accuracy_dict (dict): Dictionnaire pour enregistrer les résultats d'accuracy.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.set_backbone()\n",
        "        self.set_model()\n",
        "        self.train_model(epochs=epochs, batch=batch)\n",
        "        self.save_model(name=name)\n",
        "        self.plot_training_history()\n",
        "        self.log_accuracy(results_dict=log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXuo5huH7cIy"
      },
      "outputs": [],
      "source": [
        "def save_best_model(results_dict, model_name=\"test.h5\"):\n",
        "    \"\"\"\n",
        "    Sauvegarde le modèle ayant obtenu la meilleure précision (accuracy) à partir d'un dictionnaire de résultats.\n",
        "\n",
        "    Le dictionnaire 'results_dict' doit contenir, pour chaque clef (nom du modèle), une structure :\n",
        "        {\n",
        "            \"instance\": instance_du_modèle,\n",
        "            \"accuracy\": précision_obtenue (float)\n",
        "        }\n",
        "\n",
        "    La fonction identifie l'entrée avec la précision maximale, affiche un résumé,\n",
        "    et sauvegarde l'instance correspondante au format Keras (.h5) sous le nom spécifié.\n",
        "\n",
        "    Paramètres\n",
        "    ----------\n",
        "    results_dict : dict\n",
        "        Dictionnaire contenant les modèles et leurs précisions associées.\n",
        "\n",
        "    model_name : str\n",
        "        Nom du fichier dans lequel sauvegarder le meilleur modèle (format .h5).\n",
        "\n",
        "    Retourne\n",
        "    --------\n",
        "    None\n",
        "    \"\"\"\n",
        "    if not results_dict:\n",
        "        return None  # Handle empty dictionary case\n",
        "\n",
        "    # Recherche le modèle avec la meilleure précision\n",
        "    best_model_key = max(\n",
        "        results_dict, key=lambda k: results_dict[k][\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # garder en mémoire la meilleure précision\n",
        "    best_accuracy = results_dict[best_model_key][\"accuracy\"]\n",
        "\n",
        "    # et l'instance du modèle\n",
        "    best_instance = results_dict[best_model_key][\"instance\"]\n",
        "\n",
        "    print(\n",
        "        f\"Le réseau {best_model_key} est celui qui a enregistré la meilleur accuracy : {best_accuracy}\"\n",
        "    )\n",
        "\n",
        "    best_instance.save_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons définir un dictionnaire intitulé `log_accuracy_dict` qui contiendra les *accuracies* successives pour chaque réseau. Ce dernier constituera un historique des performances des réseaux entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z-uT2eey8Ph0"
      },
      "outputs": [],
      "source": [
        "log_accuracy_dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNWs9l8L0bWx"
      },
      "source": [
        "Création de la classe `GONetDemo`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JfuVC90KRFDQ"
      },
      "outputs": [],
      "source": [
        "class GONetDemo(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Définit l'architecture du tronc du réseau de neurones.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.x (sortie du tronc)\n",
        "        \"\"\"\n",
        "        filters = 32\n",
        "        x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(\n",
        "            self.input_layer\n",
        "        )\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CVZ_rb1QVelh",
        "outputId": "91a71821-394d-4f8d-93b5-be8deffe2578"
      },
      "outputs": [],
      "source": [
        "GONetDemo_instance = GONetDemo()\n",
        "GONetDemo_instance.workflow(\n",
        "    epochs=2,\n",
        "    batch=128,\n",
        "    name=\"gonetdemo.h5\",\n",
        "    log_accuracy_dict=log_accuracy_dict,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Première implémentation\n",
        "\n",
        "ATTENTION : Soit utiliser l'implémentation de Deep learning and the game of go soit utiliser du zero padding entre les couches de convolution.\n",
        "\n",
        "Sur la base de nos travaux de recherches bibliographiques, nous avons étudié deux implémentation différentes de réseaux de neurones pour jouer au jeu de Go. La première implémentation est inspirée du travail de [Silver et al. (2016)](https://www.nature.com/articles/nature16961) et utilise un réseau de neurones convolutionnel avec deux têtes : une pour la politique et une pour la valeur. La seconde implémentation est inspirée du travail de [Silver et al. (2017)](https://www.nature.com/articles/nature24270) et utilise un réseau de neurones profond avec plusieurs couches cachées.\n",
        "\n",
        "Dans un premier temps, nous allons réaliser deux implémentations de réseau de neurone de convolution présentés dans [Deep learning and the game of go, pp. 164-167](https://www.manning.com/books/deep-learning-and-the-game-of-go). La première structure (cf. https://github.com/ejhg/dlgo/blob/master/betago/networks/small.py) est plus simple et plus rapide à entraîner, tandis que la seconde est plus complexe et nécessite plus de temps d'entraînement (cf. https://github.com/ejhg/dlgo/blob/master/betago/networks/large.py). Commençons par la première implémentation.\n",
        "\n",
        "Dans le cadre de notre étude bibliographique certains auteurs ont fait état de l'utilité d'utiliser du zero padding entre les couches de convolution pour conserver les dimensions entre couche de convolution. L'usage du zero padding est une technique courante dans les réseaux de neurones convolutionnels, car elle permet de conserver la taille des cartes de caractéristiques (feature maps) après l'application de convolutions. Cela peut être particulièrement utile lorsque l'on souhaite maintenir la résolution spatiale des données d'entrée tout au long du réseau. En effet, le zero padding permet d'ajouter des zéros autour des bords de l'image d'entrée, ce qui évite la réduction de la taille des cartes de caractéristiques à chaque couche de convolution. Cela peut également aider à préserver les informations aux bords de l'image et à éviter la perte d'informations importantes lors du traitement des données.\n",
        "L'usagedu zero padding nécessite de supprimer la valeur `padding='same'` dans les couches de convolution. En effet, cette valeur permet de conserver la taille des cartes de caractéristiques après l'application de convolutions, ce qui n'est pas nécessaire si l'on utilise du zero padding. En revanche, il est important de s'assurer que les dimensions des cartes de caractéristiques sont compatibles entre les différentes couches du réseau. Si les dimensions ne correspondent pas, cela peut entraîner des erreurs lors de l'entraînement du modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetCNNZeroPadding(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Définit l'architecture du tronc du réseau de neurones.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.x (sortie du tronc)\n",
        "        \"\"\"\n",
        "        filters = 32\n",
        "        x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(\n",
        "            self.input_layer\n",
        "        )\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation=\"relu\")(x)\n",
        "            x = layers.ZeroPadding2D(padding=(1, 1))(x)\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetCNNZeroPadding_instance = GONetCNNZeroPadding()\n",
        "GONetCNNZeroPadding_instance.set_backbone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetCNNZeroPadding_instance.workflow(\n",
        "    epochs=10,\n",
        "    batch=128,\n",
        "    name=\"gonetzeropadding.h5\",\n",
        "    log_accuracy_dict=log_accuracy_dict,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mobile Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetCNNMobileNetwork(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "        filters=512,\n",
        "        trunk=32,\n",
        "        blocks=5,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "        self.filters = filters\n",
        "        self.trunk = trunk\n",
        "        self.blocks = blocks\n",
        "\n",
        "    @staticmethod\n",
        "    def bottleneck_block(x, expand=512, squeeze=128):\n",
        "        m = layers.Conv2D(\n",
        "            expand,\n",
        "            (1, 1),\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "            use_bias=False,\n",
        "        )(x)\n",
        "        m = layers.BatchNormalization()(m)\n",
        "        m = layers.Activation(\"relu\")(m)\n",
        "        m = layers.DepthwiseConv2D(\n",
        "            (3, 3),\n",
        "            padding=\"same\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "            use_bias=False,\n",
        "        )(m)\n",
        "        m = layers.BatchNormalization()(m)\n",
        "        m = layers.Activation(\"relu\")(m)\n",
        "        m = layers.Conv2D(\n",
        "            squeeze,\n",
        "            (1, 1),\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "            use_bias=False,\n",
        "        )(m)\n",
        "        m = layers.BatchNormalization()(m)\n",
        "        return layers.Add()([m, x])\n",
        "\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Définit l'architecture du tronc du réseau de neurones.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.x (sortie du tronc)\n",
        "        \"\"\"\n",
        "        x = layers.Conv2D(\n",
        "            self.trunk,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(self.input_layer)\n",
        "        print(f\"{x.shape=}\")\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        print(f\"{x.shape=}\")\n",
        "        x = layers.ReLU()(x)\n",
        "        print(f\"{x.shape=}\")\n",
        "        for i in range(self.blocks):\n",
        "            x = self.bottleneck_block(\n",
        "                x, expand=self.filters, squeeze=self.trunk\n",
        "            )\n",
        "            print(f\"{x.shape=}\")\n",
        "        print(f\"{x.shape=}\")\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n"
          ]
        }
      ],
      "source": [
        "GONetCNNMobileNetwork_instance = GONetCNNMobileNetwork()\n",
        "GONetCNNMobileNetwork_instance.set_backbone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " board (InputLayer)          [(None, 19, 19, 31)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 19, 19, 32)           1024      ['board[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 19, 19, 32)           128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 19, 19, 32)           0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 19, 19, 512)          16384     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 19, 19, 512)          2048      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (Depthw  (None, 19, 19, 512)          4608      ['activation_10[0][0]']       \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_5[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 19, 19, 32)           128       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_19[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 19, 19, 512)          16384     ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 19, 19, 512)          2048      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (Depthw  (None, 19, 19, 512)          4608      ['activation_12[0][0]']       \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_6[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 19, 19, 32)           128       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 19, 19, 512)          16384     ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 19, 19, 512)          2048      ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (Depthw  (None, 19, 19, 512)          4608      ['activation_14[0][0]']       \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_7[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 19, 19, 32)           128       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 19, 19, 512)          16384     ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 19, 19, 512)          2048      ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (Depthw  (None, 19, 19, 512)          4608      ['activation_16[0][0]']       \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_8[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 19, 19, 32)           128       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 19, 19, 512)          16384     ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 19, 19, 512)          2048      ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (Depthw  (None, 19, 19, 512)          4608      ['activation_18[0][0]']       \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_9[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 19, 19, 32)           128       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 19, 19, 32)           0         ['batch_normalization_31[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 19, 19, 1)            32        ['add_9[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 19, 19, 1)            32        ['add_9[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 361)                  0         ['conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 361)                  0         ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 50)                   18100     ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " policy (Activation)         (None, 361)                  0         ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " value (Dense)               (None, 1)                    51        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 227367 (888.15 KB)\n",
            "Trainable params: 216743 (846.65 KB)\n",
            "Non-trainable params: 10624 (41.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "GONetCNNMobileNetwork_instance.set_model()\n",
        "# GONetCNNMobileNetwork_instance.save_model(\n",
        "#     name=\"gonetcnnmobilenetwork.h5\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "x.shape=TensorShape([None, 19, 19, 32])\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " board (InputLayer)          [(None, 19, 19, 31)]         0         []                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 19, 19, 32)           1024      ['board[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 19, 19, 32)           128       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 19, 19, 32)           0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 19, 19, 512)          16384     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 19, 19, 512)          2048      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depth  (None, 19, 19, 512)          4608      ['activation_20[0][0]']       \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_10[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 19, 19, 32)           128       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 19, 19, 32)           0         ['batch_normalization_35[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 19, 19, 512)          16384     ['add_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 19, 19, 512)          2048      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depth  (None, 19, 19, 512)          4608      ['activation_22[0][0]']       \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_11[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 19, 19, 32)           128       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 19, 19, 32)           0         ['batch_normalization_38[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 19, 19, 512)          16384     ['add_11[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 19, 19, 512)          2048      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depth  (None, 19, 19, 512)          4608      ['activation_24[0][0]']       \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_12[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 19, 19, 32)           128       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 19, 19, 32)           0         ['batch_normalization_41[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 19, 19, 512)          16384     ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 19, 19, 512)          2048      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depth  (None, 19, 19, 512)          4608      ['activation_26[0][0]']       \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_13[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 19, 19, 32)           128       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 19, 19, 32)           0         ['batch_normalization_44[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 19, 19, 512)          16384     ['add_13[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 19, 19, 512)          2048      ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depth  (None, 19, 19, 512)          4608      ['activation_28[0][0]']       \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 19, 19, 512)          2048      ['depthwise_conv2d_14[0][0]'] \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 19, 19, 512)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 19, 19, 32)           16384     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 19, 19, 32)           128       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 19, 19, 32)           0         ['batch_normalization_47[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 19, 19, 1)            32        ['add_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 19, 19, 1)            32        ['add_14[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 361)                  0         ['conv2d_36[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 361)                  0         ['conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 50)                   18100     ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            " policy (Activation)         (None, 361)                  0         ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " value (Dense)               (None, 1)                    51        ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 227367 (888.15 KB)\n",
            "Trainable params: 216743 (846.65 KB)\n",
            "Non-trainable params: 10624 (41.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2025-04-12 15:20:17.620830: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "2025-04-12 15:20:18.126428: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14440000 exceeds 10% of free system memory.\n",
            "2025-04-12 15:20:18.225182: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "2025-04-12 15:20:18.380791: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14440000 exceeds 10% of free system memory.\n",
            "2025-04-12 15:20:22.871381: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2025-04-12 15:20:34.661112: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 90.25MiB (rounded to 94633984)requested by op model_1/batch_normalization_46/FusedBatchNormV3\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2025-04-12 15:20:34.661216: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
            "2025-04-12 15:20:34.661235: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 144, Chunks in use: 144. 36.0KiB allocated for chunks. 36.0KiB in use in bin. 11.7KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661265: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 2, Chunks in use: 1. 1.0KiB allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661270: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661277: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 118, Chunks in use: 118. 246.8KiB allocated for chunks. 246.8KiB in use in bin. 236.0KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661283: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 5, Chunks in use: 4. 20.0KiB allocated for chunks. 16.0KiB in use in bin. 15.5KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661288: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 16, Chunks in use: 15. 338.8KiB allocated for chunks. 310.0KiB in use in bin. 270.0KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661298: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661303: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 45, Chunks in use: 45. 2.89MiB allocated for chunks. 2.89MiB in use in bin. 2.81MiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661333: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661339: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 256.0KiB allocated for chunks. 256.0KiB in use in bin. 180.5KiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661344: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661349: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661353: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661360: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 12, Chunks in use: 11. 67.08MiB allocated for chunks. 61.87MiB in use in bin. 61.87MiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661366: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 13.77MiB allocated for chunks. 13.77MiB in use in bin. 13.77MiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661370: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661375: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661381: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 19, Chunks in use: 19. 1.69GiB allocated for chunks. 1.69GiB in use in bin. 1.67GiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661387: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661394: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 426.90MiB allocated for chunks. 426.90MiB in use in bin. 426.90MiB client-requested in use in bin.\n",
            "2025-04-12 15:20:34.661400: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 90.25MiB was 64.00MiB, Chunk State: \n",
            "2025-04-12 15:20:34.661404: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 2351693824\n",
            "2025-04-12 15:20:34.661410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000000 of size 1280 next 1\n",
            "2025-04-12 15:20:34.661414: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000500 of size 256 next 2\n",
            "2025-04-12 15:20:34.661417: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000600 of size 256 next 3\n",
            "2025-04-12 15:20:34.661421: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000700 of size 256 next 5\n",
            "2025-04-12 15:20:34.661424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000800 of size 256 next 6\n",
            "2025-04-12 15:20:34.661428: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000900 of size 256 next 4\n",
            "2025-04-12 15:20:34.661431: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000a00 of size 256 next 86\n",
            "2025-04-12 15:20:34.661435: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000b00 of size 256 next 89\n",
            "2025-04-12 15:20:34.661439: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000c00 of size 512 next 12\n",
            "2025-04-12 15:20:34.661442: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000e00 of size 256 next 13\n",
            "2025-04-12 15:20:34.661446: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503000f00 of size 256 next 14\n",
            "2025-04-12 15:20:34.661449: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001000 of size 256 next 53\n",
            "2025-04-12 15:20:34.661453: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001100 of size 256 next 84\n",
            "2025-04-12 15:20:34.661457: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001200 of size 1024 next 83\n",
            "2025-04-12 15:20:34.661460: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001600 of size 256 next 81\n",
            "2025-04-12 15:20:34.661464: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001700 of size 256 next 80\n",
            "2025-04-12 15:20:34.661467: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503001800 of size 2048 next 67\n",
            "2025-04-12 15:20:34.661471: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002000 of size 2048 next 94\n",
            "2025-04-12 15:20:34.661475: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002800 of size 256 next 91\n",
            "2025-04-12 15:20:34.661478: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002900 of size 256 next 90\n",
            "2025-04-12 15:20:34.661482: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002a00 of size 256 next 77\n",
            "2025-04-12 15:20:34.661485: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002b00 of size 256 next 78\n",
            "2025-04-12 15:20:34.661489: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002c00 of size 256 next 76\n",
            "2025-04-12 15:20:34.661492: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002d00 of size 256 next 73\n",
            "2025-04-12 15:20:34.661516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002e00 of size 256 next 59\n",
            "2025-04-12 15:20:34.661519: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503002f00 of size 256 next 56\n",
            "2025-04-12 15:20:34.661523: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003000 of size 256 next 41\n",
            "2025-04-12 15:20:34.661526: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003100 of size 256 next 44\n",
            "2025-04-12 15:20:34.661556: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003200 of size 256 next 39\n",
            "2025-04-12 15:20:34.661559: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003300 of size 256 next 40\n",
            "2025-04-12 15:20:34.661563: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003400 of size 256 next 18\n",
            "2025-04-12 15:20:34.661566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003500 of size 256 next 25\n",
            "2025-04-12 15:20:34.661570: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003600 of size 256 next 23\n",
            "2025-04-12 15:20:34.661574: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003700 of size 256 next 36\n",
            "2025-04-12 15:20:34.661577: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003800 of size 256 next 42\n",
            "2025-04-12 15:20:34.661581: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003900 of size 256 next 48\n",
            "2025-04-12 15:20:34.661584: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003a00 of size 256 next 70\n",
            "2025-04-12 15:20:34.661588: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003b00 of size 256 next 62\n",
            "2025-04-12 15:20:34.661591: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003c00 of size 256 next 47\n",
            "2025-04-12 15:20:34.661595: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003d00 of size 256 next 30\n",
            "2025-04-12 15:20:34.661598: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003e00 of size 256 next 34\n",
            "2025-04-12 15:20:34.661602: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503003f00 of size 256 next 33\n",
            "2025-04-12 15:20:34.661605: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004000 of size 256 next 46\n",
            "2025-04-12 15:20:34.661609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004100 of size 256 next 16\n",
            "2025-04-12 15:20:34.661612: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004200 of size 256 next 20\n",
            "2025-04-12 15:20:34.661616: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004300 of size 256 next 21\n",
            "2025-04-12 15:20:34.661640: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004400 of size 2048 next 60\n",
            "2025-04-12 15:20:34.661644: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503004c00 of size 2048 next 28\n",
            "2025-04-12 15:20:34.661647: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503005400 of size 2048 next 68\n",
            "2025-04-12 15:20:34.661651: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503005c00 of size 2048 next 7\n",
            "2025-04-12 15:20:34.661655: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503006400 of size 2048 next 346\n",
            "2025-04-12 15:20:34.661660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503006c00 of size 2048 next 352\n",
            "2025-04-12 15:20:34.661664: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503007400 of size 2048 next 353\n",
            "2025-04-12 15:20:34.661667: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503007c00 of size 2048 next 354\n",
            "2025-04-12 15:20:34.661671: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503008400 of size 2048 next 357\n",
            "2025-04-12 15:20:34.661674: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503008c00 of size 2048 next 358\n",
            "2025-04-12 15:20:34.661677: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503009400 of size 2048 next 364\n",
            "2025-04-12 15:20:34.661681: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503009c00 of size 2048 next 365\n",
            "2025-04-12 15:20:34.661712: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50300a400 of size 2048 next 366\n",
            "2025-04-12 15:20:34.661716: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 50300ac00 of size 29440 next 27\n",
            "2025-04-12 15:20:34.661719: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503011f00 of size 72448 next 19\n",
            "2025-04-12 15:20:34.661723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503023a00 of size 102656 next 43\n",
            "2025-04-12 15:20:34.661727: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303cb00 of size 4096 next 100\n",
            "2025-04-12 15:20:34.661731: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303db00 of size 2048 next 107\n",
            "2025-04-12 15:20:34.661735: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303e300 of size 2048 next 106\n",
            "2025-04-12 15:20:34.661738: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303eb00 of size 2048 next 108\n",
            "2025-04-12 15:20:34.661742: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303f300 of size 2048 next 110\n",
            "2025-04-12 15:20:34.661745: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303fb00 of size 256 next 111\n",
            "2025-04-12 15:20:34.661749: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303fc00 of size 256 next 112\n",
            "2025-04-12 15:20:34.661752: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303fd00 of size 256 next 115\n",
            "2025-04-12 15:20:34.661756: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303fe00 of size 256 next 116\n",
            "2025-04-12 15:20:34.661759: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50303ff00 of size 2048 next 117\n",
            "2025-04-12 15:20:34.661763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503040700 of size 2048 next 118\n",
            "2025-04-12 15:20:34.661788: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503040f00 of size 2048 next 120\n",
            "2025-04-12 15:20:34.661791: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503041700 of size 2048 next 121\n",
            "2025-04-12 15:20:34.661821: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503041f00 of size 2048 next 122\n",
            "2025-04-12 15:20:34.661824: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503042700 of size 2048 next 123\n",
            "2025-04-12 15:20:34.661828: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503042f00 of size 2816 next 31\n",
            "2025-04-12 15:20:34.661832: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503043a00 of size 65536 next 75\n",
            "2025-04-12 15:20:34.661836: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503053a00 of size 72448 next 57\n",
            "2025-04-12 15:20:34.661839: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503065500 of size 65536 next 55\n",
            "2025-04-12 15:20:34.661843: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503075500 of size 65536 next 38\n",
            "2025-04-12 15:20:34.661847: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503085500 of size 65792 next 95\n",
            "2025-04-12 15:20:34.661850: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095600 of size 256 next 97\n",
            "2025-04-12 15:20:34.661854: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095700 of size 256 next 98\n",
            "2025-04-12 15:20:34.661858: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095800 of size 256 next 96\n",
            "2025-04-12 15:20:34.661862: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095900 of size 256 next 99\n",
            "2025-04-12 15:20:34.661865: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095a00 of size 256 next 101\n",
            "2025-04-12 15:20:34.661869: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503095b00 of size 2048 next 102\n",
            "2025-04-12 15:20:34.661872: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503096300 of size 2048 next 103\n",
            "2025-04-12 15:20:34.661876: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503096b00 of size 2048 next 105\n",
            "2025-04-12 15:20:34.661880: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503097300 of size 3840 next 88\n",
            "2025-04-12 15:20:34.661884: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503098200 of size 4096 next 22\n",
            "2025-04-12 15:20:34.661887: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503099200 of size 2048 next 66\n",
            "2025-04-12 15:20:34.661891: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503099a00 of size 2048 next 65\n",
            "2025-04-12 15:20:34.661894: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309a200 of size 2048 next 51\n",
            "2025-04-12 15:20:34.661898: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309aa00 of size 2048 next 50\n",
            "2025-04-12 15:20:34.661901: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309b200 of size 2048 next 8\n",
            "2025-04-12 15:20:34.661926: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309ba00 of size 2048 next 17\n",
            "2025-04-12 15:20:34.661929: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309c200 of size 2048 next 87\n",
            "2025-04-12 15:20:34.661933: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309ca00 of size 2048 next 155\n",
            "2025-04-12 15:20:34.661937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309d200 of size 256 next 156\n",
            "2025-04-12 15:20:34.661940: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309d300 of size 256 next 157\n",
            "2025-04-12 15:20:34.661943: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309d400 of size 256 next 160\n",
            "2025-04-12 15:20:34.661947: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309d500 of size 256 next 161\n",
            "2025-04-12 15:20:34.661950: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309d600 of size 2048 next 162\n",
            "2025-04-12 15:20:34.661980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309de00 of size 2048 next 163\n",
            "2025-04-12 15:20:34.661983: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309e600 of size 2048 next 165\n",
            "2025-04-12 15:20:34.662007: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309ee00 of size 2048 next 166\n",
            "2025-04-12 15:20:34.662010: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309f600 of size 2048 next 167\n",
            "2025-04-12 15:20:34.662013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50309fe00 of size 2048 next 168\n",
            "2025-04-12 15:20:34.662044: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a0600 of size 2048 next 169\n",
            "2025-04-12 15:20:34.662047: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a0e00 of size 2048 next 171\n",
            "2025-04-12 15:20:34.662051: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1600 of size 256 next 172\n",
            "2025-04-12 15:20:34.662054: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1700 of size 256 next 173\n",
            "2025-04-12 15:20:34.662058: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1800 of size 256 next 175\n",
            "2025-04-12 15:20:34.662061: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1900 of size 256 next 176\n",
            "2025-04-12 15:20:34.662065: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1a00 of size 256 next 177\n",
            "2025-04-12 15:20:34.662089: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1b00 of size 256 next 178\n",
            "2025-04-12 15:20:34.662093: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1c00 of size 256 next 179\n",
            "2025-04-12 15:20:34.662096: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1d00 of size 256 next 180\n",
            "2025-04-12 15:20:34.662099: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1e00 of size 256 next 181\n",
            "2025-04-12 15:20:34.662103: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a1f00 of size 256 next 182\n",
            "2025-04-12 15:20:34.662106: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2000 of size 256 next 183\n",
            "2025-04-12 15:20:34.662110: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2100 of size 256 next 184\n",
            "2025-04-12 15:20:34.662113: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2200 of size 256 next 187\n",
            "2025-04-12 15:20:34.662116: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2300 of size 256 next 189\n",
            "2025-04-12 15:20:34.662139: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2400 of size 256 next 188\n",
            "2025-04-12 15:20:34.662142: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2500 of size 256 next 190\n",
            "2025-04-12 15:20:34.662170: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2600 of size 256 next 191\n",
            "2025-04-12 15:20:34.662174: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2700 of size 256 next 192\n",
            "2025-04-12 15:20:34.662177: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2800 of size 256 next 193\n",
            "2025-04-12 15:20:34.662180: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2900 of size 256 next 194\n",
            "2025-04-12 15:20:34.662184: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2a00 of size 256 next 197\n",
            "2025-04-12 15:20:34.662187: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2b00 of size 256 next 195\n",
            "2025-04-12 15:20:34.662190: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2c00 of size 256 next 196\n",
            "2025-04-12 15:20:34.662194: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2d00 of size 256 next 35\n",
            "2025-04-12 15:20:34.662197: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2e00 of size 256 next 201\n",
            "2025-04-12 15:20:34.662200: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a2f00 of size 2816 next 63\n",
            "2025-04-12 15:20:34.662204: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030a3a00 of size 262144 next 82\n",
            "2025-04-12 15:20:34.662208: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e3a00 of size 18432 next 109\n",
            "2025-04-12 15:20:34.662231: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8200 of size 2048 next 124\n",
            "2025-04-12 15:20:34.662234: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8a00 of size 256 next 126\n",
            "2025-04-12 15:20:34.662237: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8b00 of size 256 next 127\n",
            "2025-04-12 15:20:34.662268: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8c00 of size 256 next 129\n",
            "2025-04-12 15:20:34.662272: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8d00 of size 256 next 130\n",
            "2025-04-12 15:20:34.662295: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e8e00 of size 2048 next 131\n",
            "2025-04-12 15:20:34.662299: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e9600 of size 2048 next 132\n",
            "2025-04-12 15:20:34.662302: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030e9e00 of size 2048 next 134\n",
            "2025-04-12 15:20:34.662305: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030ea600 of size 2048 next 135\n",
            "2025-04-12 15:20:34.662309: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030eae00 of size 2048 next 136\n",
            "2025-04-12 15:20:34.662312: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030eb600 of size 2048 next 137\n",
            "2025-04-12 15:20:34.662316: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030ebe00 of size 3072 next 125\n",
            "2025-04-12 15:20:34.662320: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030eca00 of size 28672 next 93\n",
            "2025-04-12 15:20:34.662324: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5030f3a00 of size 65536 next 92\n",
            "2025-04-12 15:20:34.662328: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503103a00 of size 65536 next 104\n",
            "2025-04-12 15:20:34.662332: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503113a00 of size 2048 next 140\n",
            "2025-04-12 15:20:34.662335: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114200 of size 256 next 141\n",
            "2025-04-12 15:20:34.662339: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114300 of size 256 next 142\n",
            "2025-04-12 15:20:34.662343: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114400 of size 256 next 145\n",
            "2025-04-12 15:20:34.662346: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114500 of size 256 next 146\n",
            "2025-04-12 15:20:34.662349: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114600 of size 2048 next 147\n",
            "2025-04-12 15:20:34.662353: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503114e00 of size 2048 next 148\n",
            "2025-04-12 15:20:34.662356: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503115600 of size 2048 next 150\n",
            "2025-04-12 15:20:34.662359: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503115e00 of size 2048 next 151\n",
            "2025-04-12 15:20:34.662363: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503116600 of size 2048 next 152\n",
            "2025-04-12 15:20:34.662393: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503116e00 of size 2048 next 153\n",
            "2025-04-12 15:20:34.662396: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503117600 of size 3072 next 139\n",
            "2025-04-12 15:20:34.662400: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503118200 of size 18432 next 138\n",
            "2025-04-12 15:20:34.662403: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311ca00 of size 256 next 224\n",
            "2025-04-12 15:20:34.662407: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311cb00 of size 256 next 225\n",
            "2025-04-12 15:20:34.662410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311cc00 of size 256 next 348\n",
            "2025-04-12 15:20:34.662414: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311cd00 of size 256 next 229\n",
            "2025-04-12 15:20:34.662418: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311ce00 of size 2048 next 230\n",
            "2025-04-12 15:20:34.662421: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311d600 of size 2048 next 231\n",
            "2025-04-12 15:20:34.662425: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311de00 of size 2048 next 10\n",
            "2025-04-12 15:20:34.662428: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311e600 of size 2048 next 234\n",
            "2025-04-12 15:20:34.662432: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311ee00 of size 2048 next 236\n",
            "2025-04-12 15:20:34.662435: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311f600 of size 2048 next 235\n",
            "2025-04-12 15:20:34.662439: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311fe00 of size 256 next 349\n",
            "2025-04-12 15:20:34.662463: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50311ff00 of size 256 next 350\n",
            "2025-04-12 15:20:34.662467: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503120000 of size 3584 next 239\n",
            "2025-04-12 15:20:34.662470: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503120e00 of size 256 next 240\n",
            "2025-04-12 15:20:34.662474: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503120f00 of size 256 next 241\n",
            "2025-04-12 15:20:34.662477: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503121000 of size 256 next 360\n",
            "2025-04-12 15:20:34.662481: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503121100 of size 256 next 244\n",
            "2025-04-12 15:20:34.662484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503121200 of size 2048 next 245\n",
            "2025-04-12 15:20:34.662488: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503121a00 of size 2048 next 246\n",
            "2025-04-12 15:20:34.662518: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503122200 of size 2048 next 356\n",
            "2025-04-12 15:20:34.662521: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503122a00 of size 2048 next 249\n",
            "2025-04-12 15:20:34.662525: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503123200 of size 2048 next 114\n",
            "2025-04-12 15:20:34.662529: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503123a00 of size 65536 next 113\n",
            "2025-04-12 15:20:34.662532: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503133a00 of size 65536 next 119\n",
            "2025-04-12 15:20:34.662536: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503143a00 of size 65536 next 128\n",
            "2025-04-12 15:20:34.662540: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503153a00 of size 65536 next 133\n",
            "2025-04-12 15:20:34.662543: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503163a00 of size 18432 next 154\n",
            "2025-04-12 15:20:34.662547: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503168200 of size 2048 next 204\n",
            "2025-04-12 15:20:34.662551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503168a00 of size 2048 next 205\n",
            "2025-04-12 15:20:34.662575: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503169200 of size 2048 next 15\n",
            "2025-04-12 15:20:34.662578: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503169a00 of size 2048 next 199\n",
            "2025-04-12 15:20:34.662609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50316a200 of size 4096 next 198\n",
            "2025-04-12 15:20:34.662613: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50316b200 of size 2048 next 202\n",
            "2025-04-12 15:20:34.662616: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50316ba00 of size 2048 next 52\n",
            "2025-04-12 15:20:34.662642: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50316c200 of size 2048 next 170\n",
            "2025-04-12 15:20:34.662645: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50316ca00 of size 28672 next 144\n",
            "2025-04-12 15:20:34.662649: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503173a00 of size 65536 next 143\n",
            "2025-04-12 15:20:34.662653: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503183a00 of size 65536 next 149\n",
            "2025-04-12 15:20:34.662656: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503193a00 of size 256 next 209\n",
            "2025-04-12 15:20:34.662660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503193b00 of size 256 next 210\n",
            "2025-04-12 15:20:34.662663: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503193c00 of size 256 next 45\n",
            "2025-04-12 15:20:34.662667: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503193d00 of size 256 next 214\n",
            "2025-04-12 15:20:34.662670: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503193e00 of size 2048 next 215\n",
            "2025-04-12 15:20:34.662673: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503194600 of size 2048 next 216\n",
            "2025-04-12 15:20:34.662677: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503194e00 of size 2048 next 61\n",
            "2025-04-12 15:20:34.662680: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503195600 of size 2048 next 219\n",
            "2025-04-12 15:20:34.662684: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503195e00 of size 2048 next 220\n",
            "2025-04-12 15:20:34.662687: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503196600 of size 2048 next 221\n",
            "2025-04-12 15:20:34.662691: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503196e00 of size 2048 next 29\n",
            "2025-04-12 15:20:34.662694: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503197600 of size 3072 next 207\n",
            "2025-04-12 15:20:34.662698: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503198200 of size 18432 next 206\n",
            "2025-04-12 15:20:34.662701: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319ca00 of size 2048 next 250\n",
            "2025-04-12 15:20:34.662705: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319d200 of size 256 next 361\n",
            "2025-04-12 15:20:34.662734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319d300 of size 256 next 362\n",
            "2025-04-12 15:20:34.662738: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319d400 of size 3584 next 253\n",
            "2025-04-12 15:20:34.662742: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319e200 of size 256 next 254\n",
            "2025-04-12 15:20:34.662746: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319e300 of size 256 next 255\n",
            "2025-04-12 15:20:34.662749: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 50319e400 of size 512 next 259\n",
            "2025-04-12 15:20:34.662752: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319e600 of size 2048 next 260\n",
            "2025-04-12 15:20:34.662756: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50319ee00 of size 2048 next 261\n",
            "2025-04-12 15:20:34.662760: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 50319f600 of size 4096 next 264\n",
            "2025-04-12 15:20:34.662763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a0600 of size 2048 next 265\n",
            "2025-04-12 15:20:34.662767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a0e00 of size 2048 next 266\n",
            "2025-04-12 15:20:34.662771: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a1600 of size 2048 next 267\n",
            "2025-04-12 15:20:34.662774: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a1e00 of size 2048 next 269\n",
            "2025-04-12 15:20:34.662778: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2600 of size 256 next 270\n",
            "2025-04-12 15:20:34.662782: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2700 of size 256 next 271\n",
            "2025-04-12 15:20:34.662785: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2800 of size 256 next 273\n",
            "2025-04-12 15:20:34.662809: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2900 of size 256 next 274\n",
            "2025-04-12 15:20:34.662813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2a00 of size 256 next 275\n",
            "2025-04-12 15:20:34.662816: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2b00 of size 256 next 276\n",
            "2025-04-12 15:20:34.662819: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2c00 of size 256 next 277\n",
            "2025-04-12 15:20:34.662823: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2d00 of size 256 next 278\n",
            "2025-04-12 15:20:34.662826: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2e00 of size 256 next 279\n",
            "2025-04-12 15:20:34.662856: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a2f00 of size 256 next 282\n",
            "2025-04-12 15:20:34.662859: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3000 of size 256 next 283\n",
            "2025-04-12 15:20:34.662863: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3100 of size 256 next 286\n",
            "2025-04-12 15:20:34.662867: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3200 of size 256 next 287\n",
            "2025-04-12 15:20:34.662870: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3300 of size 256 next 288\n",
            "2025-04-12 15:20:34.662874: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3400 of size 256 next 289\n",
            "2025-04-12 15:20:34.662877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3500 of size 256 next 290\n",
            "2025-04-12 15:20:34.662881: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3600 of size 256 next 291\n",
            "2025-04-12 15:20:34.662884: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3700 of size 256 next 293\n",
            "2025-04-12 15:20:34.662888: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3800 of size 256 next 294\n",
            "2025-04-12 15:20:34.662913: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3900 of size 256 next 159\n",
            "2025-04-12 15:20:34.662917: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031a3a00 of size 65536 next 158\n",
            "2025-04-12 15:20:34.662946: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031b3a00 of size 65536 next 164\n",
            "2025-04-12 15:20:34.662950: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031c3a00 of size 65536 next 174\n",
            "2025-04-12 15:20:34.662954: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031d3a00 of size 72448 next 186\n",
            "2025-04-12 15:20:34.662957: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031e5500 of size 72448 next 185\n",
            "2025-04-12 15:20:34.662961: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031f7000 of size 18432 next 222\n",
            "2025-04-12 15:20:34.662986: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5031fb800 of size 18432 next 238\n",
            "2025-04-12 15:20:34.662989: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503200000 of size 28672 next 212\n",
            "2025-04-12 15:20:34.662993: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503207000 of size 65536 next 211\n",
            "2025-04-12 15:20:34.662996: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503217000 of size 65536 next 217\n",
            "2025-04-12 15:20:34.663000: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503227000 of size 18432 next 252\n",
            "2025-04-12 15:20:34.663003: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322b800 of size 4096 next 292\n",
            "2025-04-12 15:20:34.663006: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322c800 of size 2048 next 295\n",
            "2025-04-12 15:20:34.663010: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322d000 of size 2048 next 296\n",
            "2025-04-12 15:20:34.663013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322d800 of size 2048 next 297\n",
            "2025-04-12 15:20:34.663017: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322e000 of size 2048 next 298\n",
            "2025-04-12 15:20:34.663020: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322e800 of size 256 next 299\n",
            "2025-04-12 15:20:34.663023: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322e900 of size 256 next 300\n",
            "2025-04-12 15:20:34.663027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322ea00 of size 2048 next 302\n",
            "2025-04-12 15:20:34.663030: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50322f200 of size 3584 next 268\n",
            "2025-04-12 15:20:34.663034: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503230000 of size 28672 next 227\n",
            "2025-04-12 15:20:34.663037: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503237000 of size 65536 next 226\n",
            "2025-04-12 15:20:34.663041: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503247000 of size 65536 next 232\n",
            "2025-04-12 15:20:34.663044: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503257000 of size 65536 next 242\n",
            "2025-04-12 15:20:34.663047: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503267000 of size 65536 next 247\n",
            "2025-04-12 15:20:34.663051: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503277000 of size 65536 next 257\n",
            "2025-04-12 15:20:34.663079: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503287000 of size 65536 next 256\n",
            "2025-04-12 15:20:34.663083: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503297000 of size 65536 next 262\n",
            "2025-04-12 15:20:34.663086: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5032a7000 of size 65536 next 272\n",
            "2025-04-12 15:20:34.663090: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5032b7000 of size 72448 next 280\n",
            "2025-04-12 15:20:34.663094: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5032c8b00 of size 72448 next 281\n",
            "2025-04-12 15:20:34.663098: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5032da600 of size 447640064 next 284\n",
            "2025-04-12 15:20:34.663102: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ddc1800 of size 14440192 next 285\n",
            "2025-04-12 15:20:34.663106: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51eb86f00 of size 65536 next 301\n",
            "2025-04-12 15:20:34.663110: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51eb96f00 of size 18432 next 303\n",
            "2025-04-12 15:20:34.663113: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51eb9b700 of size 2048 next 304\n",
            "2025-04-12 15:20:34.663117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51eb9bf00 of size 2048 next 305\n",
            "2025-04-12 15:20:34.663120: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51eb9c700 of size 65536 next 306\n",
            "2025-04-12 15:20:34.663124: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebac700 of size 256 next 307\n",
            "2025-04-12 15:20:34.663127: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebac800 of size 256 next 308\n",
            "2025-04-12 15:20:34.663131: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebac900 of size 65536 next 309\n",
            "2025-04-12 15:20:34.663156: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebbc900 of size 2048 next 310\n",
            "2025-04-12 15:20:34.663159: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebbd100 of size 2048 next 311\n",
            "2025-04-12 15:20:34.663163: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebbd900 of size 18432 next 312\n",
            "2025-04-12 15:20:34.663166: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebc2100 of size 2048 next 313\n",
            "2025-04-12 15:20:34.663169: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebc2900 of size 2048 next 314\n",
            "2025-04-12 15:20:34.663173: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebc3100 of size 65536 next 315\n",
            "2025-04-12 15:20:34.663177: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebd3100 of size 256 next 316\n",
            "2025-04-12 15:20:34.663207: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebd3200 of size 256 next 317\n",
            "2025-04-12 15:20:34.663210: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebd3300 of size 65536 next 318\n",
            "2025-04-12 15:20:34.663214: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe3300 of size 2048 next 319\n",
            "2025-04-12 15:20:34.663218: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe3b00 of size 2048 next 320\n",
            "2025-04-12 15:20:34.663222: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe4300 of size 18432 next 321\n",
            "2025-04-12 15:20:34.663225: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe8b00 of size 2048 next 322\n",
            "2025-04-12 15:20:34.663229: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe9300 of size 2048 next 323\n",
            "2025-04-12 15:20:34.663232: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebe9b00 of size 65536 next 324\n",
            "2025-04-12 15:20:34.663236: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebf9b00 of size 256 next 325\n",
            "2025-04-12 15:20:34.663259: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebf9c00 of size 256 next 326\n",
            "2025-04-12 15:20:34.663263: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ebf9d00 of size 65536 next 327\n",
            "2025-04-12 15:20:34.663266: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec09d00 of size 2048 next 328\n",
            "2025-04-12 15:20:34.663297: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec0a500 of size 2048 next 329\n",
            "2025-04-12 15:20:34.663300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec0ad00 of size 18432 next 330\n",
            "2025-04-12 15:20:34.663304: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec0f500 of size 2048 next 331\n",
            "2025-04-12 15:20:34.663307: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec0fd00 of size 2048 next 332\n",
            "2025-04-12 15:20:34.663311: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec10500 of size 65536 next 333\n",
            "2025-04-12 15:20:34.663336: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec20500 of size 256 next 334\n",
            "2025-04-12 15:20:34.663340: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec20600 of size 256 next 335\n",
            "2025-04-12 15:20:34.663343: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec20700 of size 256 next 336\n",
            "2025-04-12 15:20:34.663347: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec20800 of size 256 next 337\n",
            "2025-04-12 15:20:34.663350: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec20900 of size 72448 next 338\n",
            "2025-04-12 15:20:34.663354: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32400 of size 256 next 339\n",
            "2025-04-12 15:20:34.663357: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32500 of size 256 next 340\n",
            "2025-04-12 15:20:34.663361: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32600 of size 256 next 341\n",
            "2025-04-12 15:20:34.663364: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32700 of size 256 next 342\n",
            "2025-04-12 15:20:34.663367: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32800 of size 256 next 343\n",
            "2025-04-12 15:20:34.663371: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32900 of size 256 next 344\n",
            "2025-04-12 15:20:34.663374: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32a00 of size 256 next 345\n",
            "2025-04-12 15:20:34.663378: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec32b00 of size 65536 next 24\n",
            "2025-04-12 15:20:34.663381: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec42b00 of size 65536 next 58\n",
            "2025-04-12 15:20:34.663385: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec52b00 of size 65536 next 26\n",
            "2025-04-12 15:20:34.663388: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51ec62b00 of size 65536 next 72\n",
            "2025-04-12 15:20:34.663392: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 51ec72b00 of size 5467648 next 85\n",
            "2025-04-12 15:20:34.663422: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51f1a9900 of size 5729792 next 74\n",
            "2025-04-12 15:20:34.663426: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51f720700 of size 5914624 next 79\n",
            "2025-04-12 15:20:34.663429: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 51fcc4700 of size 5914624 next 71\n",
            "2025-04-12 15:20:34.663433: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 520268700 of size 94633984 next 200\n",
            "2025-04-12 15:20:34.663437: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 525ca8700 of size 94633984 next 69\n",
            "2025-04-12 15:20:34.663442: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 52b6e8700 of size 94633984 next 203\n",
            "2025-04-12 15:20:34.663445: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 531128700 of size 94633984 next 54\n",
            "2025-04-12 15:20:34.663449: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 536b68700 of size 5914624 next 208\n",
            "2025-04-12 15:20:34.663453: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 53710c700 of size 5914624 next 37\n",
            "2025-04-12 15:20:34.663456: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5376b0700 of size 94633984 next 213\n",
            "2025-04-12 15:20:34.663460: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 53d0f0700 of size 94633984 next 9\n",
            "2025-04-12 15:20:34.663464: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 542b30700 of size 94633984 next 218\n",
            "2025-04-12 15:20:34.663467: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 548570700 of size 94633984 next 64\n",
            "2025-04-12 15:20:34.663471: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 54dfb0700 of size 5914624 next 223\n",
            "2025-04-12 15:20:34.663494: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 54e554700 of size 5914624 next 49\n",
            "2025-04-12 15:20:34.663498: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 54eaf8700 of size 94633984 next 228\n",
            "2025-04-12 15:20:34.663502: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 554538700 of size 94633984 next 32\n",
            "2025-04-12 15:20:34.663531: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 559f78700 of size 94633984 next 233\n",
            "2025-04-12 15:20:34.663535: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 55f9b8700 of size 94633984 next 11\n",
            "2025-04-12 15:20:34.663538: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5653f8700 of size 5914624 next 237\n",
            "2025-04-12 15:20:34.663542: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 56599c700 of size 5914624 next 347\n",
            "2025-04-12 15:20:34.663546: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 565f40700 of size 94633984 next 243\n",
            "2025-04-12 15:20:34.663550: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 56b980700 of size 94633984 next 351\n",
            "2025-04-12 15:20:34.663553: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 5713c0700 of size 94633984 next 248\n",
            "2025-04-12 15:20:34.663557: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 576e00700 of size 94633984 next 355\n",
            "2025-04-12 15:20:34.663560: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 57c840700 of size 5914624 next 251\n",
            "2025-04-12 15:20:34.663565: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 57cde4700 of size 5914624 next 359\n",
            "2025-04-12 15:20:34.663569: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 57d388700 of size 94633984 next 258\n",
            "2025-04-12 15:20:34.663572: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 582dc8700 of size 94633984 next 363\n",
            "2025-04-12 15:20:34.663577: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 588808700 of size 111900928 next 18446744073709551615\n",
            "2025-04-12 15:20:34.663580: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
            "2025-04-12 15:20:34.663608: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 144 Chunks of size 256 totalling 36.0KiB\n",
            "2025-04-12 15:20:34.663613: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 512 totalling 512B\n",
            "2025-04-12 15:20:34.663644: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1024 totalling 1.0KiB\n",
            "2025-04-12 15:20:34.663651: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
            "2025-04-12 15:20:34.663660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 109 Chunks of size 2048 totalling 218.0KiB\n",
            "2025-04-12 15:20:34.663668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2816 totalling 5.5KiB\n",
            "2025-04-12 15:20:34.663676: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3072 totalling 9.0KiB\n",
            "2025-04-12 15:20:34.663683: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3584 totalling 10.5KiB\n",
            "2025-04-12 15:20:34.663690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
            "2025-04-12 15:20:34.663718: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 4096 totalling 16.0KiB\n",
            "2025-04-12 15:20:34.663726: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 11 Chunks of size 18432 totalling 198.0KiB\n",
            "2025-04-12 15:20:34.663734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 28672 totalling 112.0KiB\n",
            "2025-04-12 15:20:34.663771: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 36 Chunks of size 65536 totalling 2.25MiB\n",
            "2025-04-12 15:20:34.663777: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 65792 totalling 64.2KiB\n",
            "2025-04-12 15:20:34.663781: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 72448 totalling 495.2KiB\n",
            "2025-04-12 15:20:34.663786: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 102656 totalling 100.2KiB\n",
            "2025-04-12 15:20:34.663791: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 262144 totalling 256.0KiB\n",
            "2025-04-12 15:20:34.663795: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5729792 totalling 5.46MiB\n",
            "2025-04-12 15:20:34.663800: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 10 Chunks of size 5914624 totalling 56.41MiB\n",
            "2025-04-12 15:20:34.663805: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14440192 totalling 13.77MiB\n",
            "2025-04-12 15:20:34.663809: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 18 Chunks of size 94633984 totalling 1.59GiB\n",
            "2025-04-12 15:20:34.663814: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 111900928 totalling 106.72MiB\n",
            "2025-04-12 15:20:34.663819: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 447640064 totalling 426.90MiB\n",
            "2025-04-12 15:20:34.663824: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 2.18GiB\n",
            "2025-04-12 15:20:34.663850: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 2351693824 memory_limit_: 2351693824 available bytes: 0 curr_region_allocation_bytes_: 4703387648\n",
            "2025-04-12 15:20:34.663859: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
            "Limit:                      2351693824\n",
            "InUse:                      2346192128\n",
            "MaxInUse:                   2346192128\n",
            "NumAllocs:                         917\n",
            "MaxAllocSize:                447640064\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2025-04-12 15:20:34.663879: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
            "2025-04-12 15:20:34.663981: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at fused_batch_norm_op.cc:1565 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,512,19,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node model_1/batch_normalization_46/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_1529/2354059667.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_1529/2721073593.py\", line 355, in workflow\n\n  File \"/tmp/ipykernel_1529/2721073593.py\", line 236, in train_model\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[128,512,19,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_46/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7107]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGONetCNNMobileNetwork_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgonetcnnmobilenetwork.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_accuracy_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[2], line 355\u001b[0m, in \u001b[0;36mGONet.workflow\u001b[0;34m(self, epochs, batch, name, log_accuracy_dict)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_backbone()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_model()\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_training_history()\n",
            "Cell \u001b[0;32mIn[2], line 236\u001b[0m, in \u001b[0;36mGONet.train_model\u001b[0;34m(self, batch, epochs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m golois\u001b[38;5;241m.\u001b[39mgetBatch(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN,\n\u001b[1;32m    235\u001b[0m )\n\u001b[0;32m--> 236\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Extraction des valeurs depuis history.history\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_total\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Loss globale\u001b[39;00m\n",
            "File \u001b[0;32m~/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node model_1/batch_normalization_46/FusedBatchNormV3 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_1529/2354059667.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_1529/2721073593.py\", line 355, in workflow\n\n  File \"/tmp/ipykernel_1529/2721073593.py\", line 236, in train_model\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/home/aurelien/workspace/Deep_learning/deep_learning_go/src/venv/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 964, in _fused_batch_norm_training\n\nOOM when allocating tensor with shape[128,512,19,19] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_46/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7107]"
          ]
        }
      ],
      "source": [
        "GONetCNNMobileNetwork_instance.workflow(\n",
        "    epochs=10,\n",
        "    batch=128,\n",
        "    name=\"gonetcnnmobilenetwork.h5\",\n",
        "    log_accuracy_dict={},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters = 512\n",
        "trunk = 128\n",
        "def bottleneck_block(x, expand=filters, squeeze=trunk):\n",
        "  m = layers.Conv2D(\n",
        "    expand, (1,1),\n",
        "    kernel_regularizer=regularizers.l2(0.0001),\n",
        "    use_bias = False\n",
        "  )(x)\n",
        "  m = layers.BatchNormalization()(m)\n",
        "  m = layers.Activation('relu')(m)\n",
        "  m = layers.DepthwiseConv2D((3,3), padding='same',\n",
        "  kernel_regularizer=regularizers.l2(0.0001),\n",
        "  use_bias = False)(m)\n",
        "  m = layers.BatchNormalization()(m)\n",
        "  m = layers.Activation('relu')(m)\n",
        "  m = layers.Conv2D(squeeze, (1,1),\n",
        "  kernel_regularizer=regularizers.l2(0.0001),\n",
        "  use_bias = False)(m)\n",
        "  m = layers.BatchNormalization()(m)\n",
        "  return layers.Add()([m, x])\n",
        "def getModel ():\n",
        "  input = keras.Input(shape=(19, 19, 21), name='board')\n",
        "  x = layers.Conv2D(trunk, 1, padding='same',\n",
        "  kernel_regularizer=regularizers.l2(0.0001))(input)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  for i in range (blocks):\n",
        "    x = bottleneck_block (x, filters, trunk)\n",
        "  policy_head = layers.Conv2D(1, 1, activation='relu', padding='same',\n",
        "  use_bias = False,\n",
        "  kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "  policy_head = layers.Flatten()(policy_head)\n",
        "  policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "  value_head = layers.GlobalAveragePooling2D()(x)\n",
        "  value_head = layers.Dense(50, activation='relu',\n",
        "  kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "  value_head = layers.Dense(1, activation='sigmoid', name='value',\n",
        "  kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "  model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetCNNSmall(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def set_backbone(self):\n",
        "        \"\"\"\n",
        "        Définit l'architecture du tronc du réseau de neurones.\n",
        "\n",
        "        Args: None\n",
        "\n",
        "        Returns:\n",
        "            None: Affecte self.x (sortie du tronc)\n",
        "        \"\"\"\n",
        "        x = layers.ZeroPadding2D(\n",
        "            padding=(0, 0),  # aucun padding pour conserver la dimension 19x19\n",
        "            data_format=\"channels_last\"\n",
        "        )(self.input_layer)\n",
        "\n",
        "        x = layers.Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(7, 7),\n",
        "            padding=\"same\",  # conserve la taille 19x19\n",
        "            activation=\"relu\",\n",
        "            data_format=\"channels_last\"\n",
        "        )(x)\n",
        "        print(f\"{x.shape=}\")\n",
        "\n",
        "        x = layers.ZeroPadding2D(\n",
        "            padding=(0, 0),  # aucun padding pour conserver la dimension 19x19\n",
        "            data_format=\"channels_last\",\n",
        "        )(x)\n",
        "        print(f\"{x.shape=}\")\n",
        "\n",
        "        x = layers.Conv2D(\n",
        "            filters=32,\n",
        "            kernel_size=(48, 48),\n",
        "            padding=\"same\",  # conserve la taille 19x19\n",
        "            activation=\"relu\",\n",
        "            data_format=\"channels_last\",\n",
        "        )(x)\n",
        "        print(f\"{x.shape=}\")\n",
        "\n",
        "    # return [\n",
        "    #     ZeroPadding2D(\n",
        "    #         (3, 3), input_shape=input_shape, data_format=\"channels_first\"\n",
        "    #     ),\n",
        "    #     Conv2D(48, (7, 7), padding=\"valid\", data_format=\"channels_first\"),\n",
        "    #     Activation(\"relu\"),\n",
        "    #     ZeroPadding2D((2, 2), data_format=\"channels_first\"),\n",
        "    #     Conv2D(32, (5, 5), data_format=\"channels_first\"),\n",
        "    #     Activation(\"relu\"),\n",
        "    #     ZeroPadding2D((2, 2), data_format=\"channels_first\"),\n",
        "    #     Conv2D(32, (5, 5), data_format=\"channels_first\"),\n",
        "    #     Activation(\"relu\"),\n",
        "    #     ZeroPadding2D((2, 2), data_format=\"channels_first\"),\n",
        "    #     Conv2D(32, (5, 5), data_format=\"channels_first\"),\n",
        "    #     Activation(\"relu\"),\n",
        "    #     Flatten(),\n",
        "    #     Dense(512),\n",
        "    #     Activation(\"relu\"),\n",
        "    # ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetCNNSmall_instance = GONetCNNSmall()\n",
        "GONetCNNSmall_instance.set_backbone()\n",
        "# GONetCNNSmall_instance.workflow(\n",
        "#     epochs=2,\n",
        "#     batch=128,\n",
        "#     name=\"gonetdemo.h5\",\n",
        "#     log_accuracy_dict=log_accuracy_dict,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Réseaux de neurones résiduels\n",
        "\n",
        "La couche standard utilisée dans les programmes de Go computationnel tels que AlphaGo \\cite{AlphaGo} et DarkForest \\cite{DarkForest} est généralement constituée d’une couche convolutionnelle suivie d’une activation ReLU, comme illustré en Figure~1.\n",
        "\n",
        "La couche résiduelle, souvent utilisée pour des tâches de classification d’images, consiste à additionner l’entrée de la couche avec sa sortie. Elle est composée de deux couches convolutionnelles consécutives, entre lesquelles des activations ReLU sont appliquées après la première convolution et après l’opération d’addition. Cette structure est représentée en Figure~2. Nous envisageons d’exploiter ce type de couches résiduelles dans le cadre de nos réseaux dédiés au jeu de Go.\n",
        "\n",
        "La couche d’entrée de nos réseaux pour le Go adopte elle aussi une structure résiduelle. Elle repose sur une combinaison parallèle de deux couches convolutionnelles : l’une de taille $5 \\times 5$ et l’autre de taille $1 \\times 1$. Leurs sorties respectives sont additionnées, puis une activation ReLU est appliquée. Cette architecture est illustrée en Figure~3.\n",
        "\n",
        "La couche de sortie du réseau est constituée d’une couche convolutionnelle de taille $3 \\times 3$, produisant un unique plan de sortie, suivie d’une fonction d’activation SoftMax. L’ensemble des couches cachées du réseau utilise des filtres de taille $3 \\times 3$ avec 256 plans de caractéristiques.\n",
        "\n",
        "Dans le cadre de cet article, nous définissons la profondeur d’un réseau comme étant le nombre total de couches convolutionnelles. Ainsi, un réseau à 28 couches comprend 28 couches convolutionnelles, correspondant à 14 blocs résiduels tels que décrits en Figure~2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GONetRes_residual(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "    ):\n",
        "        super().__init__(moves, N, planes)\n",
        "\n",
        "    def residual_block(self, x, filters, name_prefix):\n",
        "        skip = x\n",
        "        x = layers.Conv2D(\n",
        "            filters,\n",
        "            3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            name=f\"{name_prefix}_conv1\",\n",
        "        )(x)\n",
        "        x = layers.Conv2D(\n",
        "            filters, 3, padding=\"same\", name=f\"{name_prefix}_conv2\"\n",
        "        )(x)\n",
        "        x = layers.Add(name=f\"{name_prefix}_add\")([x, skip])\n",
        "        x = layers.Activation(\"relu\", name=f\"{name_prefix}_relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def go_residual_input(self, x, filters):\n",
        "        conv_5x5 = layers.Conv2D(\n",
        "            filters, 5, padding=\"same\", name=\"input_conv5x5\"\n",
        "        )(x)\n",
        "        conv_1x1 = layers.Conv2D(\n",
        "            filters, 1, padding=\"same\", name=\"input_conv1x1\"\n",
        "        )(x)\n",
        "        x = layers.Add(name=\"input_add\")([conv_5x5, conv_1x1])\n",
        "        x = layers.Activation(\"relu\", name=\"input_relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def set_backbone(self, filters=256, n_blocks=14):\n",
        "        x = self.go_residual_input(self.input_layer, filters)\n",
        "        for i in range(n_blocks):\n",
        "            x = self.residual_block(x, filters, name_prefix=f\"res{i+1}\")\n",
        "        self.x = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GONetRes_residual_instance = GONetRes_residual()\n",
        "GONetRes_residual_instance.set_backbone()\n",
        "GONetRes_residual_instance.train_model(epochs=2)\n",
        "GONetRes_residual_instance.plot_training_history()\n",
        "GONetRes_residual_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEV7ZUUU0g-3"
      },
      "source": [
        "Création de la classe `GONetRes_cnn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSmJCGWqpZ8F"
      },
      "outputs": [],
      "source": [
        "class GONetRes_cnn(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def set_model(self, filters=32, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 1, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y720WYUsq7--",
        "outputId": "e44cd560-bfe4-4226-c039-8184a259149d"
      },
      "outputs": [],
      "source": [
        "GONetRes_cnn_instance = GONetRes_cnn()\n",
        "GONetRes_cnn_instance.set_model()\n",
        "GONetRes_cnn_instance.train_model(20)\n",
        "GONetRes_cnn_instance.plot_training_history()\n",
        "GONetRes_cnn_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t71Qs2Rg0lS6"
      },
      "source": [
        "## Création de la classe `GONetRes_resnet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iofDxz7OsGh_"
      },
      "outputs": [],
      "source": [
        "class GONetRes_resnet(GONet):\n",
        "    def __init__(\n",
        "        self, batch=128, epochs=20, filters=32, moves=361, N=10000, planes=31\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        \"\"\"\n",
        "        Fonction de création des en-têtes de politique et de valeur.\n",
        "        \"\"\"\n",
        "        policy_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        policy_head = layers.Flatten()(policy_head)\n",
        "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "\n",
        "        value_head = layers.Conv2D(1, 1, activation='relu', padding='same', use_bias=False)(x)\n",
        "        value_head = layers.Flatten()(value_head)\n",
        "        value_head = layers.Dense(50, activation='relu')(value_head)\n",
        "        value_head = layers.Dense(1, activation='sigmoid', name='value')(value_head)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=[policy_head, value_head])\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                      loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "                      metrics={'policy': 'categorical_accuracy', 'value': 'mse'})\n",
        "        return model\n",
        "\n",
        "    def residual_block(self, x, filters):\n",
        "        shortcut = x\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Conv2D(filters, (3,3), padding='same', use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "        x = layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def set_model(self, filters=64, planes=31):\n",
        "        input_layer = layers.Input(shape=(19, 19, planes), name='board')\n",
        "        x = layers.Conv2D(filters, 3, activation='relu', padding='same')(input_layer)\n",
        "        for _ in range(5):\n",
        "            x = self.residual_block(x, filters)\n",
        "        self.model = self.create_policy_value_heads(x, input_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bwkWX5hfs2s6",
        "outputId": "80a31476-61a3-4176-b067-53154d14c857"
      },
      "outputs": [],
      "source": [
        "GONetRes_resnet_instance = GONetRes_resnet()\n",
        "GONetRes_resnet_instance.set_model()\n",
        "GONetRes_resnet_instance.train_model(20)\n",
        "GONetRes_resnet_instance.plot_training_history()\n",
        "GONetRes_resnet_instance.log_accuracy(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "1zImqELY55Zh",
        "outputId": "ed575033-8004-40a1-fd13-32b470a1ea55"
      },
      "outputs": [],
      "source": [
        "save_best_model(log_accuracy_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Compare Resnets, Mobilenets and Convnexts, Shufflenet by training on the game of go**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *Shufflenet*\n",
        "\n",
        "*ShuffleNet* est une architecture de réseau neuronal conçue pour être rapide et efficace. Elle repose sur le concept de permutation des canaux du tenseur d’entrée, ce qui améliore l’efficacité en termes de calcul et d’utilisation de la mémoire.\n",
        "\n",
        "Le réseau se compose de deux principales parties :\n",
        "\n",
        "1.  Couche de convolution : Cette couche a pour rôle d’extraire les caractéristiques du tenseur d’entrée.\n",
        "\n",
        "2.  Couche de permutation (*shuffling*) : Cette couche permutent les canaux du tenseur d’entrée. Elle est conçue pour être légère et efficace, ce qui contribue fortement à la performance globale et à l’efficacité du réseau\n",
        "\n",
        "*Shufflenet* est un mobilenet avec moins de paramètres puisqu'il y a des plans séparés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    DepthwiseConv2D,\n",
        "    Dense,\n",
        "    Concatenate,\n",
        "    Add,\n",
        "    ReLU,\n",
        "    BatchNormalization,\n",
        "    AvgPool2D,\n",
        "    MaxPool2D,\n",
        "    GlobalAveragePooling2D,\n",
        "    Reshape,\n",
        "    Permute,\n",
        "    Lambda,\n",
        "    Flatten,\n",
        "    Activation,\n",
        ")\n",
        "\n",
        "\n",
        "class GONetRes_shufflenet(GONet):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        batch=128,\n",
        "        epochs=20,\n",
        "        filters=32,\n",
        "        moves=361,\n",
        "        N=10000,\n",
        "        planes=31,\n",
        "        trunk=32,  # trunk (hyperparamètre) : nombre de filtres dans le tronc (32, 64, etc.). Dans le modèle de go il est de l'ordre de 32.\n",
        "        blocks=5,  # blocks : nombre de blocs résiduels\n",
        "    ):\n",
        "        super().__init__(batch, epochs, filters, moves, N, planes)\n",
        "        self.trunk = trunk\n",
        "        self.blocks = blocks\n",
        "\n",
        "    def create_policy_value_heads(self, x, input_layer):\n",
        "        input = keras.Input(shape=(19, 19, self.planes), name=\"board\")\n",
        "        x = Conv2D(\n",
        "            self.trunk,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(input)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        for i in range(self.blocks):\n",
        "            x = self.bottleneck_block(x, self.filters, self.trunk)\n",
        "        policy_head = Conv2D(\n",
        "            1,\n",
        "            1,\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\",\n",
        "            use_bias=False,\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(x)\n",
        "        policy_head = Flatten()(policy_head)\n",
        "        policy_head = Activation(\"softmax\", name=\"policy\")(policy_head)\n",
        "        value_head = GlobalAveragePooling2D()(x)\n",
        "        value_head = Dense(\n",
        "            50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
        "        )(value_head)\n",
        "        value_head = Dense(\n",
        "            1,\n",
        "            activation=\"sigmoid\",\n",
        "            name=\"value\",\n",
        "            kernel_regularizer=regularizers.l2(0.0001),\n",
        "        )(value_head)\n",
        "        model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "        return model\n",
        "\n",
        "    def bottleneck_block(self, tensor, expand=96, squeeze=16):\n",
        "        x = self.gconv(tensor, channels=expand, groups=4)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = self.channel_shuffle(x, groups=4)\n",
        "        # Depthwise (comme dans les mobilenets)\n",
        "        x = DepthwiseConv2D(kernel_size=3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = self.gconv(x, channels=squeeze, groups=4)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Add()([tensor, x])\n",
        "        # Les connexions résiduelles ajoutent de la souplesse et permettre de\n",
        "        # rendre les réseaux plus entraînables\n",
        "        output = ReLU()(x)\n",
        "        return output\n",
        "\n",
        "    def gconv(tensor, channels, groups):\n",
        "        \"\"\"\n",
        "        gconv permet de faire un groupe de convolution sur l'entrée du tenseur\n",
        "\n",
        "        Args:\n",
        "            tensor (_type_): _description_\n",
        "            channels (_type_): _description_\n",
        "            groups (_type_): _description_\n",
        "\n",
        "        Returns:\n",
        "            _type_: _description_\n",
        "        \"\"\"\n",
        "        input_ch = tensor.get_shape().as_list()[-1]\n",
        "        group_ch = input_ch // groups\n",
        "        output_ch = channels // groups\n",
        "        groups_list = []\n",
        "        for i in range(groups):\n",
        "            group_tensor = tensor[:, :, :, i * group_ch : (i + 1) * group_ch]\n",
        "            group_tensor = Conv2D(output_ch, 1)(group_tensor)\n",
        "            groups_list.append(group_tensor)\n",
        "        output = Concatenate()(groups_list)\n",
        "        return output\n",
        "\n",
        "    def channel_shuffle(self, x, groups):\n",
        "        _, width, height, channels = x.get_shape().as_list()\n",
        "        group_ch = channels // groups\n",
        "        x = Reshape([width, height, group_ch, groups])(x)\n",
        "        x = Permute([1, 2, 4, 3])(x)\n",
        "        x = Reshape([width, height, channels])(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glossaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Réseau de neurones *feed forward* :\n",
        "\n",
        "« Un réseau de neurones à propagation avant, en anglais *feed forward neural network*, est un réseau de neurones artificiels acyclique, se distinguant ainsi des réseaux de neurones récurrents. Le plus connu est le perceptron multicouche qui est une extension du premier réseau de neurones artificiel. Le perceptron a été inventé en 1957 par Frank Rosenblatt.\n",
        "\n",
        "Le réseau de neurones à propagation avant a été le premier et le plus simple type de réseau neuronal artificiel conçu. Typiquement, il ne comportait qu'une seule couche cachée et s'appelait perceptron. Dans ce réseau, l'information ne se déplace que dans une seule direction, vers l'avant, à partir des nœuds d'entrée, en passant par les couches cachées (le cas échéant) et vers les nœuds de sortie. Il n'y a pas de cycles ou de boucles dans ce réseau. C'est pourquoi on le désigne parfois par réseau de neurones sans boucle.\n",
        "\n",
        "Quand le réseau de neurones à propagation avant comporte plusieurs couches cachées, on parle habituellement d'un perceptron multicouche. » (cf. [Réseau de neurones *feed forward*](https://datafranca.org/wiki/R%C3%A9seau_de_neurones_%C3%A0_propagation_avant))\n",
        "\n",
        "\n",
        "\n",
        "![Réseau de neurones *feed forward*](https://upload.wikimedia.org/wikipedia/commons/8/82/FeedForwardNN.png)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
