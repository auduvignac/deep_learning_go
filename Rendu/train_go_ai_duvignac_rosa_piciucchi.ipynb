{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqnIOf1oB2r9"
   },
   "source": [
    "# Entraînement d'un réseau de neurones pour jouer au Go\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/auduvignac/deep_learning_go/blob/main/src/train_go_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGW-Bl5SB2r_"
   },
   "source": [
    "## Description\n",
    "\n",
    "- [https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html](https://www.lamsade.dauphine.fr/~cazenave/DeepLearningProject.html)  \n",
    "- L'objectif est d'entraîner un réseau pour jouer au jeu de Go.  \n",
    "- Afin de garantir une équité en termes de ressources d'entraînement, le nombre de paramètres des réseaux soumis doit être inférieur à 100 000.  \n",
    "- Le nombre maximal d'étudiants par équipe est de deux.  \n",
    "- Les données utilisées pour l'entraînement proviennent des parties auto-jouées du programme Katago Go.  \n",
    "- Le jeu de données d'entraînement contient un total de 1 000 000 de parties différentes.  \n",
    "- Les données d'entrée sont composées de 31 plans de taille 19x19 :  \n",
    "  - Couleur au trait  \n",
    "  - Échelles  \n",
    "  - État actuel sur deux plans  \n",
    "  - Deux états précédents sur plusieurs plans  \n",
    "- Les cibles de sortie sont :  \n",
    "  - **La politique** : un vecteur de taille 361 avec `1.0` pour le coup joué, `0.0` pour les autres coups.  \n",
    "  - **La valeur** : une valeur entre `0.0` et `1.0` fournie par la recherche d'arbre Monte-Carlo, représentant la probabilité de victoire de Blanc.\n",
    "\n",
    "- Le projet a été écrit et fonctionne sous Ubuntu 22.04.  \n",
    "- Il utilise TensorFlow 2.9 et Keras pour le réseau.  \n",
    "- Un exemple de réseau convolutionnel avec deux têtes est donné dans le fichier `golois.py` et est sauvegardé dans le fichier `test.h5`.  \n",
    "- Les réseaux que vous concevez et entraînez doivent également avoir les mêmes têtes de politique et de valeur et être sauvegardés au format `.h5`.  \n",
    "- Un exemple de réseau et un épisode d'entraînement sont fournis dans le fichier `golois.py`.  \n",
    "- Si vous souhaitez compiler la bibliothèque Golois, vous devez installer **Pybind11** et exécuter `compile.sh`.\n",
    "\n",
    "## Tournois\n",
    "\n",
    "- Toutes les deux semaines environ, un tournoi est organisé entre les réseaux téléchargés.  \n",
    "- Chaque nom de réseau correspond aux noms des étudiants qui ont conçu et entraîné le réseau.  \n",
    "- Le modèle doit être sauvegardé au format **Keras h5**.  \n",
    "- Un tournoi en **round robin** sera organisé et les résultats seront envoyés par e-mail.  \n",
    "- Chaque réseau sera utilisé par un moteur **PUCT**, qui disposera de **2 secondes de temps CPU** par coup pour jouer dans le tournoi.\n",
    "\n",
    "## Exemple de réseau\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import golois\n",
    "\n",
    "planes = 31\n",
    "moves = 361\n",
    "N = 10000\n",
    "epochs = 20\n",
    "batch = 128\n",
    "filters = 32\n",
    "\n",
    "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
    "input_data = input_data.astype(\"float32\")\n",
    "\n",
    "policy = np.random.randint(moves, size=(N,))\n",
    "policy = keras.utils.to_categorical(policy)\n",
    "\n",
    "value = np.random.randint(2, size=(N,))\n",
    "value = value.astype(\"float32\")\n",
    "\n",
    "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
    "end = end.astype(\"float32\")\n",
    "\n",
    "groups = np.zeros((N, 19, 19, 1))\n",
    "groups = groups.astype(\"float32\")\n",
    "\n",
    "print(\"Tensorflow version\", tf.__version__)\n",
    "print(\"getValidation\", flush=True)\n",
    "golois.getValidation(input_data, policy, value, end)\n",
    "\n",
    "\n",
    "input = keras.Input(shape=(19, 19, planes), name=\"board\")\n",
    "x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(input)\n",
    "for i in range(5):\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "policy_head = layers.Conv2D(\n",
    "    1,\n",
    "    1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    ")(x)\n",
    "policy_head = layers.Flatten()(policy_head)\n",
    "policy_head = layers.Activation(\"softmax\", name=\"policy\")(policy_head)\n",
    "value_head = layers.Conv2D(\n",
    "    1,\n",
    "    1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    ")(x)\n",
    "value_head = layers.Flatten()(value_head)\n",
    "value_head = layers.Dense(\n",
    "    50, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)\n",
    ")(value_head)\n",
    "value_head = layers.Dense(\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"value\",\n",
    "    kernel_regularizer=regularizers.l2(0.0001),\n",
    ")(value_head)\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.0005, momentum=0.9),\n",
    "    loss={\n",
    "        \"policy\": \"categorical_crossentropy\",\n",
    "        \"value\": \"binary_crossentropy\",\n",
    "    },\n",
    "    loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
    "    metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
    ")\n",
    "\n",
    "for i in range(1, epochs + 1):\n",
    "    print(\"epoch \" + str(i))\n",
    "    golois.getBatch(input_data, policy, value, end, groups, i * N)\n",
    "    history = model.fit(\n",
    "        input_data,\n",
    "        {\"policy\": policy, \"value\": value},\n",
    "        epochs=1,\n",
    "        batch_size=batch,\n",
    "    )\n",
    "    if i % 5 == 0:\n",
    "        gc.collect()\n",
    "    if i % 20 == 0:\n",
    "        golois.getValidation(input_data, policy, value, end)\n",
    "        val = model.evaluate(\n",
    "            input_data, [policy, value], verbose=0, batch_size=batch\n",
    "        )\n",
    "        print(\"val =\", val)\n",
    "        model.save(\"test.h5\")\n",
    "```\n",
    "\n",
    "## Instructions :  \n",
    "- Entraînez un réseau pour jouer au Go.  \n",
    "- Soumettez les réseaux entraînés **avant samedi soir**.  \n",
    "- Tournoi des réseaux **chaque dimanche**.  \n",
    "- Téléchargez un réseau **avant la fin de la session**.\n",
    "\n",
    "## Objectif du projet\n",
    "\n",
    "Ce projet a pour objectif d’implémenter et d’évaluer plusieurs architectures de réseaux de neurones convolutionnels appliquées à la modélisation du jeu de Go. Les architectures ciblées sont les suivantes :\n",
    "\n",
    "- **ResNet** : réseaux résiduels profonds facilitant l’apprentissage de modèles très profonds grâce aux connexions de saut (skip connections).\n",
    "\n",
    "- **MobileNet** : architectures légères conçues pour les environnements contraints, utilisant des convolutions séparables en profondeur (depthwise separable convolutions) pour réduire le nombre de paramètres.\n",
    "\n",
    "- **ConvNeXt** : réseaux convolutionnels modernes inspirés des Transformers, conçus comme une évolution des CNN classiques avec des performances compétitives sur ImageNet.\n",
    "\n",
    "- **ShuffleNet** : modèles optimisés pour l'efficacité computationnelle, combinant group convolutions et opérations de réorganisation (channel shuffle) pour limiter le coût en calcul tout en maintenant de bonnes performances.\n",
    "\n",
    "Ces modèles seront adaptés, entraînés et comparés dans le cadre d’un apprentissage supervisé pour prédire les coups dans des parties de Go.\n",
    "\n",
    "## Mise en place de l'environnement de travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dvHmQK9tU2S"
   },
   "source": [
    "Installation préalable de l’API de Go et de la bibliothèque Golois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "VvTcnNjdcrGe",
    "outputId": "8ecc98fe-5e0f-47a6-cdee-df5968d55b2a"
   },
   "outputs": [],
   "source": [
    "!wget https://www.lamsade.dauphine.fr/~cazenave/project2025.zip\n",
    "!unzip project2025.zip\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ahGisrKtU2U"
   },
   "source": [
    "Ensuite, nous allons installer les dépendances nécessaires à l'entraînement du réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "LXj_yFKDbhiI",
    "outputId": "ee8c4a58-1499-4559-9c23-cf5647dd0069"
   },
   "outputs": [],
   "source": [
    "%pip uninstall -y tensorflow\n",
    "%pip install tensorrt-bindings==8.6.1\n",
    "%pip install --extra-index-url https://pypi.nvidia.com tensorrt-libs\n",
    "%pip install tensorflow[and-cuda]==2.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ETzpOZ5tU2W"
   },
   "source": [
    "**Remarque importante :** Cette étape réalisée, il est nécessaire de redémmarer la session par l'intermédiaire de l'onglet « Exécution » et « Redémarrer le session »."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nyInIRFh_KZ"
   },
   "source": [
    "# Choix méthodologique : Focalisation sur la profondeur des réseaux\n",
    "\n",
    "Dans le cadre de cette étude, le choix a été fait de **faire varier exclusivement la profondeur des architectures** (nombre de blocs) tout en maintenant constantes les autres paramètres, notamment le **nombre de filtres**.\n",
    "\n",
    "Cette stratégie s'inscrit dans une logique rigoureuse, à la croisée de contraintes pratiques et d'objectifs analytiques :\n",
    "\n",
    "- **Objectif ciblé** : L'étude vise à évaluer l'**impact direct de la profondeur** sur la capacité d'un modèle à apprendre les régularités d'un jeu de stratégie complexe comme le Go, dans un **cadre contraint en ressources**.\n",
    "- **Contrainte stricte de complexité** : Tous les modèles sont limités à un **maximum de 100 000 paramètres**, ce qui exclut toute montée en capacité par simple élargissement du réseau.\n",
    "- **Contrôle expérimental** : En maintenant constant le nombre de filtres, on **isole l'effet de la profondeur** sur la performance, ce qui permet une analyse plus fine de son influence.\n",
    "- **Approche progressive** : En explorant un grand nombre de profondeurs différentes (jusqu'à 28 blocs pour `MobileNet`), le travail permet de **cartographier la relation entre profondeur et performance** dans un budget de complexité fixe.\n",
    "- **Justification temporelle** : Compte tenu des **contraintes de temps inhérentes au projet**, un balayage systématique de la profondeur a été privilégié à une exploration conjointe profondeur-largeur, qui aurait exigé davantage de ressources.\n",
    "\n",
    "> Le choix de **ne faire évoluer que la profondeur des réseaux** dans une enveloppe de **paramètres limitée à 100 000** permet d'**évaluer précisément la complexité verticale** des architectures tout en **respectant un budget computationnel réaliste**. Ce cadre expérimental assure une **analyse structurée, reproductible et pertinente** dans le contexte du projet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbD7AJF5tU2W"
   },
   "source": [
    "## Rappels Apprentissage par renforcement\n",
    "\n",
    "« L'apprentissage par renforcement (en anglais, *reinforcement learning*, ou RL) est la branche de l'apprentissage automatique qui consiste à apprendre comment un agent doit se comporter dans un environnement de manière à maximiser une récompense. Naturellement, l’apprentissage par renforcement profond restreint la méthode d'apprentissage à l'apprentissage profond » ([Charniak, E. (2019). *Introduction au Deep Learning*. Dunod. p. 105](https://www.dunod.com/sciences-techniques/introduction-au-deep-learning)).\n",
    "\n",
    "« Dans l'apprentissage par renforcement, un agent logiciel procède à des observations et réalise des actions au sein d'un environnement. En retour, il reçoit des récompenses. Son objectif est d'apprendre à agir de façon à maximiser les récompenses espérées sur le long terme » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 440](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
    "\n",
    "« L'algorithme que l'agent logiciel utilise pour déterminer ses actions est appelé stratégie ou politique (*policy*). Cette politique peut être un réseau de neurones qui prend en entrée des observations et produit en sortie l'action à réaliser » ([Géron, A. (2023). *Deep Learning avec Keras et TensorFlow* (3e éd.). O'Reilly. p. 441](https://www.dunod.com/sciences-techniques/deep-learning-avec-keras-et-tensorflow-mise-en-oeuvre-et-cas-concrets-0)).\n",
    "\n",
    "\n",
    "Dans le cas du jeu de go:\n",
    "- L'agent est le programme qui joue au jeu ;\n",
    "- L'environnement est le plateau de jeu ;\n",
    "- Les récompenses sont les points gagnés ou perdus lors d'une partie ;\n",
    "- La politique définit la manière dont l'agent choisit ses coups en fonction de l'état du plateau, dans le but de maximiser ses gains à long terme.\n",
    "\n",
    "\n",
    "L'objectif de ce projet est de concevoir un réseau de neurones permettant de jouer au jeu de go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR4CT2R1qaB1"
   },
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAcwAJJ9qZF7"
   },
   "outputs": [],
   "source": [
    "import gc  # garbage collector\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    DepthwiseConv2D,\n",
    "    Dense,\n",
    "    Concatenate,\n",
    "    Add,\n",
    "    ReLU,\n",
    "    BatchNormalization,\n",
    "    AvgPool2D,\n",
    "    MaxPool2D,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    "    Permute,\n",
    "    Lambda,\n",
    "    Flatten,\n",
    "    Activation,\n",
    ")\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "import golois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAucsK0ggMaP"
   },
   "source": [
    "## Création de la classe abstraite `GONet`\n",
    "\n",
    "La première étape consiste à implémenter une classe abstraite `GONet` dont l’objectif est de servir de **modèle générique** pour la construction de réseaux de neurones capables de prédire les coups joués (politique) et la probabilité de victoire (valeur) dans le cadre du jeu de Go. Elle fournit un cadre modulaire, réutilisable et traçable pour expérimenter les diverses architectures de CNN proposée : `ResNet`, `MobileNet`, `ConvNeXt`, `ShuffleNet`,  et garantit que toutes les variantes partagent une base commune et comparable, tant sur le plan technique (entrée, sortie, entraînement) que méthodologique (nombre de paramètres, métriques, etc.).\n",
    "\n",
    "Cette classe regroupe l’ensemble des **comportements communs** à toutes les architectures : génération des données d’entrée et des cibles simulées, définition des entrées du modèle, création des têtes de sortie (politique et valeur), compilation, entraînement, évaluation, traçage des métriques et sauvegarde. L’enchaînement complet de ces étapes est centralisé dans la méthode `workflow()`.\n",
    "\n",
    "Pour assurer une compréhension aisée de l'implémentation et se focaliser exclusivement sur la construction des quatre architectures proposées dans l'énoncé, les principes fondamentaux de la programmation orientée objet seront exploités :\n",
    "\n",
    "- **Aabstraction** : via la méthode abstraite `set_backbone()`, qui impose aux classes dérivées de définir leur propre architecture du réseau (*backbone* convolutionnel) ;\n",
    "- **Héritage** : les architectures spécifiques (`ResNet`, `MobileNet`, `ConvNeXt`, `ShuffleNet`) seront implémentées dans des classes filles (`ResNetGONet`, `MobileNetGONet`, `ConvNeXtGONet`, `ShuffleNetGONet`) qui hériteront de `GONet` et exploiteront l’ensemble des fonctionnalités définies dans la classe mère ;\n",
    "- **Encapsulation** : les différentes étapes de préparation des données, de construction du modèle et d’entraînement sont regroupées dans des méthodes cohérentes, appelées par un point d’entrée unique (`workflow()`).\n",
    "\n",
    "L'objectif est de **standardiser l’entraînement, l’évaluation et la comparaison** des modèles tout en respectant les contraintes du projet, notamment :\n",
    "\n",
    "- Un maximum de **100 000 paramètres** ;\n",
    "- Deux en-têtes de sortie fixes : **politique** (softmax) et **valeur** (sigmoïde) ;\n",
    "- Données d’entrée : **31 plans 19×19** (représentation du plateau de Go) ;\n",
    "- Données générées automatiquement pour simuler l'entraînement.\n",
    "\n",
    "### Structure générale\n",
    "\n",
    "Les méthodes implémentées dans la classe mère `GONet` sont résumées ci-dessous et décrites dans le paragraphe suivant.\n",
    "\n",
    "```python\n",
    "class GONet(ABC):\n",
    "    # Méthodes utilitaires (initialisation et préparation des données)\n",
    "    def __init__(...)\n",
    "    def set_end(...)\n",
    "    def set_groups(...)\n",
    "    def set_input_data(...)\n",
    "    def set_input_layer(...)\n",
    "    def set_policy(...)\n",
    "    def set_value(...)\n",
    "\n",
    "    # Méthodes liées au modèle\n",
    "    def create_policy_value_heads(...)\n",
    "    def plot_model(...)\n",
    "    def set_backbone(...) # méthode abstraite\n",
    "    def set_model(...)\n",
    "\n",
    "    # Méthodes d'entraînement et d’évaluation\n",
    "    def log_accuracy(...)\n",
    "    def plot_training_history(...)\n",
    "    def train_model(...)\n",
    "    def workflow(...)\n",
    "\n",
    "    # Méthode de sauvegarde\n",
    "    def save_model(...)\n",
    "```\n",
    "\n",
    "### Description des méthodes\n",
    "\n",
    "#### Méthodes utilitaires (initialisation et préparation des données)\n",
    "\n",
    "##### `__init__()`\n",
    "- Initialise l’ensemble des composants nécessaires à la construction du modèle ;\n",
    "- Génère des **données simulées aléatoires** pour les entrées (plans du plateau) et les cibles (politique, valeur, fin de partie, groupes) ;\n",
    "- Prépare les structures internes pour l'entraînement et le suivi des métriques.\n",
    "\n",
    "##### `set_end()` et `set_groups()`\n",
    "- Produisent des représentations auxiliaires du plateau :\n",
    "  - `end` : pour simuler des fins de partie ;\n",
    "  - `groups` : pour simuler des regroupements de pierres.\n",
    "\n",
    "##### `set_input_data()`\n",
    "- Simule les **données d’entrée** sous la forme d’un tenseur `[N, 19, 19, 31]` représentant l’état du plateau à travers 31 plans.\n",
    "\n",
    "##### `set_input_layer()`\n",
    "- Définit la **couche d’entrée** du modèle : `Input(shape=(19, 19, 31))`.\n",
    "\n",
    "##### `set_policy()`\n",
    "- Génére des cibles pour la **tête de politique** sous forme de vecteurs one-hot de taille 361 (correspondant aux 361 positions du plateau 19x19).\n",
    "\n",
    "##### `set_value()`\n",
    "- Génére une **valeur binaire** (0 ou 1) représentant la probabilité de victoire de Blanc.\n",
    "\n",
    "#### Méthodes liées au modèle\n",
    "\n",
    "##### `create_policy_value_heads()`\n",
    "- Ajoute les deux **têtes de prédiction** finales :\n",
    "  - **Politique** : `Conv2D(1x1)` → `Flatten` → `Softmax` (sortie de taille 361) ;\n",
    "  - **Valeur** : `Conv2D(1x1)` → `Dense(50)` → `Dense(1, Sigmoid)`.\n",
    "\n",
    "- Compile le modèle avec :\n",
    "  - Optimiseur : `SGD` avec momentum `0.9` ;\n",
    "  - Pertes : `categorical_crossentropy` (politique), `binary_crossentropy` (valeur) ;\n",
    "  - Métriques : `categorical_accuracy` et `MSE`.\n",
    "\n",
    "- Vérifie que le nombre total de **paramètres** est inférieur à 100 000, sinon une exception est levée.\n",
    "\n",
    "##### `plot_model()`\n",
    "- Affiche la **structure graphique** du modèle Keras, incluant les couches et leurs dimensions.\n",
    "\n",
    "##### `set_backbone()`\n",
    "- Méthode **abstraite** (définie avec `@abstractmethod`) que chaque sous-classe doit redéfinir pour spécifier l’architecture du backbone convolutionnel.\n",
    "- Doit produire un tenseur de forme `(None, 19, 19, 32)` affecté à `self.x`.\n",
    "\n",
    "##### `set_model()`\n",
    "- Assemble le modèle complet en combinant le **backbone** défini par la sous-classe et les têtes (politique et valeur).\n",
    "\n",
    "#### Méthodes d'entraînement et d’évaluation\n",
    "\n",
    "##### `log_accuracy(results_dict)`\n",
    "- Ajoute la dernière valeur de **précision de la tête politique** dans un dictionnaire de résultats pour comparaison entre architectures.\n",
    "\n",
    "##### `plot_training_history()`\n",
    "- Affiche l’évolution de l’apprentissage sous forme de courbes :\n",
    "  - Pertes : totale, politique, valeur ;\n",
    "  - Métriques : précision politique (*categorical accuracy*) et MSE valeur.\n",
    "\n",
    "##### `train_model()`\n",
    "- Lance l’entraînement du modèle sur plusieurs *epochs* ;\n",
    "- Enregistre les **pertes et métriques** à chaque époque ;\n",
    "- Effectue une évaluation intermédiaire toutes les 20 *epochs* ;\n",
    "- Libère la mémoire toutes les 5 *epochs* via `gc.collect()`.\n",
    "\n",
    "##### `workflow(epochs, batch, name, log_accuracy_dict)`\n",
    "- Lance le **pipeline complet** du modèle :\n",
    "  1. Construction du backbone ;\n",
    "  2. Création du modèle ;\n",
    "  3. Entraînement ;\n",
    "  4. Sauvegarde ;\n",
    "  5. Affichage des courbes d’apprentissage ;\n",
    "  6. Enregistrement de l’accuracy finale.\n",
    "\n",
    "#### Méthode de sauvegarde\n",
    "\n",
    "##### `save_model(name)`\n",
    "- Sauvegarde le modèle Keras entraîné au format `.h5` dans le fichier spécifié (`name`), en vue d’une soumission ou d’une réutilisation ultérieure.\n",
    "\n",
    "### Tableau récapitulatif des méthodes de `GONet`\n",
    "\n",
    "| Méthode                   |  Description                                                | Catégorie                            |\n",
    "|---------------------------|-------------------------------------------------------------|--------------------------------------|\n",
    "| `__init__()`              | Initialise les composants et les données simulées           | Utilitaires / Initialisation         |\n",
    "| `set_end()`               | Crée des fins de parties simulées                           | Utilitaires / Initialisation         |\n",
    "| `set_groups()`            | Initialise les groupes de pierres                           | Utilitaires / Initialisation         |\n",
    "| `set_input_data()`        | Génère les entrées simulées du plateau                      | Utilitaires / Initialisation         |\n",
    "| `set_input_layer()`       | Définit la couche d’entrée du modèle                        | Utilitaires / Initialisation         |\n",
    "| `set_policy()`            | Génère les cibles de la politique (one-hot)                 | Utilitaires / Initialisation         |\n",
    "| `set_value()`             | Génère les cibles de la valeur (0 ou 1)                     | Utilitaires / Initialisation         |\n",
    "| `create_policy_value_heads()` | Ajoute les têtes de sortie (politique, valeur) et compile le modèle | Modèle                               |\n",
    "| `plot_model()`            | Affiche la structure du modèle                              | Modèle                               |\n",
    "| `set_backbone()`          | Méthode abstraite pour définir l’architecture CNN           | Modèle (à implémenter dans les classes filles) |\n",
    "| `set_model()`             | Assemble le backbone et les têtes                           | Modèle                               |\n",
    "| `log_accuracy()`          | Enregistre la dernière accuracy dans un dictionnaire        | Entraînement / Évaluation            |\n",
    "| `plot_training_history()` | Affiche les courbes de pertes et métriques                  | Entraînement / Évaluation            |\n",
    "| `train_model()`           | Entraîne le modèle et collecte les métriques                | Entraînement / Évaluation            |\n",
    "| `workflow()`              | Exécute le pipeline complet d’entraînement et d’évaluation  | Entraînement / Évaluation            |\n",
    "| `save_model(name)`        | Sauvegarde le modèle au format `.h5`                        | Sauvegarde                           |\n",
    "\n",
    "\n",
    "### Elements de précision sur l'interprétation des courbes de *loss* et des métriques\n",
    "\n",
    "Les courbes d'entraînement illustrent l'évolution conjointe des erreurs (*losses*) et des performances (métriques) du modèle tout au long de l'apprentissage.\n",
    "Ces valeurs sont collectées à chaque *epoch* au sein de la méthode `train_model`, qui enregistre les différentes mesures de *loss* et de précision pendant l'entraînement.\n",
    "\n",
    "Le tableau ci-dessous synthétise leur signification :\n",
    "\n",
    "#### Losses\n",
    "\n",
    "| **Courbe**      | **Interprétation**                                                                 |\n",
    "|-----------------|-------------------------------------------------------------------------------------|\n",
    "| *Loss* totale | Somme pondérée des pertes de la tête policy et de la tête value.                   |\n",
    "| *Policy Loss* | Perte de classification associée à la prédiction du coup (ex. : `categorical_crossentropy`). |\n",
    "| *Value Loss*  | Perte de régression pour estimer l'issue de la partie (ex. : `mean_squared_error`). |\n",
    "\n",
    "#### Métriques\n",
    "\n",
    "| **Courbe**         | **Interprétation**                                                                 |\n",
    "|--------------------|------------------------------------------------------------------------------------|\n",
    "| *Policy Accuracy*| Taux de bonnes prédictions des coups joués, évalué sur la tête de policy.          |\n",
    "| *Value MSE*      | Erreur quadratique moyenne sur la prédiction de la valeur de position (tête value).|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_6C3MiaVelc"
   },
   "outputs": [],
   "source": [
    "class GONet(ABC):\n",
    "    \"\"\"\n",
    "    Classe abstraite pour la construction d'un réseau de neurones pour le jeu de Go.\n",
    "\n",
    "    Cette classe initialise des données simulées, définit les entrées et\n",
    "    sorties du modèle, permet la construction des en-têtes de prédiction\n",
    "    (politique et valeur), et gère l'entraînement et l'évaluation.\n",
    "\n",
    "    Les sous-classes doivent obligatoirement implémenter `set_backbone()`,\n",
    "    qui définit l'architecture du corps principal du réseau.\n",
    "\n",
    "    La méthode `create_policy_value_heads` en charge de créer les en-têtes\n",
    "    de sortie du modèle (politique et valeur) restera inchangée indépendamment\n",
    "    de la structure du réseau de neurones utilisée.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Méthodes utilitaires / initialisation\n",
    "    # -------------------------------------\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"model\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialise les paramètres et génère les données d'entraînement aléatoires.\n",
    "\n",
    "        Args:\n",
    "            moves (int): Nombre total de coups possibles (361 pour un plateau 19x19).\n",
    "            N (int): Nombre d'exemples dans le jeu de données.\n",
    "            planes (int): Nombre de plans utilisés en entrée pour représenter le plateau.\n",
    "        \"\"\"\n",
    "        self.moves = moves\n",
    "        self.N = N\n",
    "        self.planes = planes\n",
    "        self.max_params = max_params\n",
    "        self.nb_params = 0\n",
    "        self.name = name\n",
    "        self.set_input_data()\n",
    "        self.set_policy()\n",
    "        self.set_value()\n",
    "        self.set_end()\n",
    "        self.set_groups()\n",
    "        self.set_input_layer()\n",
    "        golois.getValidation(\n",
    "            self.input_data, self.policy, self.value, self.end\n",
    "        )\n",
    "        self.loss_total = []\n",
    "        self.policy_loss = []\n",
    "        self.value_loss = []\n",
    "        self.policy_acc = []\n",
    "        self.value_mse = []\n",
    "\n",
    "    def set_end(self):\n",
    "        \"\"\"\n",
    "        Génère des représentations aléatoires de fin de partie.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.end (forme: [N, 19, 19, 2])\n",
    "        \"\"\"\n",
    "        end = np.random.randint(2, size=(self.N, 19, 19, 2))\n",
    "        self.end = end.astype(\"float32\")\n",
    "\n",
    "    def set_groups(self):\n",
    "        \"\"\"\n",
    "        Initialise des groupes de pierres à zéro.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.groups (forme: [N, 19, 19, 1])\n",
    "        \"\"\"\n",
    "        groups = np.zeros((self.N, 19, 19, 1))\n",
    "        self.groups = groups.astype(\"float32\")\n",
    "\n",
    "    def set_input_data(self):\n",
    "        \"\"\"\n",
    "        Génère les données d'entrée du réseau sous forme de tenseurs aléatoires.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.input_data (forme: [N, 19, 19, planes])\n",
    "        \"\"\"\n",
    "        input_data = np.random.randint(2, size=(self.N, 19, 19, self.planes))\n",
    "        self.input_data = input_data.astype(\"float32\")\n",
    "\n",
    "    def set_input_layer(self):\n",
    "        \"\"\"\n",
    "        Définit la couche d'entrée du modèle.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.input_layer (couche d'entrée)\n",
    "        \"\"\"\n",
    "        # Couche d'entrée : plateau de Go 19x19 avec P plans de caractéristiques\n",
    "        self.input_layer = keras.Input(\n",
    "            shape=(19, 19, self.planes), name=\"board\"\n",
    "        )\n",
    "\n",
    "    def set_policy(self):\n",
    "        \"\"\"\n",
    "        Génère des cibles de politique sous forme one-hot encodées.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.policy (forme: [N, moves])\n",
    "        \"\"\"\n",
    "        policy = np.random.randint(self.moves, size=(self.N,))\n",
    "        self.policy = keras.utils.to_categorical(policy)\n",
    "\n",
    "    def set_value(self):\n",
    "        \"\"\"\n",
    "        Génère des valeurs de victoire (0 ou 1) aléatoires.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.value (forme: [N])\n",
    "        \"\"\"\n",
    "        value = np.random.randint(2, size=(self.N,))\n",
    "        self.value = value.astype(\"float32\")\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Méthodes liées au modèle\n",
    "    # -------------------------------------\n",
    "\n",
    "    def create_policy_value_heads(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Crée les en-têtes de sortie du modèle : politique (softmax) et\n",
    "        valeur (sigmoïde).\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Sortie du tronc du modèle.\n",
    "            input_layer (Tensor): Couche d'entrée du modèle.\n",
    "\n",
    "        Returns:\n",
    "            keras.Model: Modèle compilé avec têtes de sortie et métriques\n",
    "              définies.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            expected_shape = (None, 19, 19, 32)\n",
    "\n",
    "            for i, (a, e) in enumerate(zip(self.x.shape, expected_shape)):\n",
    "                if e is not None and a != e:\n",
    "                    raise ValueError(\n",
    "                        f\"\"\"\n",
    "                        - Forme inattendue pour self.x : {self.x.shape}.\n",
    "                        - La dimension {i} vaut {a} au lieu de {e} ;\n",
    "                        - Forme attendue complète : {expected_shape}\n",
    "                      \"\"\"\n",
    "                    )\n",
    "            # En-tête de politique\n",
    "            policy_head = layers.Conv2D(\n",
    "                1,\n",
    "                1,\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizers.l2(0.0001),\n",
    "            )(self.x)\n",
    "            policy_head = layers.Flatten()(policy_head)\n",
    "            policy_head = layers.Activation(\"softmax\", name=\"policy\")(\n",
    "                policy_head\n",
    "            )\n",
    "            # En-tête de valeur\n",
    "            value_head = layers.Conv2D(\n",
    "                1,\n",
    "                1,\n",
    "                activation=\"relu\",\n",
    "                padding=\"same\",\n",
    "                use_bias=False,\n",
    "                kernel_regularizer=regularizers.l2(0.0001),\n",
    "            )(self.x)\n",
    "            value_head = layers.Flatten()(value_head)\n",
    "            value_head = layers.Dense(\n",
    "                50,\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(0.0001),\n",
    "            )(value_head)\n",
    "            value_head = layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                name=\"value\",\n",
    "                kernel_regularizer=regularizers.l2(0.0001),\n",
    "            )(value_head)\n",
    "\n",
    "            model = keras.Model(\n",
    "                inputs=self.input_layer,\n",
    "                outputs=[policy_head, value_head],\n",
    "                name=self.name,\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                model.summary()\n",
    "\n",
    "            # Vérification du nombre total de paramètres\n",
    "            self.nb_params = model.count_params()\n",
    "            if self.nb_params > self.max_params:\n",
    "                raise Exception(\n",
    "                    f\"\"\"\n",
    "                  Le nombre de paramètres {self.nb_params} doit être inférieur à {self.max_params}\n",
    "                \"\"\"\n",
    "                )\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"Le modèle contient {self.nb_params} paramètres, \"\n",
    "                        f\"inférieur au seuil maximal ({self.max_params}). \"\n",
    "                        \"Traitement poursuivi.\"\n",
    "                    )\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=keras.optimizers.SGD(\n",
    "                    learning_rate=0.0005, momentum=0.9\n",
    "                ),\n",
    "                loss={\n",
    "                    \"policy\": \"categorical_crossentropy\",\n",
    "                    \"value\": \"binary_crossentropy\",\n",
    "                },\n",
    "                loss_weights={\"policy\": 1.0, \"value\": 1.0},\n",
    "                metrics={\"policy\": \"categorical_accuracy\", \"value\": \"mse\"},\n",
    "            )\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "    def plot_model(self):\n",
    "        plot_model(self.model, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_backbone(self):\n",
    "        \"\"\"\n",
    "        Méthode abstraite pour définir le tronc du modèle (blocs convolutifs,\n",
    "          etc.).\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Doit être implémentée dans une sous-classe.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"set_backbone() must be implemented in subclasses\"\n",
    "        )\n",
    "\n",
    "    def set_model(self, verbose=False):\n",
    "        self.model = self.create_policy_value_heads(verbose)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Entrainement et évaluation\n",
    "    # -------------------------------------\n",
    "\n",
    "    def log_accuracy(self, results_dict={}):\n",
    "        \"\"\"\n",
    "        Enregistre la dernière précision de la tête \"policy\" dans un\n",
    "          dictionnaire.\n",
    "\n",
    "        Args:\n",
    "            results_dict (dict): Dictionnaire auquel ajouter les résultats.\n",
    "\n",
    "        Returns:\n",
    "            None: Met à jour results_dict avec l'accuracy du modèle.\n",
    "        \"\"\"\n",
    "        results_dict[self.__class__.__name__] = {\n",
    "            \"instance\": self,\n",
    "            \"accuracy\": self.policy_acc[-1],\n",
    "        }\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"\n",
    "        Affiche les courbes d'apprentissage pour les pertes et métriques\n",
    "        (par époque).\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affiche un graphique matplotlib.\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.loss_total) + 1)  # Liste des époques\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.suptitle(\n",
    "            f\"Évolution de l'entraînement du modèle : {self.name}\", fontsize=16\n",
    "        )\n",
    "\n",
    "        # Graphique des pertes\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.loss_total, label=\"Loss totale\", marker=\"o\")\n",
    "        plt.plot(epochs, self.policy_loss, label=\"Policy Loss\", marker=\"o\")\n",
    "        plt.plot(epochs, self.value_loss, label=\"Value Loss\", marker=\"o\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Valeur de la loss\")\n",
    "        plt.title(\"Évolution des losses\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Graphique des métriques\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.policy_acc, label=\"Policy Accuracy\", marker=\"o\")\n",
    "        plt.plot(epochs, self.value_mse, label=\"Value MSE\", marker=\"o\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Valeur des métriques\")\n",
    "        plt.title(\"Évolution des métriques\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Affichage\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    def train_model(self, batch=128, epochs=20, verbose=False):\n",
    "        \"\"\"\n",
    "        Entraîne le modèle en plusieurs époques avec suivi des métriques.\n",
    "\n",
    "        Args:\n",
    "            batch (int): Taille du batch d'entraînement.\n",
    "            epochs (int): Nombre total d'époques.\n",
    "\n",
    "        Returns:\n",
    "            None: Met à jour l'historique d'entraînement.\n",
    "        \"\"\"\n",
    "        for i in range(1, epochs + 1):\n",
    "            print(f\"epoch {i}\")\n",
    "            golois.getBatch(\n",
    "                self.input_data,\n",
    "                self.policy,\n",
    "                self.value,\n",
    "                self.end,\n",
    "                self.groups,\n",
    "                i * self.N,\n",
    "            )\n",
    "            history = self.model.fit(\n",
    "                self.input_data,\n",
    "                {\"policy\": self.policy, \"value\": self.value},\n",
    "                epochs=1,\n",
    "                batch_size=batch,\n",
    "            )\n",
    "            # Extraction des valeurs depuis history.history\n",
    "            self.loss_total.append(history.history[\"loss\"][0])\n",
    "            self.policy_loss.append(\n",
    "                history.history[\"policy_loss\"][0]\n",
    "            )  # Policy loss\n",
    "            self.value_loss.append(\n",
    "                history.history[\"value_loss\"][0]\n",
    "            )  # Value loss\n",
    "            self.policy_acc.append(\n",
    "                history.history[\"policy_categorical_accuracy\"][0]\n",
    "            )  # Policy accuracy\n",
    "            self.value_mse.append(history.history[\"value_mse\"][0])\n",
    "            if i % 5 == 0:\n",
    "                gc.collect()\n",
    "            if i % 20 == 0:\n",
    "                golois.getValidation(\n",
    "                    self.input_data, self.policy, self.value, self.end\n",
    "                )\n",
    "                val = self.model.evaluate(\n",
    "                    self.input_data,\n",
    "                    [self.policy, self.value],\n",
    "                    verbose=0,\n",
    "                    batch_size=batch,\n",
    "                )\n",
    "                if verbose:\n",
    "                    print(f\"{val=}\")\n",
    "\n",
    "    def workflow(\n",
    "        self,\n",
    "        epochs=20,\n",
    "        batch=128,\n",
    "        save_model=False,\n",
    "        log_accuracy_dict={},\n",
    "        verbose=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Exécute le flux de travail complet : construction, entraînement et évaluation du modèle.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): Nombre d'époques pour l'entraînement.\n",
    "            batch (int): Taille du batch pour l'entraînement.\n",
    "            save_model (boolean): Si True enregistre le modèle au format h5 dans un fichier\n",
    "            Nom du fichier pour enregistrer le modèle.\n",
    "            log_accuracy_dict (dict): Dictionnaire pour enregistrer les résultats d'accuracy.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.set_backbone()\n",
    "        self.set_model(verbose=verbose)\n",
    "        self.train_model(epochs=epochs, batch=batch, verbose=verbose)\n",
    "        if save_model:\n",
    "            if not self.name:\n",
    "                print(\n",
    "                    \"Le modèle n’a pas de nom défini, il ne pourra donc pas être \"\n",
    "                    \"enregistré.\"\n",
    "                )\n",
    "            else:\n",
    "                self.save_model(name=f\"{self.name}.h5\")\n",
    "        self.plot_training_history()\n",
    "        self.log_accuracy(results_dict=log_accuracy_dict)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Sauvegarde du modèle\n",
    "    # -------------------------------------\n",
    "\n",
    "    def save_model(self, name):\n",
    "        \"\"\"\n",
    "        Sauvegarde le modèle et déclenche le téléchargement dans le fichier dédié.\n",
    "\n",
    "        Args:\n",
    "            name (str): Nom de fichier pour enregistrer le modèle (.h5, etc.)\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.model.save(name)\n",
    "        # A décommenter avec Google Colab\n",
    "        files.download(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ivfyKAwgMaQ"
   },
   "source": [
    "Dans l'objectif de conserver le modèle ayant obtenu la meilleur précision, une méthode `save_best_model` est également implémentée.\n",
    "Celle-ci prend deux paramètres d'entrée :\n",
    "- un dictionnaire intitulé `results_dict` qui contient les instances des modèles et leur précision respective ;\n",
    "- le nom du fichier dans lequel sera conservé le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXuo5huH7cIy"
   },
   "outputs": [],
   "source": [
    "def save_best_model(results_dict, model_name=\"test.h5\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde le modèle ayant obtenu la meilleure précision (accuracy) à\n",
    "    partir d'un dictionnaire de résultats.\n",
    "\n",
    "    Le dictionnaire 'results_dict' doit contenir, pour chaque clef\n",
    "    (nom du modèle), une structure :\n",
    "        {\n",
    "            \"instance\": instance_du_modèle,\n",
    "            \"accuracy\": précision_obtenue (float)\n",
    "        }\n",
    "\n",
    "    La fonction identifie l'entrée avec la précision maximale, affiche un\n",
    "    résumé, et sauvegarde l'instance correspondante au format Keras (.h5) sous\n",
    "    le nom spécifié.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    results_dict : dict\n",
    "        Dictionnaire contenant les modèles et leurs précisions associées.\n",
    "\n",
    "    model_name : str\n",
    "        Nom du fichier dans lequel sauvegarder le meilleur modèle (format .h5).\n",
    "\n",
    "    Retourne\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not results_dict:\n",
    "        return None  # Gestion du cas où le dictionnaire est vide\n",
    "\n",
    "    # Recherche le modèle avec la meilleure précision\n",
    "    best_model_key = max(\n",
    "        results_dict, key=lambda k: results_dict[k][\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # garder en mémoire la meilleure précision\n",
    "    best_accuracy = results_dict[best_model_key][\"accuracy\"]\n",
    "\n",
    "    # et l'instance du modèle\n",
    "    best_instance = results_dict[best_model_key][\"instance\"]\n",
    "\n",
    "    print(\n",
    "        f\"Le réseau {best_instance.name} est celui qui a enregistré la \"\n",
    "        f\"meilleure accuracy : {best_accuracy}\"\n",
    "    )\n",
    "\n",
    "    best_instance.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GxMhcBotU2a"
   },
   "source": [
    "Un dictionnaire nommé `log_accuracy_dict` est initialisé pour enregistrer les *accuracies* de chaque réseau entraîné, constituant ainsi un historique des performances des différentes architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-uT2eey8Ph0"
   },
   "outputs": [],
   "source": [
    "log_accuracy_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5eoUn_YgMaR"
   },
   "source": [
    "Avant de nous pencher sur l’étude comparative des architectures telles que *ResNet*, *MobileNet*, *ConvNeXt* et *ShuffleNet*, il est essentiel de commencer par analyser le réseau de base fourni dans l’énoncé. Cette première étape permettra de mieux comprendre la structure attendue, de poser les fondations de notre pipeline d’entraînement et d’évaluation, et de justifier les choix effectués dans la conception de nos variantes.\n",
    "\n",
    "Cette section servira également de point d’ancrage pour comparer les performances des différentes architectures que nous aborderons par la suite.\n",
    "\n",
    "# Réseau de référence fourni dans l’énoncé\n",
    "\n",
    "Dans cette section, nous analysons l’architecture minimale proposée dans l'énoncé, implémentée dans la classe `GONetDemo`. Ce modèle sert de référence de base pour les futures comparaisons. Il repose sur une pile de couches convolutionnelles simples avec activation ReLU.\n",
    "Le but étant d'offrir un socle d'expérimentation rapide, sans complexité architecturale majeure, afin de valider le pipeline RL et tester la structure `GoNet`.\n",
    "\n",
    "## Description de l’architecture\n",
    "\n",
    "```python\n",
    "class GONetDemo(GONet):\n",
    "\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    def set_backbone(self):\n",
    "        \"\"\"\n",
    "        Définit l'architecture du tronc du réseau de neurones.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.x (sortie du tronc)\n",
    "        \"\"\"\n",
    "        filters = 32\n",
    "        x = layers.Conv2D(filters, 1, activation=\"relu\", padding=\"same\")(\n",
    "            self.input_layer\n",
    "        )\n",
    "        for _ in range(5):\n",
    "            x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        self.x = x\n",
    "```\n",
    "\n",
    "Le tableau ci-dessous regroupe les Composants clefs du réseau.\n",
    "\n",
    "| Étape               | Description                                                                          |\n",
    "| ------------------- | ------------------------------------------------------------------------------------ |\n",
    "| `Conv2D(1x1)`       | Réduction ou transformation linéaire initiale des canaux.                            |\n",
    "| 5x `Conv2D(3x3)`    | Empilement de convolutions avec *padding* \"same\" pour préserver la dimension spatiale. |\n",
    "| `activation=\"relu\"` | Activation non-linéaire standard.                                                    |\n",
    "| `filters=32`        | Taille constante des cartes de caractéristiques.                                     |\n",
    "\n",
    "Il s’agit d’un réseau entièrement convolutionnel, sans *downsampling* explicite (pas de *pooling* ni *stride*), adapté à des images de petite taille ou des tâches où la précision spatiale est cruciale.\n",
    "\n",
    "> Dans les réseaux de neurones convolutionnels, plusieurs mécanismes permettent de réduire la taille spatiale (hauteur $\\times$ largeur) des cartes de caractéristiques : c'est ce qu'on appelle le **downsampling**. Cette opération est essentielle pour diminuer la complexité computationnelle, élargir le champ réceptif des neurones, et capturer des informations à plus grande échelle. Deux méthodes courantes de downsampling sont le **pooling** et l'utilisation de **convolutions avec stride**.\n",
    "> Le **pooling** consiste à résumer localement une région d'activation, par exemple en prenant la valeur maximale (**MaxPooling**) ou la moyenne (**AveragePooling**) sur une fenêtre glissante. Quant au **stride**, il représente le pas de déplacement de cette fenêtre : un `stride=1` signifie un déplacement pixel par pixel, tandis qu’un `stride=2` fait sauter un pixel à chaque étape, divisant ainsi la résolution par deux. Ces techniques jouent un rôle central dans la conception d'architectures efficaces, notamment pour extraire des représentations hiérarchiques à partir d’images.\n",
    "\n",
    "La figure ci-dessous illustre la structure du réseau de neurones associée à `GONetDemo`.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/auduvignac/deep_learning_go/refs/heads/main/figures/gonetdemo.png?token=GHSAT0AAAAAADC7QGOOSBXO3RINXSBOJWHC2ATNXDQ\" alt=\"GONet Demo\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "> La construction d’un réseau de neurones convolutionnel avec `Keras` s’appuie sur la couche `Conv2D`, qui applique des filtres sur des données 2D, comme un plateau de Go. Après les couches convolutionnelles, la couche `Flatten` convertit la grille de sorties en un vecteur unidimensionnel, prêt à être exploité par une ou plusieurs couches `Dense`, typiquement utilisées pour la classification (ex. : prédiction d’un coup) ou la régression (ex. : évaluation d’une position).\n",
    "\n",
    "\n",
    "## Intégration dans `GoNet`\n",
    "\n",
    "`GONetDemo` hérite logiquement de `GONet`, qui définit le squelette général du modèle.\n",
    "\n",
    "L’intégration consiste simplement à surcharger `set_backbone`, laissant `GONet` gérer l’assemblage complet du modèle.\n",
    "\n",
    "## Remarques relatives à la structure du réseau `GONet`\n",
    "\n",
    "* Ce réseau ne contient pas de mécanismes avancés (pas de normalisation, résidus, ni mobilisation de paramètres) ;\n",
    "* Il est utile pour tester la cohérence fonctionnelle du cadre `GONet` (entrée/sortie, apprentissage) ;\n",
    "* Il servira de *baseline* comparative vis-à-vis des architectures modernes (*ResNet*, *MobileNet*, *ConvNeXt* et *ShuffleNet*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfuVC90KRFDQ"
   },
   "outputs": [],
   "source": [
    "class GONetDemo(GONet):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"model\",\n",
    "        filters=32,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            moves=moves, N=N, planes=planes, max_params=max_params, name=name\n",
    "        )\n",
    "        self.filters = filters\n",
    "\n",
    "    def set_backbone(self):\n",
    "        \"\"\"\n",
    "        Définit l'architecture du tronc du réseau de neurones.\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            None: Affecte self.x (sortie du tronc)\n",
    "        \"\"\"\n",
    "        x = layers.Conv2D(self.filters, 1, activation=\"relu\", padding=\"same\")(\n",
    "            self.input_layer\n",
    "        )\n",
    "        for _ in range(5):\n",
    "            x = layers.Conv2D(\n",
    "                self.filters, 3, activation=\"relu\", padding=\"same\"\n",
    "            )(x)\n",
    "        self.x = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxfAJzfciM4T"
   },
   "source": [
    "## Entraînement du modèle `GONetDemo`\n",
    "\n",
    "Pour rappel, l'appel au *pipeline* d'entraînement se fait via la méthode `workflow`, qui encapsule les différentes étapes : préparation des données, entraînement, évaluation, et sauvegarde du modèle.\n",
    "\n",
    "Les paramètres et leur description associée sont décrites dans le tableau ci-dessous.\n",
    "\n",
    "| Paramètre           | Description                                             |\n",
    "| ------------------- | ------------------------------------------------------- |\n",
    "| `epochs`            | Nombre d'époques d'entraînement                         |\n",
    "| `batch`             | Taille de lot utilisée pour le gradient                 |\n",
    "| `name`              | Nom du fichier `.h5` pour la sauvegarde du modèle       |\n",
    "| `log_accuracy_dict` | Dictionnaire pour enregistrer les précisions par modèle |\n",
    "\n",
    "Le fichier qui contiendra le modèle associé à `GONetDemo` est intitulé : `gonetdemo.h5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CVZ_rb1QVelh",
    "outputId": "ba901aa3-d4d9-4497-a208-5a52c3f9ad28"
   },
   "outputs": [],
   "source": [
    "GONetDemo_instance = GONetDemo(name=\"GONetDemo\")\n",
    "\n",
    "GONetDemo_instance.workflow(batch=128, log_accuracy_dict=log_accuracy_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brDlAGlUmMeo"
   },
   "source": [
    "## Interprétation des courbes d'entraînement\n",
    "\n",
    "Analysons de manière détaillée les métriques et les courbres d'entraînement du modèle `GONetDemo`.\n",
    "\n",
    "### Évaluation des pertes\n",
    "\n",
    "La figure de gauche représente les courbes des différentes pertes :\n",
    "- *Loss* totale : mesure globale de l'erreur sur les deux sorties (*policy* + *value*).\n",
    "- *Policy loss* : erreur spécifique à la tête de *policy* (prédiction des coups).\n",
    "- *Value loss* : erreur sur la prédiction de l'issue des parties (value head).\n",
    "\n",
    "Les observations qui s'en dégagent sont les suivantes :\n",
    "\n",
    "- Les **pertes sont quasiment constantes**, avec très peu d'évolution.\n",
    "- Cela suggère que le **modèle n'apprend pas efficacement** :\n",
    "  - soit les **gradients sont faibles ou bloqués** (vanishing gradients),\n",
    "  - soit les **données ne permettent pas de progresser** (mauvais format, peu variées),\n",
    "  - soit l'architecture est trop **limitée en capacité expressive**.\n",
    "\n",
    "### Évaluation des métriques\n",
    "\n",
    "Sur la figure de droite :\n",
    "- *Policy accuracy* : mesure la capacité à prédire les bons coups ;\n",
    "- *Value MSE* : mesure l'erreur quadratique sur la prédiction de l'issue.\n",
    "\n",
    "Les observations qui s'en dégagent sont les suivantes :\n",
    "\n",
    "- La **Policy accuracy** reste très faible (~0.005 à 0.007), sans progression.\n",
    "- La **Value MSE** est stable autour de 0.12, ce qui confirme le **manque d'évolution du modèle**.\n",
    "\n",
    "### Tableau récapitulatif des métriques\n",
    "\n",
    "| Élément analysé     | Observation principale                                   |\n",
    "|---------------------|----------------------------------------------------------|\n",
    "| Loss totale         | Constante, absence d'optimisation                        |\n",
    "| Policy Loss         | Stable, aucun apprentissage apparent                     |\n",
    "| Value Loss          | Inchangée, ~0.7                                          |\n",
    "| Policy Accuracy     | Très faible, aucune amélioration                         |\n",
    "| Value MSE           | Stable (~0.12), peu d'évolution                          |\n",
    "\n",
    "### Conclusion quant au modèle `GONetDemo`\n",
    "\n",
    "Ce modèle a été conçu dans un objectif de validation d'implémentation. Bien que les performances observées restent modestes, les résultats obtenus permettent de valider le bon comportement de l'architecture et du *pipeline* d'entraînement.\n",
    "Fort de cette conclusion, l'exploration d'architectures plus puissantes peut désormais être envisagée.\n",
    "L'architecture de type *ResNet* sera étudiée en premier lieu.\n",
    "\n",
    "# ResNet\n",
    "\n",
    "Introduite pour remédier au problème d'évanescence du gradient dans les réseaux profonds, l'architecture des réseaux de neuronnes résiduels repose sur l'ajout de connexions résiduelles, permettant l'entraînement efficace de modèles plus profonds et expressifs — un atout particulièrement pertinent dans le contexte du jeu de Go.\n",
    "\n",
    "## Quelques rappels\n",
    "\n",
    "« Un réseau neuronal résiduel ou réseau de neurones résiduel est une architecture de réseaux de neurones caractérisée par l'emploi de connexions résiduelles ou connexions saute-couches.\n",
    "\n",
    "ResNet est un nom propre qui désigne le réseau neuronal résiduel qui a remporté la compétition ILSVRC en 2015.\n",
    "\n",
    "Un réseau de neurones résiduel (ResNet) est un réseau de neurones artificiels (artificial neuronal network) qui s'appuie sur des constructions connues à partir de cellules pyramidales du cortex cérébral. Pour ce faire, les réseaux de neurones résiduels utilisent des connexions saute-couches, i.e. des raccourcis, pour sauter par-dessus certaines couches. » (cf. https://datafranca.org/wiki/R%C3%A9seau_neuronal_r%C3%A9siduel).\n",
    "\n",
    "Le principe des réseaux résiduels consiste à ajouter l'entrée d'une couche à sa sortie. Grâce à cette simple modification, l'entraînement est plus rapide et permet la construction de réseaux plus profonds.\n",
    "L'utilisation des réseaux résiduels pour le Go permet d'accélérer l'apprentissage, d'augmenter la précision et de permettre l'entraînement de réseaux plus profonds (cf. https://www.lamsade.dauphine.fr/~cazenave/papers/resnet.pdf).\n",
    "\n",
    "L'implémentation du réseau de neurones résiduel implémenté s'appuie sur celle réalisée dans https://www.lamsade.dauphine.fr/~cazenave/papers/resnet.pdf.\n",
    "\n",
    "\n",
    "## Description de l'architecture\n",
    "\n",
    "L'architecture `GONetResNet` repose sur le principe fondamental des connexions résiduelles, qui permettent de faciliter l'entraînement de réseaux plus profonds.\n",
    "\n",
    "L'implémentation d'un bloc résiduel est donné ci-dessous.\n",
    "\n",
    "```python\n",
    "def residual_block(self, x):\n",
    "    filters = 32\n",
    "    conv_5x5 = layers.Conv2D(filters, 5, padding=\"same\")(x)\n",
    "    conv_1x1 = layers.Conv2D(filters, 1, padding=\"same\")(x)\n",
    "    added = layers.Add()([conv_5x5, conv_1x1])\n",
    "    return layers.Activation(\"relu\")(added)\n",
    "```\n",
    "\n",
    "Chaque bloc résiduel est constitué de deux chemins parallèles :\n",
    "- Une convolution 5 $\\times$ 5 pour extraire des caractéristiques complexes ;\n",
    "- Une convolution 1 $\\times$ 1 jouant le rôle de raccourci (skip connection) ;\n",
    "- Les deux sorties sont additionnées puis passées à une activation ReLU.\n",
    "\n",
    "La méthode `set_backbone` empile `num_blocks` blocs résiduels. Par défaut, `num_blocks` est instanciée à 1 dans le constructeur.\n",
    "\n",
    "```python\n",
    "def set_backbone(self):\n",
    "    x = self.input_layer\n",
    "    for _ in range(self.num_blocks):\n",
    "        x = self.residual_block(x)\n",
    "    self.x = x\n",
    "```\n",
    "\n",
    "> Cette implémentation reprend l'esprit de *ResNet*, bien qu'elle ne reproduise pas rigoureusement les blocs standards (pas de *BatchNormalization*, pas de projection si changement de dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DExqOv0TDc3"
   },
   "outputs": [],
   "source": [
    "class GONetResNet(GONet):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"model\",\n",
    "        num_blocks=1,\n",
    "        filters=32,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            moves=moves, N=N, planes=planes, max_params=max_params, name=name\n",
    "        )\n",
    "        self.num_blocks = num_blocks\n",
    "        self.filters = filters\n",
    "\n",
    "    def residual_block(self, x):\n",
    "        shortcut = x\n",
    "        x = layers.Conv2D(self.filters, 3, padding=\"same\")(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Conv2D(self.filters, 3, padding=\"same\")(x)\n",
    "\n",
    "        # Projection du shortcut si nécessaire\n",
    "        if shortcut.shape[-1] != x.shape[-1]:\n",
    "            shortcut = layers.Conv2D(self.filters, 1, padding=\"same\")(shortcut)\n",
    "\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        return layers.ReLU()(x)\n",
    "\n",
    "    def set_backbone(self):\n",
    "        x = self.input_layer\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.residual_block(x)\n",
    "        self.x = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2-BjWEtuJ7Q"
   },
   "source": [
    "## Entraînement du modèle `GONetResNet`\n",
    "\n",
    "Dans une démarche analogue à celle appliquée sur le réseau `GONetDemo`, l'entraînement est lancé sur 10 *epochs* avec enregistrement du modèle et suivi dans le dictionnaire `log_accuracy_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SqOr6_GUNO2i",
    "outputId": "437327a7-9b0f-4511-d0c4-ddb4c1d60bb4"
   },
   "outputs": [],
   "source": [
    "GONetResNet_instance = GONetResNet(name=\"GONetResNet_1_layer\")\n",
    "\n",
    "GONetResNet_instance.workflow(\n",
    "    batch=128,\n",
    "    log_accuracy_dict=log_accuracy_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53fSvxAjxh5d"
   },
   "source": [
    "## Interprétation des courbes d'entraînement\n",
    "\n",
    "Analysons de manière détaillée les métriques et les courbes d'entraînement du modèle `GONetResNet`.\n",
    "\n",
    "### Évolution des *losses*\n",
    "\n",
    "Le tableau ci-dessous présente les métriques associées aux *Losses* et leur interprétation respective.\n",
    "\n",
    "| Courbe          | Observation                                                                       |\n",
    "| --------------- | --------------------------------------------------------------------------------- |\n",
    "| *Loss* totale | Baisse nette constatée, indiquant une phase de convergence.           |\n",
    "| *Policy Loss* | En diminution progressive : le modèle apprend à mieux prédire les coups.          |\n",
    "| *Value Loss*  | Stable mais légèrement inférieure à celle de `GONetDemo` : valeur mieux capturée. |\n",
    "\n",
    "L'ajout d'une connexion résiduelle semble améliorer la stabilité de l'apprentissage et facilite la descente de la *loss policy*, contrairement à `GONetDemo` où les *losses* restaient quasi constantes.\n",
    "\n",
    "### Évolution des métriques\n",
    "\n",
    "Le tableau ci-dessous présente les métriques permettant de quantifier des prédictions obtenues après l'entraînement.\n",
    "\n",
    "| Courbe              | Observation                                                                                                                                                       |\n",
    "| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| *Policy Accuracy* | Amélioration progressive. Au bout de 20 *epoch* atteint 14%, résultat en nette progression par rapport à `GONetDemo` |\n",
    "| **Value MSE**       | Stable autour de 0.12 : peu de gain ici, mais pas de régression non plus.                                                                                         |\n",
    "\n",
    "Les éléments qui se dégagent de ces résultats sont les suivants :\n",
    "\n",
    "- La *Policy Accuracy* montre que le modèle est en mesure d'extraire des *patterns* pertinents ;\n",
    "- La *Value MSE* reste globalement inchangée. Ce qui suggère possiblement un manque de capacité ou du bruit dans les données de valeur.\n",
    "\n",
    "### Conclusion quant aux résultats obtenus\n",
    "\n",
    "- L'architecture `GONetResNet`, bien que simple dans sa construction (une seulles couche résiduelle), permet une *meilleure convergence* que `GONetDemo`.\n",
    "- La baisse des *losses*, notamment sur la politique, ainsi que la progression de l'*accuracy* montrent que le modèle apprend effectivement à identifier des coups probables ;\n",
    "- Ces résultats soulignent l'intérêt des connexions résiduelles dans l'entraînement de réseaux plus profonds, en particulier dans le contexte du Go où les relations spatiales complexes dominent.\n",
    "\n",
    "Ces résultats encouragent à explorer un nombre croissant de couches résiduelles (paramétrables via `num_blocks`). Il faut toutefois prendre garde à ne pas dépasser le nombre de paramètres autorisés, 100 000 en l'occurrence.\n",
    "\n",
    "## Analyse quantitative de l'augmentation du nombre de blocs résiduels sur l'efficacité du réseau\n",
    "\n",
    "La première étape consiste à identifier le nombre maximal de couches résiduelles permettant de rester en dessous du seuil de 100 000 paramètres.\n",
    "Une fois cette contrainte établie, les modèles correspondants seront entraînés, afin d'analyser dans quelle mesure l'augmentation du nombre de couches résiduelles influence les performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0T0DPw611H3f",
    "outputId": "47bb2fe9-b218-44c6-a53e-c697d9c2d4fa"
   },
   "outputs": [],
   "source": [
    "num_blocks = 1\n",
    "\n",
    "while True:\n",
    "    GONetResNet_instance = GONetResNet(num_blocks=num_blocks)\n",
    "    GONetResNet_instance.set_backbone()\n",
    "    GONetResNet_instance.set_model()\n",
    "\n",
    "    if GONetResNet_instance.nb_params > GONetResNet_instance.max_params:\n",
    "        print(\n",
    "            f\"Nombre de paramètres dépassé ({GONetResNet_instance.nb_params}).\\n\"\n",
    "            \"Nombre maximal de blocs résiduels sans dépasser 100 000 : \"\n",
    "            f\"{num_blocks - 1}\"\n",
    "        )\n",
    "        break\n",
    "    num_blocks += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M77AKj2u9MZt"
   },
   "source": [
    "Afin de respecter la contrainte de complexité ($\\leq$ 100 000 paramètres), le nombre de blocs résiduels a été limité à 3, valeur maximale avant dépassement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TYeB_KR_zNa",
    "outputId": "38d61030-5cd2-45cb-e6c3-5706410c2a4a"
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "GONetResNet_instances = []\n",
    "\n",
    "# Fonction de création + entraînement d'un modèle GONetResNet\n",
    "\n",
    "\n",
    "def run_gonetresnet(num_blocks):\n",
    "    model_name = f\"gonetresnet_{num_blocks}_blocks\"\n",
    "    print(f\"Démarrage de l'entraînement : {model_name}\")\n",
    "\n",
    "    # Création de l'instance avec un nombre variable de blocs\n",
    "    instance = GONetResNet(num_blocks=num_blocks, name=model_name)\n",
    "    instance.set_backbone()\n",
    "    instance.set_model()\n",
    "    instance.train_model(epochs=20, batch=128)  # adapte epochs si besoin\n",
    "\n",
    "    print(f\"Modèle terminé : {model_name}\")\n",
    "    return {\"num_blocks\": num_blocks, \"instance\": instance}\n",
    "\n",
    "\n",
    "# Entraînement séquentiel avec barre de progression\n",
    "for i in tqdm(range(1, 4), desc=\"Entraînement des modèles\"):\n",
    "    result = run_gonetresnet(i)\n",
    "    GONetResNet_instances.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kbYtQapIAxgz",
    "outputId": "6b00a689-b434-446e-c3c3-fbbe7036406c"
   },
   "outputs": [],
   "source": [
    "for GONetResNet_instance in GONetResNet_instances:\n",
    "    instance = GONetResNet_instance.get(\"instance\")\n",
    "    instance.plot_training_history()\n",
    "    instance.log_accuracy(results_dict=log_accuracy_dict)\n",
    "\n",
    "epochs = range(1, 21)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, inst_dict in enumerate(GONetResNet_instances):\n",
    "    instance = inst_dict.get(\"instance\")\n",
    "    if instance is not None and hasattr(instance, \"policy_acc\"):\n",
    "        plt.plot(\n",
    "            epochs, instance.policy_acc, marker=\"o\", label=f\"{instance.name}\"\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Policy Accuracy\")\n",
    "plt.title(\"Comparaison de l'accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMtwXh9AE0Nd"
   },
   "source": [
    "## Analyse comparative de l'effet du nombre de blocs résiduels\n",
    "\n",
    "### *Policy Accuracy*\n",
    "\n",
    "| Architecture        | *Accuracy* finale | Convergence |\n",
    "|---------------------|-------------------|-------------|\n",
    "| 1 bloc résiduel     | ~0.133            | Lente       |\n",
    "| 2 blocs résiduels   | ~0.206            | Rapide      |\n",
    "| 3 blocs résiduels   | ~0.210            | Très rapide |\n",
    "\n",
    "- Le passage de 1 à 2 blocs apporte un gain significatif en *accuracy* et en vitesse d'apprentissage ;\n",
    "- Le passage de 2 à 3 blocs ne procure qu'un gain marginal ;\n",
    "- À partir de 2 blocs, l'amélioration de la policy accuracy sature.\n",
    "\n",
    "### *Losses* et *Value MSE*\n",
    "\n",
    "- *Policy loss* diminue régulièrement pour les 3 modèles, plus efficacement à partir de 2 blocs ;\n",
    "- *Value loss* et *Value MSE* restent stables et peu sensibles à l'augmentation de la profondeur, autour de ~0.12-0.13.\n",
    "- Cela suggère une difficulté à optimiser la valeur indépendamment de la complexité du réseau.\n",
    "\n",
    "### Conclusion quant à l'analyse quantitative du nombre croissant de couches résiduelles\n",
    "\n",
    "Le modèle à deux blocs résiduels apparaît comme le meilleur compromis :\n",
    "- Excellente *accuracy* atteinte rapidement ;\n",
    "- Complexité contrôlée (moins de surcoût que 3 blocs) ;\n",
    "- Pas de gain notable à utiliser un troisème bloc.\n",
    "\n",
    "Le modèle à deux blocs résiduels constitue donc un compromis optimal, alliant expressivité et stabilité, sans dépasser les contraintes fixées.\n",
    "\n",
    "Cette étude a mis en exergue que l'ajout de blocs résiduels améliore significativement la performance des réseaux de neurones convolutifs, jusqu'à un certain point. Toutefois, cette amélioration s'accompagne d'une augmentation du nombre de paramètres, du temps d'entraînement et de la consommation mémoire.\n",
    "\n",
    "Dans une optique d'optimisation du rapport performance et d'efficacité, il devient pertinent de se tourner vers des architectures plus légères et efficaces.\n",
    "\n",
    "C'est dans ce contexte que s'inscrit *MobileNet*, une architecture conçue pour offrir une bonne précision tout en réduisant fortement la complexité computationnelle, grâce à l'utilisation de **convolutions séparables en profondeur**.\n",
    "\n",
    "La prochaine étape consiste à étudier cette architecture et la comparer avec les architectures étudiées jusqu'à présent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZZFelI_ZTf-"
   },
   "source": [
    "# MobileNet\n",
    "\n",
    "Les réseaux *MobileNet* sont couramment utilisés en vision par ordinateur pour classer des images. Ils atteignent une haute précision sur les jeux de données standards tout en conservant un nombre de paramètres inférieur à celui d'autres architectures de réseaux neuronaux.\n",
    "\n",
    "Etudions cette architecture sur le jeu de données fourni.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWsv61b6ZVmi"
   },
   "outputs": [],
   "source": [
    "class GONetMobileNet(GONet):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"model\",\n",
    "        num_blocks=1,\n",
    "        trunk=32,\n",
    "        filters=32,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            moves=moves, N=N, planes=planes, max_params=max_params, name=name\n",
    "        )\n",
    "        self.num_blocks = num_blocks\n",
    "        self.trunk = trunk\n",
    "        self.filters = filters\n",
    "\n",
    "    def bottleneck_block(self, x):\n",
    "        m = layers.Conv2D(\n",
    "            self.filters,\n",
    "            (1, 1),\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "            use_bias=False,\n",
    "        )(x)\n",
    "        m = layers.BatchNormalization()(m)\n",
    "        m = layers.Activation(\"relu\")(m)\n",
    "        m = layers.DepthwiseConv2D(\n",
    "            (3, 3),\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "            use_bias=False,\n",
    "        )(m)\n",
    "        m = layers.BatchNormalization()(m)\n",
    "        m = layers.Activation(\"relu\")(m)\n",
    "        m = layers.Conv2D(\n",
    "            self.trunk,\n",
    "            (1, 1),\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "            use_bias=False,\n",
    "        )(m)\n",
    "        m = layers.BatchNormalization()(m)\n",
    "        return layers.Add()([m, x])\n",
    "\n",
    "    def set_backbone(self):\n",
    "        x = self.input_layer\n",
    "        x = layers.Conv2D(\n",
    "            self.trunk,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.bottleneck_block(x)\n",
    "        self.x = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "Y12L-_Ux8u3U",
    "outputId": "d50e1534-a919-4b95-f2fb-81fbf63f268b"
   },
   "outputs": [],
   "source": [
    "GONetMobileNet_instance = GONetMobileNet(name=\"GONetMobileNet\")\n",
    "GONetMobileNet_instance.set_backbone()\n",
    "GONetMobileNet_instance.set_model()\n",
    "GONetMobileNet_instance.save_model(\"GONetMobileNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TEiYb92AazTT",
    "outputId": "a1f2c394-4498-4a8a-8bed-b32294f5f412"
   },
   "outputs": [],
   "source": [
    "GONetMobileNet_instance = GONetMobileNet(name=\"GONetMobileNet\")\n",
    "GONetMobileNet_instance.workflow(\n",
    "    batch=128,\n",
    "    log_accuracy_dict=log_accuracy_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVy7K9ftdDnN",
    "outputId": "20b3966b-fd68-422f-b1e9-7cbe4c7dc2c5"
   },
   "outputs": [],
   "source": [
    "num_blocks = 1\n",
    "\n",
    "while True:\n",
    "    GONetMobileNet_instance = GONetMobileNet(num_blocks=num_blocks)\n",
    "    GONetMobileNet_instance.set_backbone()\n",
    "    GONetMobileNet_instance.set_model()\n",
    "\n",
    "    if GONetMobileNet_instance.nb_params > GONetMobileNet_instance.max_params:\n",
    "        print(\n",
    "            f\"Nombre de paramètres dépassé ({GONetMobileNet_instance.nb_params}).\\n\"\n",
    "            \"Nombre maximal de blocs résiduels sans dépasser 100 000 : \"\n",
    "            f\"{num_blocks - 1}\"\n",
    "        )\n",
    "        break\n",
    "    num_blocks += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0BHCrhZCgxz",
    "outputId": "59e5ffbf-f43a-4e29-ecd9-372b34f8eb69"
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "GONetMobileNet_instances = []\n",
    "\n",
    "# Fonction de création + entraînement d'un modèle GONetResNet\n",
    "\n",
    "\n",
    "def run_gomobilenet(num_blocks):\n",
    "    model_name = f\"gomobilenet_{num_blocks}_blocks\"\n",
    "    print(f\"Démarrage de l'entraînement : {model_name}\")\n",
    "\n",
    "    # Création de l'instance avec un nombre variable de blocs\n",
    "    instance = GONetMobileNet(num_blocks=num_blocks, name=model_name)\n",
    "    instance.set_backbone()\n",
    "    instance.set_model()\n",
    "    instance.train_model(epochs=20, batch=128)\n",
    "\n",
    "    print(f\"Modèle terminé : {model_name}\")\n",
    "    return {\"num_blocks\": num_blocks, \"instance\": instance}\n",
    "\n",
    "\n",
    "# Entraînement séquentiel avec barre de progression\n",
    "for i in tqdm(range(1, 29), desc=\"Entraînement des modèles\"):\n",
    "    result = run_gomobilenet(i)\n",
    "    GONetMobileNet_instances.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4zuaV8jSelf"
   },
   "outputs": [],
   "source": [
    "def plot_metric(instances, attribute, ylabel, title, epochs=range(1, 21)):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for inst_dict in instances:\n",
    "        instance = inst_dict.get(\"instance\")\n",
    "        if instance is not None and hasattr(instance, attribute):\n",
    "            plt.plot(\n",
    "                epochs,\n",
    "                getattr(instance, attribute),\n",
    "                marker=\"o\",\n",
    "                label=f\"{instance.name}\",\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.legend(\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc=\"upper left\",\n",
    "        borderaxespad=0.0,\n",
    "        fontsize=\"small\",\n",
    "        title=\"Modèles\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.75, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sSctdrh9TBIf",
    "outputId": "5cefff40-0f53-46bf-d23f-1ef9d112c781"
   },
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    GONetMobileNet_instances,\n",
    "    \"policy_acc\",\n",
    "    \"Policy Accuracy\",\n",
    "    \"Comparaison de l'accuracy\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetMobileNet_instances,\n",
    "    \"loss_total\",\n",
    "    \"Loss totale\",\n",
    "    \"Comparaison de la loss totale\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetMobileNet_instances,\n",
    "    \"policy_loss\",\n",
    "    \"Policy Loss\",\n",
    "    \"Comparaison de la policy loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetMobileNet_instances,\n",
    "    \"value_loss\",\n",
    "    \"Value Loss\",\n",
    "    \"Comparaison de la value loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetMobileNet_instances, \"value_mse\", \"Value MSE\", \"Comparaison du MSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2nDizQlQOMN"
   },
   "outputs": [],
   "source": [
    "def extract_final_metrics(instances, metric_names):\n",
    "    metrics_data = []\n",
    "\n",
    "    for inst_dict in instances:\n",
    "        instance = inst_dict.get(\"instance\")\n",
    "        if instance is not None:\n",
    "            row = {\n",
    "                \"name\": instance.name,\n",
    "                \"num_blocks\": inst_dict.get(\"num_blocks\"),\n",
    "            }\n",
    "            for metric in metric_names:\n",
    "                values = getattr(instance, metric, None)\n",
    "                if values:\n",
    "                    row[f\"final_{metric}\"] = values[-1]\n",
    "            metrics_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(metrics_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P03P_p8AmZGv"
   },
   "outputs": [],
   "source": [
    "# Liste des métriques à extraire\n",
    "metric_list = [\n",
    "    \"loss_total\",\n",
    "    \"policy_loss\",\n",
    "    \"value_loss\",\n",
    "    \"policy_acc\",\n",
    "    \"value_mse\",\n",
    "]\n",
    "\n",
    "# Création du DataFrame\n",
    "df_metrics = extract_final_metrics(GONetMobileNet_instances, metric_list)\n",
    "\n",
    "# Tri par la métrique de précision\n",
    "df_metrics = df_metrics.sort_values(\n",
    "    by=\"final_policy_acc\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "display(df_metrics.style.format(precision=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kycHtjG2WDa_"
   },
   "source": [
    "## Interprétation des résultats obtenus\n",
    "\n",
    "L'analyse porte sur les performances de 28 modèles `GONetMobileNet` variant par le nombre de blocs (de 1 à 28). Les métriques principales évaluées sont les pertes (*losses*) et les performances (métriques) des têtes `policy` et `value`. Les observations suivantes synthétisent le comportement global observé durant l'entraînement.\n",
    "\n",
    "### Évolution des losses\n",
    "\n",
    "- *Policy Loss* : elle décroît de manière régulière au fil des époques pour toutes les architectures, indiquant un apprentissage progressif de la politique.\n",
    "- **Value Loss** : elle diminue initialement, puis stagne autour de **0.70** à partir de **5 epochs**, quel que soit le nombre de blocs ;\n",
    "- *Loss totale* : la courbe suit globalement la même tendance que la somme des deux pertes précédentes, avec une décroissance initiale avant stabilisation.\n",
    "\n",
    "### Évolution des métriques\n",
    "\n",
    "- *Policy Accuracy* : la précision augmente légèrement au début mais reste modeste dans l'ensemble. Elle atteint son maximum (0.2455) avec **5 blocs**, puis décline lentement avec l'augmentation de la profondeur ;\n",
    "- *Value MSE* : une diminution progressive est observée sur les premières époques, pour ensuite stagner autour de **0.12**, sans amélioration significative liée à la profondeur.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Les **meilleures performances globales** sont obtenues avec des architectures comprenant **entre 4 et 6 blocs**. En s'appuyant exclusivement sur l'*accurracy* le meilleur se trouve être celui comprenant **5 blocs** ;\n",
    "- L'**augmentation du nombre de blocs** au-delà de ce seuil n'apporte **aucun bénéfice clair**, ni sur les pertes ni sur les métriques, et tend même à les dégrader ;\n",
    "- Le **MSE et la value loss stagnants** indiquent que la tête `value` reste limitée, probablement du fait de la nature simulée des données ;\n",
    "\n",
    "Après avoir exploré l'architecture MobileNet avec différentes profondeurs, il est pertinent d'élargir la comparaison à des modèles plus récents et puissants.\n",
    "\n",
    "Parmi ceux-ci, *ConvNeXt* s'impose comme une évolution majeure des réseaux convolutifs classiques. Inspiré des meilleures pratiques des Transformers, *ConvNeXt* revisite la conception des réseaux de neurones de convolution pour les rendre plus compétitifs sur les tâches de vision.\n",
    "\n",
    "Nous allons désormais explorer cette architecture, en l'adaptant à notre classe `GoNet`, et en comparant ses performances aux réseaux précédemment étudiés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xry75ar2YmPi"
   },
   "source": [
    "# ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zONJ8KUXYVYG"
   },
   "outputs": [],
   "source": [
    "class GONetConvNeXtLike(GONet):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"model\",\n",
    "        num_blocks=1,\n",
    "        trunk=96,\n",
    "        filters=48,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            moves=moves, N=N, planes=planes, max_params=max_params, name=name\n",
    "        )\n",
    "        self.num_blocks = num_blocks  # nombre de blocs ConvNeXt\n",
    "        self.trunk = trunk  # profondeur / projection initiale\n",
    "        self.filters = filters  # nombre de filtres dans les blocs\n",
    "\n",
    "    def set_backbone(self):\n",
    "        \"\"\"\n",
    "        Définit un tronc ConvNeXt-like basé sur des blocs V1.\n",
    "\n",
    "        Architecture :\n",
    "        - Projection initiale vers 'filters' canaux\n",
    "        - Répétition de 'num_blocks' blocs ConvNeXt\n",
    "        - Réduction finale à 32 canaux pour compatibilité avec les têtes\n",
    "        \"\"\"\n",
    "        x = self.input_layer\n",
    "\n",
    "        # Projection initiale (31 → filters canaux)\n",
    "        x = layers.Conv2D(self.filters, kernel_size=1, padding=\"same\")(x)\n",
    "\n",
    "        for _ in range(self.num_blocks):\n",
    "            residual = x\n",
    "            x1 = layers.DepthwiseConv2D(\n",
    "                kernel_size=7, padding=\"same\", use_bias=False\n",
    "            )(x)\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(x1)\n",
    "            x1 = layers.Conv2D(\n",
    "                4 * self.filters,\n",
    "                kernel_size=1,\n",
    "                activation=\"gelu\",\n",
    "                padding=\"same\",\n",
    "            )(x1)\n",
    "            x1 = layers.Conv2D(self.filters, kernel_size=1, padding=\"same\")(x1)\n",
    "            x = layers.Add()([x, x1])\n",
    "            x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Réduction finale à 32 canaux pour create_policy_value_heads\n",
    "        x = layers.Conv2D(32, kernel_size=1, padding=\"same\", use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "        self.x = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RD4A-knxYxSC",
    "outputId": "419ed765-cda1-4ddf-fea2-03c8157a9500"
   },
   "outputs": [],
   "source": [
    "GONetConvNeXtLike_instance = GONetConvNeXtLike(name=\"GONetConvNeXtLike\")\n",
    "GONetConvNeXtLike_instance.workflow(\n",
    "    batch=128,\n",
    "    log_accuracy_dict=log_accuracy_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0udJQSZ0j_fl",
    "outputId": "b70c9f17-58f8-46bf-ae2b-c1b82157ca9e"
   },
   "outputs": [],
   "source": [
    "num_blocks = 1\n",
    "\n",
    "while True:\n",
    "    GONetConvNeXtLike_instance = GONetConvNeXtLike(num_blocks=num_blocks)\n",
    "    GONetConvNeXtLike_instance.set_backbone()\n",
    "    GONetConvNeXtLike_instance.set_model()\n",
    "\n",
    "    if (\n",
    "        GONetConvNeXtLike_instance.nb_params\n",
    "        > GONetConvNeXtLike_instance.max_params\n",
    "    ):\n",
    "        print(\n",
    "            f\"Nombre de paramètres dépassé ({GONetConvNeXtLike_instance.nb_params}).\\n\"\n",
    "            \"Nombre maximal de blocs résiduels sans dépasser 100 000 : \"\n",
    "            f\"{num_blocks - 1}\"\n",
    "        )\n",
    "        break\n",
    "    num_blocks += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiE1QUp7kTsP",
    "outputId": "c773bca3-913a-4df0-f1c6-8f50bccb2e5a"
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "GONetConvNeXtLike_instances = []\n",
    "\n",
    "# Fonction de création + entraînement d'un modèle GONetResNet\n",
    "\n",
    "\n",
    "def run_goconvnextlike(num_blocks):\n",
    "    model_name = f\"goconvnextlike_{num_blocks}_blocks\"\n",
    "    print(f\"Démarrage de l'entraînement : {model_name}\")\n",
    "\n",
    "    # Création de l'instance avec un nombre variable de blocs\n",
    "    instance = GONetConvNeXtLike(num_blocks=num_blocks, name=model_name)\n",
    "    instance.set_backbone()\n",
    "    instance.set_model()\n",
    "    instance.train_model(epochs=20, batch=128)\n",
    "\n",
    "    print(f\"Modèle terminé : {model_name}\")\n",
    "    return {\"num_blocks\": num_blocks, \"instance\": instance}\n",
    "\n",
    "\n",
    "# Entraînement séquentiel avec barre de progression\n",
    "for i in tqdm(range(1, 4), desc=\"Entraînement des modèles\"):\n",
    "    result = run_goconvnextlike(i)\n",
    "    GONetConvNeXtLike_instances.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1SiZJ8G3lAHl",
    "outputId": "5b5d169b-8fa8-490e-ec03-493a25f9fc59"
   },
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    GONetConvNeXtLike_instances,\n",
    "    \"policy_acc\",\n",
    "    \"Policy Accuracy\",\n",
    "    \"Comparaison de l'accuracy\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetConvNeXtLike_instances,\n",
    "    \"loss_total\",\n",
    "    \"Loss totale\",\n",
    "    \"Comparaison de la loss totale\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetConvNeXtLike_instances,\n",
    "    \"policy_loss\",\n",
    "    \"Policy Loss\",\n",
    "    \"Comparaison de la policy loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetConvNeXtLike_instances,\n",
    "    \"value_loss\",\n",
    "    \"Value Loss\",\n",
    "    \"Comparaison de la value loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetConvNeXtLike_instances, \"value_mse\", \"Value MSE\", \"Comparaison du MSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Hjxj2cONmdYZ",
    "outputId": "f51c7a03-5963-4a63-b8fd-9cabdfeacac1"
   },
   "outputs": [],
   "source": [
    "# Liste des métriques à extraire\n",
    "metric_list = [\n",
    "    \"loss_total\",\n",
    "    \"policy_loss\",\n",
    "    \"value_loss\",\n",
    "    \"policy_acc\",\n",
    "    \"value_mse\",\n",
    "]\n",
    "\n",
    "# Création du DataFrame\n",
    "df_metrics = extract_final_metrics(GONetConvNeXtLike_instances, metric_list)\n",
    "\n",
    "# Tri par la métrique de précision\n",
    "df_metrics = df_metrics.sort_values(\n",
    "    by=\"final_policy_acc\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "display(df_metrics.style.format(precision=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrl-r0U-olta"
   },
   "source": [
    "# ShuffleNet\n",
    "\n",
    "*ShuffleNet* est une architecture de réseau neuronal conçue pour être rapide et efficace. Elle repose sur le concept de permutation des canaux du tenseur d'entrée, ce qui améliore l'efficacité en termes de calcul et d'utilisation de la mémoire.\n",
    "\n",
    "Le réseau se compose de deux principales parties :\n",
    "\n",
    "1.  Couche de convolution : Cette couche a pour rôle d'extraire les caractéristiques du tenseur d'entrée.\n",
    "\n",
    "2.  Couche de permutation (*shuffling*) : Cette couche permutent les canaux du tenseur d'entrée. Elle est conçue pour être légère et efficace, ce qui contribue fortement à la performance globale et à l'efficacité du réseau\n",
    "\n",
    "*Shufflenet* est un mobilenet avec moins de paramètres puisqu'il y a des plans séparés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47HUthpQqFbx"
   },
   "outputs": [],
   "source": [
    "class GONetShuffleNet(GONet):\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"gonet_shufflenet\",\n",
    "        num_blocks=1,\n",
    "        trunk=32,\n",
    "        filters=32,\n",
    "        shuffle_groups=4,\n",
    "    ):\n",
    "        super().__init__(moves, N, planes, max_params, name)\n",
    "        self.num_blocks = num_blocks\n",
    "        self.trunk = trunk\n",
    "        self.filters = filters\n",
    "        self.shuffle_groups = shuffle_groups\n",
    "\n",
    "    def set_backbone(self):\n",
    "        x = Conv2D(\n",
    "            self.trunk,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "        )(self.input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.bottleneck_block(\n",
    "                x, expand=self.filters * 3, squeeze=self.trunk\n",
    "            )\n",
    "\n",
    "        self.x = x\n",
    "\n",
    "    def bottleneck_block(self, x, expand, squeeze):\n",
    "        residual = x\n",
    "        x = self.gconv(x, channels=expand, shuffle_groups=self.shuffle_groups)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = self.channel_shuffle(x, self.shuffle_groups)\n",
    "        x = DepthwiseConv2D(kernel_size=3, padding=\"same\", use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = self.gconv(x, channels=squeeze, shuffle_groups=self.shuffle_groups)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([residual, x])\n",
    "        return ReLU()(x)\n",
    "\n",
    "    def gconv(self, x, channels, shuffle_groups):\n",
    "        input_ch = x.shape[-1]\n",
    "        group_ch = input_ch // shuffle_groups\n",
    "        out_ch = channels // shuffle_groups\n",
    "        group_outputs = []\n",
    "        for i in range(shuffle_groups):\n",
    "            slice_x = x[:, :, :, i * group_ch : (i + 1) * group_ch]\n",
    "            conv = Conv2D(out_ch, kernel_size=1, use_bias=False)(slice_x)\n",
    "            group_outputs.append(conv)\n",
    "        return Concatenate(axis=-1)(group_outputs)\n",
    "\n",
    "    def channel_shuffle(self, x, shuffle_groups):\n",
    "        \"\"\"\n",
    "        Applique l'opération de channel shuffle.\n",
    "        Args:\n",
    "            x: Tensor de forme [batch_size, height, width, channels]\n",
    "            shuffle_groups: Nombre de groupes à créer\n",
    "        Returns:\n",
    "            Tensor après permutation des canaux entre les groupes\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        height = tf.shape(x)[1]\n",
    "        width = tf.shape(x)[2]\n",
    "        channels = tf.shape(x)[3]\n",
    "\n",
    "        # Vérification statique de la divisibilité\n",
    "        if x.shape[-1] is not None and x.shape[-1] % shuffle_groups != 0:\n",
    "            raise ValueError(\n",
    "                \"Le nombre de canaux doit être divisible par le nombre de groupes pour le channel shuffle.\"\n",
    "            )\n",
    "\n",
    "        group_channels = channels // shuffle_groups\n",
    "\n",
    "        # Reshape pour grouper les canaux\n",
    "        x = tf.reshape(\n",
    "            x, [batch_size, height, width, shuffle_groups, group_channels]\n",
    "        )\n",
    "\n",
    "        # Permutation des groupes et des canaux\n",
    "        x = tf.transpose(\n",
    "            x, [0, 1, 2, 4, 3]\n",
    "        )  # (batch, height, width, group_channels, groups)\n",
    "\n",
    "        # Flatten à nouveau en (batch, height, width, channels)\n",
    "        x = tf.reshape(x, [batch_size, height, width, channels])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "R_f-mZBOtI5G",
    "outputId": "3b8e3a07-db08-4292-df0a-9bcbc4a7b611"
   },
   "outputs": [],
   "source": [
    "GONetShuffleNet_instance = GONetShuffleNet(name=\"GONetShuffleNet\")\n",
    "GONetShuffleNet_instance.workflow(\n",
    "    batch=128,\n",
    "    log_accuracy_dict=log_accuracy_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWM2xKRj7lMH",
    "outputId": "cc1dbbad-5a7e-411e-baa8-b6a57063e921"
   },
   "outputs": [],
   "source": [
    "num_blocks = 1\n",
    "\n",
    "while True:\n",
    "    GONetShuffleNet_instance = GONetShuffleNet(num_blocks=num_blocks)\n",
    "    GONetShuffleNet_instance.set_backbone()\n",
    "    GONetShuffleNet_instance.set_model()\n",
    "\n",
    "    if (\n",
    "        GONetShuffleNet_instance.nb_params\n",
    "        > GONetShuffleNet_instance.max_params\n",
    "    ):\n",
    "        print(\n",
    "            f\"Nombre de paramètres dépassé ({GONetShuffleNet_instance.nb_params}).\\n\"\n",
    "            \"Nombre maximal de blocs résiduels sans dépasser 100 000 : \"\n",
    "            f\"{num_blocks - 1}\"\n",
    "        )\n",
    "        break\n",
    "    num_blocks += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhJ75RSB9Yyy",
    "outputId": "640a4969-01ba-437b-e54b-53b707311b35"
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "GONetShuffleNet_instances = []\n",
    "\n",
    "\n",
    "def run_goshufflenet(num_blocks):\n",
    "    model_name = f\"goshufflenet_{num_blocks}_blocks\"\n",
    "    print(f\"Démarrage de l'entraînement : {model_name}\")\n",
    "\n",
    "    # Création de l'instance avec un nombre variable de blocs\n",
    "    instance = GONetShuffleNet(num_blocks=num_blocks, name=model_name)\n",
    "    instance.set_backbone()\n",
    "    instance.set_model()\n",
    "    instance.train_model(epochs=20, batch=128)\n",
    "\n",
    "    print(f\"Modèle terminé : {model_name}\")\n",
    "    return {\"num_blocks\": num_blocks, \"instance\": instance}\n",
    "\n",
    "\n",
    "# Entraînement séquentiel avec barre de progression\n",
    "for i in tqdm(range(1, 25), desc=\"Entraînement des modèles\"):\n",
    "    result = run_goshufflenet(i)\n",
    "    GONetShuffleNet_instances.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v8AUZ1wwLf1n",
    "outputId": "8fd9df4c-c9c4-464d-d0b2-6fbbd5c4c776"
   },
   "outputs": [],
   "source": [
    "plot_metric(\n",
    "    GONetShuffleNet_instances,\n",
    "    \"policy_acc\",\n",
    "    \"Policy Accuracy\",\n",
    "    \"Comparaison de l'accuracy\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetShuffleNet_instances,\n",
    "    \"loss_total\",\n",
    "    \"Loss totale\",\n",
    "    \"Comparaison de la loss totale\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetShuffleNet_instances,\n",
    "    \"policy_loss\",\n",
    "    \"Policy Loss\",\n",
    "    \"Comparaison de la policy loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetShuffleNet_instances,\n",
    "    \"value_loss\",\n",
    "    \"Value Loss\",\n",
    "    \"Comparaison de la value loss\",\n",
    ")\n",
    "plot_metric(\n",
    "    GONetShuffleNet_instances, \"value_mse\", \"Value MSE\", \"Comparaison du MSE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "Q-yd_4DbPzCn",
    "outputId": "f6ad57f7-0f5d-4bf9-9897-c7bac4e35a31"
   },
   "outputs": [],
   "source": [
    "# Liste des métriques à extraire\n",
    "metric_list = [\n",
    "    \"loss_total\",\n",
    "    \"policy_loss\",\n",
    "    \"value_loss\",\n",
    "    \"policy_acc\",\n",
    "    \"value_mse\",\n",
    "]\n",
    "\n",
    "# Création du DataFrame\n",
    "df_metrics = extract_final_metrics(GONetShuffleNet_instances, metric_list)\n",
    "\n",
    "# Tri par la métrique de précision\n",
    "df_metrics = df_metrics.sort_values(\n",
    "    by=\"final_policy_acc\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "display(df_metrics.style.format(precision=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz4rVMLvE03_"
   },
   "source": [
    "# Convolutions en croix (*Cross-Shaped Convolutions*)\n",
    "\n",
    "L'objectif de cette section est d'explorer une architecture basée sur les convolutions en croix. Pour cela, nous allons nous appuyer sur la classe : `GONetCrossLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXx8conyE-W6"
   },
   "outputs": [],
   "source": [
    "class GONetCrossLayer(GONet):\n",
    "    def __init__(\n",
    "        self,\n",
    "        moves=361,\n",
    "        N=10000,\n",
    "        planes=31,\n",
    "        max_params=100000,\n",
    "        name=\"gonet_crosslayer\",\n",
    "        filters=16,\n",
    "    ):\n",
    "        super().__init__(moves, N, planes, max_params, name)\n",
    "        self.filters = filters\n",
    "\n",
    "    def set_backbone(self):\n",
    "        # Branche gauche\n",
    "        left = layers.Conv2D(\n",
    "            32, 7, padding=\"same\", kernel_regularizer=regularizers.l2(0.0001)\n",
    "        )(self.input_layer)\n",
    "        left = layers.BatchNormalization()(left)\n",
    "        left = layers.ReLU()(left)\n",
    "\n",
    "        left = layers.Conv2D(\n",
    "            8, 1, padding=\"same\", kernel_regularizer=regularizers.l2(0.0001)\n",
    "        )(left)\n",
    "        left = layers.BatchNormalization()(left)\n",
    "        left = layers.ReLU()(left)\n",
    "\n",
    "        left = self.cross_layer(left, width=1, filters=8)\n",
    "\n",
    "        left = layers.Conv2D(\n",
    "            32, 1, padding=\"same\", kernel_regularizer=regularizers.l2(0.0001)\n",
    "        )(left)\n",
    "\n",
    "        # Branche droite\n",
    "        right = layers.Conv2D(\n",
    "            8, 1, padding=\"same\", kernel_regularizer=regularizers.l2(0.0001)\n",
    "        )(self.input_layer)\n",
    "        right = layers.BatchNormalization()(right)\n",
    "        right = layers.ReLU()(right)\n",
    "\n",
    "        right = self.cross_layer(right, width=5, filters=8)\n",
    "\n",
    "        right = layers.Conv2D(\n",
    "            32, 1, padding=\"same\", kernel_regularizer=regularizers.l2(0.0001)\n",
    "        )(right)\n",
    "\n",
    "        # Fusion\n",
    "        x = layers.Add()([left, right])\n",
    "        x = layers.ReLU()(x)\n",
    "\n",
    "        self.x = x\n",
    "\n",
    "    def cross_layer(self, x, width=1, filters=16):\n",
    "        \"\"\"\n",
    "        Implémente une couche convolutive \"en croix\" via deux convolutions séparables :\n",
    "        - verticale : (k, 1)\n",
    "        - horizontale : (1, k)\n",
    "        \"\"\"\n",
    "        vertical = layers.Conv2D(\n",
    "            filters, (width, 1), padding=\"same\", activation=\"relu\"\n",
    "        )(x)\n",
    "        horizontal = layers.Conv2D(\n",
    "            filters, (1, width), padding=\"same\", activation=\"relu\"\n",
    "        )(x)\n",
    "        return layers.Add()([vertical, horizontal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "7PF6uk7wrzKA",
    "outputId": "826869c0-2080-471f-cbff-a33ff5af1c03"
   },
   "outputs": [],
   "source": [
    "GONetCrossLayer_instance = GONetCrossLayer(name=\"GONetCrossLayer\")\n",
    "GONetCrossLayer_instance.set_backbone()\n",
    "GONetCrossLayer_instance.set_model()\n",
    "GONetCrossLayer_instance.save_model(\"GONetCrossLayer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "id": "nQqO9GE3QAtK",
    "outputId": "954ffc45-b7fa-4452-abc1-9dd7b29de1c7"
   },
   "outputs": [],
   "source": [
    "GONetCrossLayer_instance = GONetCrossLayer(name=\"GONetCrossLayer\")\n",
    "GONetCrossLayer_instance.workflow(\n",
    "    batch=128,\n",
    "    log_accuracy_dict=log_accuracy_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cours des 20 époques d'entraînement, la loss totale du modèle `GONetCrossLayer` a diminué de manière continue, passant d'environ 6.5 à une valeur finale de 4.2796. Cette tendance indique une amélioration générale de l'optimisation du modèle. En parallèle, la loss value est restée stable autour de 0.69, avec une valeur finale de 0.6927, traduisant une difficulté persistante à améliorer cette composante durant l'apprentissage.\n",
    "\n",
    "La policy loss, en revanche, a nettement baissé, passant de près de 5.9 à 3.5690, signalant une progression efficace sur cet aspect du modèle. Cette dynamique est cohérente avec l'évolution de la MSE, qui reste relativement constant et atteint 0.1210 en fin d'entraînement, confirmant l'absence d'amélioration notable sur la tête de valeur.\n",
    "\n",
    "Enfin, la précision catégorielle de la politique a montré une nette progression, atteignant 0.2162 après un départ très faible. Cela reflète une capacité croissante du modèle à reproduire fidèlement les coups issus des données d'entraînement, et met en évidence la solidité de l'architecture GONetCrossLayer pour l'apprentissage de la politique.\n",
    "\n",
    "Sur la base des différents résultats obtenus, abordons l'étude des meilleurs architectures en augmentant le nombre d'époques.\n",
    "\n",
    "# Choix du modèle final\n",
    "\n",
    "Le tableau suivant regroupe l'accuracy des meilleurs modèles retenues entraînés sur 50 époques.\n",
    "\n",
    "| Architecture                    | Accuracy finale (%) |\n",
    "|--------------------------------|---------------------|\n",
    "| GONetShuffleNet_4_blocs        | 27.85               |\n",
    "| GONetConvNeXtLike_2_blocs      | 27.65               |\n",
    "| GONetMobileNet_5_blocs         | 27.51               |\n",
    "| GONetResNet_3_blocs            | 26.83               |\n",
    "| GONetCrossLayer                | 26.17               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBhSh7Z37OOD",
    "outputId": "a79085ed-90d0-434a-d961-3311d97444f3"
   },
   "outputs": [],
   "source": [
    "# Définition des meilleures architectures à entraîner\n",
    "instances = [\n",
    "    GONetResNet(num_blocks=3, name=\"GONetResNet_3_blocs\"),\n",
    "    GONetMobileNet(num_blocks=5, name=\"GONetMobileNet_5_blocs\"),\n",
    "    GONetConvNeXtLike(num_blocks=2, name=\"GONetConvNeXtLike_2_blocs\"),\n",
    "    GONetShuffleNet(num_blocks=4, name=\"GONetShuffleNet_4_blocs\"),\n",
    "    GONetCrossLayer(name=\"GONetCrossLayer\"),\n",
    "]\n",
    "epochs = 50\n",
    "batch = 128\n",
    "\n",
    "# Boucle d'entraînement pour chaque architecture\n",
    "for model in instances:\n",
    "    print(f\"Initialisation : {model.name}\")\n",
    "    model.set_backbone()\n",
    "    model.set_model()\n",
    "    print(f\"Entraînement : {model.name}\")\n",
    "    model.train_model(epochs=epochs, batch=batch)\n",
    "    print(f\"Terminé : {model.name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons également l'évolution de l'accuracy pour les cinq architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "rKaDlT0XA50Q",
    "outputId": "a0bf2b6e-0114-4e69-b01e-4c7fcfb366c1"
   },
   "outputs": [],
   "source": [
    "# Crée un graphique pour toutes les courbes de policy_acc\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Parcours de chaque instance\n",
    "for model in instances:\n",
    "    if hasattr(model, \"policy_acc\"):\n",
    "        plt.plot(model.policy_acc, label=model.name)\n",
    "    else:\n",
    "        print(f\"L'attribut 'policy_acc' est manquant pour : {model.name}\")\n",
    "\n",
    "# Mise en forme du graphique\n",
    "plt.title(\"Évolution de la Policy Accuracy par architecture\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Policy Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, entraînons le meilleur modèle : `GONetShuffleNet_4_blocs` sur 100 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lXfGy9ZKGWGS",
    "outputId": "50f40036-f7f1-47df-888c-81a69574e6f9"
   },
   "outputs": [],
   "source": [
    "instance_finale = GONetShuffleNet(\n",
    "    num_blocks=4, name=\"GONetShuffleNet_4_blocs_final\"\n",
    ")\n",
    "instance_finale.workflow(epochs=100, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "Xw1EWfziIljg",
    "outputId": "348f00ee-5ed2-4892-a4a5-5abf611f9e3b"
   },
   "outputs": [],
   "source": [
    "# Vérification et tracé de l'accuracy\n",
    "if hasattr(instance_finale, \"policy_acc\"):\n",
    "    acc = instance_finale.policy_acc\n",
    "    epochs = list(range(1, len(acc) + 1))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, acc, label=instance_finale.name)\n",
    "\n",
    "    # Affiche la valeur finale\n",
    "    final_val = acc[-1] * 100\n",
    "    plt.text(\n",
    "        epochs[-1],\n",
    "        acc[-1],\n",
    "        f\"{final_val:.2f}%\",\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"bottom\",\n",
    "        horizontalalignment=\"right\",\n",
    "    )\n",
    "\n",
    "    # Mise en forme\n",
    "    plt.title(f\"Évolution de la Policy Accuracy – {instance_finale.name}\")\n",
    "    plt.xlabel(\"Époque\")\n",
    "    plt.ylabel(\"Policy Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"L'instance ne contient pas d'attribut 'policy_acc'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle retenu est le modèle basé sur l'architecture ShuffleNet avec 4 blocs entraîné sur 100 époques avec une accuracy de 30,74%. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
